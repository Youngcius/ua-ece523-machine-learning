{"cells":[{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":6666,"status":"ok","timestamp":1648877408294,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"kljq1seBv72s"},"outputs":[],"source":["import torch\n","import numpy as np\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch import nn\n","from torch import optim\n","from torchvision import transforms, datasets\n","from torch.utils.data import DataLoader\n","from sklearn import metrics\n","from sklearn import ensemble\n","from sklearn import tree\n","\n","from adaboost import MyAdaBoostClassifier\n"]},{"cell_type":"markdown","metadata":{"id":"OvF8j1SGv72v"},"source":["## 1. MLP Classification on CIFAR10 Dataset"]},{"cell_type":"markdown","metadata":{"id":"mSipB2Dcv72w"},"source":["### Predefine super-parameters"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1648877416456,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"NcqY0mlkv72x","outputId":"cc734483-819f-4b14-edde-2ce3708764ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch Version: 1.10.0+cu111\n","Torch device: cuda\n"]}],"source":["lr = 5e-4  # learning rate\n","l2_lambda = 1e-2  # L2 regularization penalty factor\n","batch_szie = 64\n","width, height = 32, 32  # for CIFAR10 images, with size 3*32*32\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"PyTorch Version:\", torch.__version__)\n","print(\"Torch device:\", device)\n"]},{"cell_type":"markdown","metadata":{"id":"9kIq17gRv72y"},"source":["### Load data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["81044ed6104047d3896ce7b535744e51","a4ae6471349f4ce58b51d18f0fdbf262","a197876f366f4549b07ae4b499969c7a","86a27bc6efc34fb3bc59705b1221c625","ed06b218451b446e9935861e0671f393","8ab5b541d41a4043961d37f64e56a51f","e6cfa800fb9d48b7a20a21e6b6323772","0eb2a87f47d146d4ab4f62d16fde2e1c","a5913d39f1dc4db6b40b327379b9a9a5","d9ae4d43857a4581908b06e10d7a1dc7","32b6de3cf20e40119f2ded41de92369d"]},"executionInfo":{"elapsed":12330,"status":"ok","timestamp":1648877432940,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"V2r7VKb7v72y","outputId":"dd813776-244b-4ade-d73c-cd4617236e29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81044ed6104047d3896ce7b535744e51","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data/\n","0.4733649 0.25156906\n"]}],"source":["cifar10_data = datasets.CIFAR10(root='./data/', train=True, download=True,\n","                                transform=transforms.Compose([transforms.ToTensor()]))\n","data = [d[0].data.cpu().numpy() for d in cifar10_data]\n","data_mean = np.mean(data)\n","data_std = np.std(data)\n","print(data_mean, data_std)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1823,"status":"ok","timestamp":1648877434761,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"tIxXHL6ev72y","outputId":"e9272cc2-8e5b-465d-ed91-6a34742101cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["trainset = datasets.CIFAR10(root='./data/', train=True, download=True,transform=transforms.Compose([\n","    # transforms.ToTensor(), transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n","    transforms.ToTensor(), transforms.Normalize(mean=data_mean, std=data_std)\n","]))\n","trainloader = DataLoader(trainset, batch_size=batch_szie, shuffle=True, num_workers=4)\n","testset = datasets.CIFAR10(root='./data/', train=False, download=True,transform=transforms.Compose([\n","    transforms.ToTensor(), transforms.Normalize(mean=data_mean, std=data_std)\n","]))\n","testloader = DataLoader(testset, batch_size=batch_szie, shuffle=True, num_workers=4)"]},{"cell_type":"markdown","metadata":{"id":"2lkiZxJuv72z"},"source":["### Define Neural Network modelm"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1648878222378,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"tsLh9o7sv720"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, n_channel, width, height):\n","        super(MLP, self).__init__()\n","        self.flatter = nn.Flatten()\n","        self.fc1 = nn.Linear(n_channel * width * height, 128)\n","        self.fc2 = nn.Linear(128, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 64)\n","        self.fc5 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        h = self.flatter(x)\n","        h = F.relu(self.fc1(h))\n","        h = F.relu(self.fc2(h))\n","        h = F.relu(self.fc3(h))\n","        h = F.relu(self.fc4(h))\n","        y = F.softmax(self.fc5(h), dim=1)\n","        return y\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1648878223278,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"mHafMjRnv720"},"outputs":[],"source":["def train(model: nn.Module, dataloader: DataLoader, optimizer: optim.Optimizer, loss_func: nn.Module, device=torch.device('cpu')):\n","    \"\"\"\n","    Training process for one epoch\n","    :param model: Neural Network instance, in type of nn.Module\n","    :param dataloader: DataLoader instance, for training\n","    :param optimizer: optimizer for updating parameters of the GNN model\n","    :param loss_func: loss function in type of nn.Module\n","    :param device: default is CPU, requires to be set to use GPU\n","    \"\"\"    \n","    correct = 0\n","    total_loss = 0\n","    for i, (data, labels) in enumerate(dataloader):\n","        data, labels = data.to(device), labels.to(device)\n","        output = model(data)\n","        loss = loss_func(output, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i + 1) % 100 == 0:\n","            print('Train batch: {}, Train loss: {:.4f}'.format(i + 1, loss.item()))\n","\n","        total_loss += loss.item()\n","        predicts = output.argmax(dim=1)\n","        correct += predicts.eq(labels.view_as(predicts)).sum().item()\n","\n","    total_loss /= len(dataloader)\n","    accuracy = correct / len(dataloader.dataset)\n","    print('Train loss: {:.4f}, Train acccuracy: {:.4f}'.format(total_loss, accuracy))\n","    return total_loss, accuracy\n","\n","def test(model: nn.Module, dataloader: DataLoader, loss_func: nn.Module, device=torch.device('cpu')):\n","    \"\"\"\n","    Testing process for one epoch\n","    :param model: Neural Network instance, in type of nn.Module\n","    :param dataloader: DataLoader instance, for testing\n","    :param loss_func: loss function in type of nn.Module\n","    :param device: default is CPU, requires to be set to use GPU\n","    \"\"\"    \n","    correct = 0\n","    total_loss = 0\n","\n","    with torch.no_grad():\n","        for i, (data, labels) in enumerate(dataloader):\n","            data, labels = data.to(device), labels.to(device)\n","            output = model(data)\n","            total_loss += loss_func(output, labels).item()\n","            predicts = output.argmax(dim=1)\n","            correct += predicts.eq(labels.view_as(predicts)).sum().item()\n","\n","    total_loss /= len(dataloader)\n","    accuracy = correct / len(dataloader.dataset)\n","    print('Test loss: {:.4f}, Test acccuracy: {:.4f}'.format(total_loss, accuracy))\n","    return total_loss, accuracy\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yJRe4sdjv721"},"source":["### Training and Evaluating"]},{"cell_type":"markdown","metadata":{"id":"Am2KinLUv721"},"source":["1. `num_epoch` is 50 (without L2 regularization)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1648878233277,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"GffC7eBhv721"},"outputs":[],"source":["mlp50 = MLP(3, width, height).to(device)\n","optimizer = optim.Adam(mlp50.parameters(), lr=lr)\n","loss_func = nn.CrossEntropyLoss()\n","num_epoch = 50"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498008,"status":"ok","timestamp":1648878732205,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"iPLZKXyNv722","outputId":"148bcf2a-e04d-4f3a-bf5c-53f734425687"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Epoch 1 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0628\n","Train batch: 200, Train loss: 2.1209\n","Train batch: 300, Train loss: 2.0395\n","Train batch: 400, Train loss: 2.0498\n","Train batch: 500, Train loss: 2.0787\n","Train batch: 600, Train loss: 2.1073\n","Train batch: 700, Train loss: 2.0036\n","Train loss: 2.1094, Train acccuracy: 0.3442\n","Test loss: 2.0628, Test acccuracy: 0.3921\n","--- Epoch 2 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9963\n","Train batch: 200, Train loss: 2.0831\n","Train batch: 300, Train loss: 2.0820\n","Train batch: 400, Train loss: 2.1244\n","Train batch: 500, Train loss: 2.0432\n","Train batch: 600, Train loss: 2.0024\n","Train batch: 700, Train loss: 2.0769\n","Train loss: 2.0497, Train acccuracy: 0.4047\n","Test loss: 2.0236, Test acccuracy: 0.4330\n","--- Epoch 3 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0864\n","Train batch: 200, Train loss: 1.8947\n","Train batch: 300, Train loss: 2.0788\n","Train batch: 400, Train loss: 2.0070\n","Train batch: 500, Train loss: 2.0327\n","Train batch: 600, Train loss: 2.0259\n","Train batch: 700, Train loss: 1.9374\n","Train loss: 2.0242, Train acccuracy: 0.4317\n","Test loss: 1.9956, Test acccuracy: 0.4624\n","--- Epoch 4 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9463\n","Train batch: 200, Train loss: 1.9901\n","Train batch: 300, Train loss: 2.0194\n","Train batch: 400, Train loss: 2.0354\n","Train batch: 500, Train loss: 1.9187\n","Train batch: 600, Train loss: 2.0279\n","Train batch: 700, Train loss: 1.9849\n","Train loss: 2.0040, Train acccuracy: 0.4525\n","Test loss: 1.9928, Test acccuracy: 0.4643\n","--- Epoch 5 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0000\n","Train batch: 200, Train loss: 1.9549\n","Train batch: 300, Train loss: 1.8720\n","Train batch: 400, Train loss: 1.9620\n","Train batch: 500, Train loss: 2.0082\n","Train batch: 600, Train loss: 1.9728\n","Train batch: 700, Train loss: 1.9868\n","Train loss: 1.9860, Train acccuracy: 0.4713\n","Test loss: 1.9845, Test acccuracy: 0.4725\n","--- Epoch 6 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0004\n","Train batch: 200, Train loss: 1.9414\n","Train batch: 300, Train loss: 2.0832\n","Train batch: 400, Train loss: 2.0675\n","Train batch: 500, Train loss: 1.8914\n","Train batch: 600, Train loss: 1.9152\n","Train batch: 700, Train loss: 1.9735\n","Train loss: 1.9779, Train acccuracy: 0.4795\n","Test loss: 1.9603, Test acccuracy: 0.4981\n","--- Epoch 7 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9303\n","Train batch: 200, Train loss: 1.8683\n","Train batch: 300, Train loss: 1.9056\n","Train batch: 400, Train loss: 1.9339\n","Train batch: 500, Train loss: 1.9334\n","Train batch: 600, Train loss: 1.9539\n","Train batch: 700, Train loss: 1.8884\n","Train loss: 1.9643, Train acccuracy: 0.4939\n","Test loss: 1.9564, Test acccuracy: 0.5023\n","--- Epoch 8 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9145\n","Train batch: 200, Train loss: 1.8887\n","Train batch: 300, Train loss: 1.9857\n","Train batch: 400, Train loss: 1.9598\n","Train batch: 500, Train loss: 2.0024\n","Train batch: 600, Train loss: 1.9495\n","Train batch: 700, Train loss: 2.0083\n","Train loss: 1.9596, Train acccuracy: 0.4981\n","Test loss: 1.9377, Test acccuracy: 0.5206\n","--- Epoch 9 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9149\n","Train batch: 200, Train loss: 1.9732\n","Train batch: 300, Train loss: 1.9990\n","Train batch: 400, Train loss: 2.0984\n","Train batch: 500, Train loss: 1.9730\n","Train batch: 600, Train loss: 2.0065\n","Train batch: 700, Train loss: 1.8542\n","Train loss: 1.9491, Train acccuracy: 0.5082\n","Test loss: 1.9535, Test acccuracy: 0.5050\n","--- Epoch 10 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9583\n","Train batch: 200, Train loss: 1.9191\n","Train batch: 300, Train loss: 1.9204\n","Train batch: 400, Train loss: 1.9555\n","Train batch: 500, Train loss: 1.8849\n","Train batch: 600, Train loss: 1.9509\n","Train batch: 700, Train loss: 1.9776\n","Train loss: 1.9464, Train acccuracy: 0.5118\n","Test loss: 1.9268, Test acccuracy: 0.5318\n","--- Epoch 11 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8459\n","Train batch: 200, Train loss: 1.9955\n","Train batch: 300, Train loss: 1.9315\n","Train batch: 400, Train loss: 1.9855\n","Train batch: 500, Train loss: 2.0171\n","Train batch: 600, Train loss: 1.8114\n","Train batch: 700, Train loss: 1.8751\n","Train loss: 1.9381, Train acccuracy: 0.5205\n","Test loss: 1.9391, Test acccuracy: 0.5199\n","--- Epoch 12 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9902\n","Train batch: 200, Train loss: 1.9353\n","Train batch: 300, Train loss: 2.0992\n","Train batch: 400, Train loss: 2.0077\n","Train batch: 500, Train loss: 1.9675\n","Train batch: 600, Train loss: 1.8736\n","Train batch: 700, Train loss: 1.7945\n","Train loss: 1.9354, Train acccuracy: 0.5232\n","Test loss: 1.9098, Test acccuracy: 0.5494\n","--- Epoch 13 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9094\n","Train batch: 200, Train loss: 1.9374\n","Train batch: 300, Train loss: 1.9361\n","Train batch: 400, Train loss: 1.9746\n","Train batch: 500, Train loss: 2.0050\n","Train batch: 600, Train loss: 1.9346\n","Train batch: 700, Train loss: 1.8976\n","Train loss: 1.9280, Train acccuracy: 0.5310\n","Test loss: 1.9152, Test acccuracy: 0.5442\n","--- Epoch 14 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9754\n","Train batch: 200, Train loss: 1.8300\n","Train batch: 300, Train loss: 1.9047\n","Train batch: 400, Train loss: 1.9397\n","Train batch: 500, Train loss: 1.9046\n","Train batch: 600, Train loss: 1.9553\n","Train batch: 700, Train loss: 1.8649\n","Train loss: 1.9200, Train acccuracy: 0.5388\n","Test loss: 1.9048, Test acccuracy: 0.5549\n","--- Epoch 15 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8563\n","Train batch: 200, Train loss: 1.9085\n","Train batch: 300, Train loss: 2.0003\n","Train batch: 400, Train loss: 1.8938\n","Train batch: 500, Train loss: 1.8485\n","Train batch: 600, Train loss: 1.9079\n","Train batch: 700, Train loss: 1.8826\n","Train loss: 1.9176, Train acccuracy: 0.5410\n","Test loss: 1.9136, Test acccuracy: 0.5456\n","--- Epoch 16 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8074\n","Train batch: 200, Train loss: 1.9903\n","Train batch: 300, Train loss: 1.9215\n","Train batch: 400, Train loss: 1.8959\n","Train batch: 500, Train loss: 1.9114\n","Train batch: 600, Train loss: 1.7574\n","Train batch: 700, Train loss: 1.9374\n","Train loss: 1.9146, Train acccuracy: 0.5445\n","Test loss: 1.9058, Test acccuracy: 0.5534\n","--- Epoch 17 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8684\n","Train batch: 200, Train loss: 1.8728\n","Train batch: 300, Train loss: 1.9731\n","Train batch: 400, Train loss: 2.0167\n","Train batch: 500, Train loss: 1.8480\n","Train batch: 600, Train loss: 1.9693\n","Train batch: 700, Train loss: 1.9974\n","Train loss: 1.9098, Train acccuracy: 0.5497\n","Test loss: 1.8987, Test acccuracy: 0.5603\n","--- Epoch 18 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9071\n","Train batch: 200, Train loss: 1.8991\n","Train batch: 300, Train loss: 1.9582\n","Train batch: 400, Train loss: 1.9077\n","Train batch: 500, Train loss: 1.9465\n","Train batch: 600, Train loss: 1.9028\n","Train batch: 700, Train loss: 1.9041\n","Train loss: 1.9039, Train acccuracy: 0.5552\n","Test loss: 1.9049, Test acccuracy: 0.5547\n","--- Epoch 19 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7774\n","Train batch: 200, Train loss: 1.8406\n","Train batch: 300, Train loss: 1.9834\n","Train batch: 400, Train loss: 1.8428\n","Train batch: 500, Train loss: 1.9114\n","Train batch: 600, Train loss: 1.9978\n","Train batch: 700, Train loss: 1.9137\n","Train loss: 1.9048, Train acccuracy: 0.5545\n","Test loss: 1.8967, Test acccuracy: 0.5629\n","--- Epoch 20 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8604\n","Train batch: 200, Train loss: 1.9358\n","Train batch: 300, Train loss: 1.8773\n","Train batch: 400, Train loss: 1.7329\n","Train batch: 500, Train loss: 1.8949\n","Train batch: 600, Train loss: 1.8998\n","Train batch: 700, Train loss: 1.8862\n","Train loss: 1.8977, Train acccuracy: 0.5620\n","Test loss: 1.9090, Test acccuracy: 0.5505\n","--- Epoch 21 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7963\n","Train batch: 200, Train loss: 1.9135\n","Train batch: 300, Train loss: 1.9572\n","Train batch: 400, Train loss: 1.9278\n","Train batch: 500, Train loss: 1.9760\n","Train batch: 600, Train loss: 1.8820\n","Train batch: 700, Train loss: 1.8908\n","Train loss: 1.8991, Train acccuracy: 0.5607\n","Test loss: 1.8886, Test acccuracy: 0.5706\n","--- Epoch 22 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9981\n","Train batch: 200, Train loss: 1.9562\n","Train batch: 300, Train loss: 1.9945\n","Train batch: 400, Train loss: 1.8705\n","Train batch: 500, Train loss: 1.9687\n","Train batch: 600, Train loss: 1.9130\n","Train batch: 700, Train loss: 1.8246\n","Train loss: 1.8969, Train acccuracy: 0.5624\n","Test loss: 1.8853, Test acccuracy: 0.5742\n","--- Epoch 23 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8605\n","Train batch: 200, Train loss: 1.8323\n","Train batch: 300, Train loss: 1.9122\n","Train batch: 400, Train loss: 1.8894\n","Train batch: 500, Train loss: 1.8693\n","Train batch: 600, Train loss: 1.9743\n","Train batch: 700, Train loss: 1.8205\n","Train loss: 1.8963, Train acccuracy: 0.5627\n","Test loss: 1.8909, Test acccuracy: 0.5688\n","--- Epoch 24 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8917\n","Train batch: 200, Train loss: 1.8714\n","Train batch: 300, Train loss: 1.8157\n","Train batch: 400, Train loss: 1.8926\n","Train batch: 500, Train loss: 1.8422\n","Train batch: 600, Train loss: 1.8752\n","Train batch: 700, Train loss: 1.8532\n","Train loss: 1.8900, Train acccuracy: 0.5698\n","Test loss: 1.8786, Test acccuracy: 0.5808\n","--- Epoch 25 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8990\n","Train batch: 200, Train loss: 1.7880\n","Train batch: 300, Train loss: 1.7812\n","Train batch: 400, Train loss: 1.8547\n","Train batch: 500, Train loss: 1.9726\n","Train batch: 600, Train loss: 1.8701\n","Train batch: 700, Train loss: 1.7994\n","Train loss: 1.8895, Train acccuracy: 0.5696\n","Test loss: 1.8847, Test acccuracy: 0.5749\n","--- Epoch 26 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8925\n","Train batch: 200, Train loss: 1.9354\n","Train batch: 300, Train loss: 1.8580\n","Train batch: 400, Train loss: 1.7974\n","Train batch: 500, Train loss: 1.8075\n","Train batch: 600, Train loss: 1.9370\n","Train batch: 700, Train loss: 1.8727\n","Train loss: 1.8862, Train acccuracy: 0.5730\n","Test loss: 1.8792, Test acccuracy: 0.5802\n","--- Epoch 27 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8449\n","Train batch: 200, Train loss: 1.9324\n","Train batch: 300, Train loss: 1.8514\n","Train batch: 400, Train loss: 1.8742\n","Train batch: 500, Train loss: 1.8291\n","Train batch: 600, Train loss: 1.8066\n","Train batch: 700, Train loss: 1.9886\n","Train loss: 1.8807, Train acccuracy: 0.5789\n","Test loss: 1.8647, Test acccuracy: 0.5948\n","--- Epoch 28 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9040\n","Train batch: 200, Train loss: 1.8320\n","Train batch: 300, Train loss: 1.9342\n","Train batch: 400, Train loss: 1.8321\n","Train batch: 500, Train loss: 1.8662\n","Train batch: 600, Train loss: 1.8839\n","Train batch: 700, Train loss: 1.9309\n","Train loss: 1.8802, Train acccuracy: 0.5792\n","Test loss: 1.8796, Test acccuracy: 0.5798\n","--- Epoch 29 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8854\n","Train batch: 200, Train loss: 1.9390\n","Train batch: 300, Train loss: 1.8804\n","Train batch: 400, Train loss: 1.9177\n","Train batch: 500, Train loss: 1.8959\n","Train batch: 600, Train loss: 1.8657\n","Train batch: 700, Train loss: 1.9350\n","Train loss: 1.8833, Train acccuracy: 0.5763\n","Test loss: 1.8783, Test acccuracy: 0.5811\n","--- Epoch 30 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9319\n","Train batch: 200, Train loss: 1.9159\n","Train batch: 300, Train loss: 1.8768\n","Train batch: 400, Train loss: 1.8641\n","Train batch: 500, Train loss: 1.8869\n","Train batch: 600, Train loss: 1.9760\n","Train batch: 700, Train loss: 1.8179\n","Train loss: 1.8768, Train acccuracy: 0.5827\n","Test loss: 1.8715, Test acccuracy: 0.5883\n","--- Epoch 31 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9260\n","Train batch: 200, Train loss: 1.8547\n","Train batch: 300, Train loss: 1.9555\n","Train batch: 400, Train loss: 1.9614\n","Train batch: 500, Train loss: 1.8854\n","Train batch: 600, Train loss: 1.8774\n","Train batch: 700, Train loss: 1.8599\n","Train loss: 1.8757, Train acccuracy: 0.5833\n","Test loss: 1.8643, Test acccuracy: 0.5954\n","--- Epoch 32 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8249\n","Train batch: 200, Train loss: 1.9699\n","Train batch: 300, Train loss: 1.8365\n","Train batch: 400, Train loss: 1.8792\n","Train batch: 500, Train loss: 1.8588\n","Train batch: 600, Train loss: 1.9050\n","Train batch: 700, Train loss: 1.9264\n","Train loss: 1.8689, Train acccuracy: 0.5907\n","Test loss: 1.8788, Test acccuracy: 0.5812\n","--- Epoch 33 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9172\n","Train batch: 200, Train loss: 1.8387\n","Train batch: 300, Train loss: 1.7868\n","Train batch: 400, Train loss: 1.8326\n","Train batch: 500, Train loss: 1.8763\n","Train batch: 600, Train loss: 1.9391\n","Train batch: 700, Train loss: 1.9012\n","Train loss: 1.8697, Train acccuracy: 0.5897\n","Test loss: 1.8542, Test acccuracy: 0.6060\n","--- Epoch 34 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8500\n","Train batch: 200, Train loss: 1.8796\n","Train batch: 300, Train loss: 1.8016\n","Train batch: 400, Train loss: 1.8737\n","Train batch: 500, Train loss: 1.8625\n","Train batch: 600, Train loss: 1.8514\n","Train batch: 700, Train loss: 1.9325\n","Train loss: 1.8676, Train acccuracy: 0.5919\n","Test loss: 1.8551, Test acccuracy: 0.6053\n","--- Epoch 35 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9716\n","Train batch: 200, Train loss: 1.7265\n","Train batch: 300, Train loss: 1.7898\n","Train batch: 400, Train loss: 1.8132\n","Train batch: 500, Train loss: 1.9210\n","Train batch: 600, Train loss: 1.9769\n","Train batch: 700, Train loss: 1.9386\n","Train loss: 1.8648, Train acccuracy: 0.5957\n","Test loss: 1.8593, Test acccuracy: 0.6007\n","--- Epoch 36 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9178\n","Train batch: 200, Train loss: 1.9641\n","Train batch: 300, Train loss: 1.7964\n","Train batch: 400, Train loss: 1.7960\n","Train batch: 500, Train loss: 1.9015\n","Train batch: 600, Train loss: 1.8135\n","Train batch: 700, Train loss: 1.9073\n","Train loss: 1.8648, Train acccuracy: 0.5951\n","Test loss: 1.8529, Test acccuracy: 0.6079\n","--- Epoch 37 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8297\n","Train batch: 200, Train loss: 1.9075\n","Train batch: 300, Train loss: 1.7665\n","Train batch: 400, Train loss: 1.8082\n","Train batch: 500, Train loss: 1.9290\n","Train batch: 600, Train loss: 1.8417\n","Train batch: 700, Train loss: 1.9199\n","Train loss: 1.8664, Train acccuracy: 0.5934\n","Test loss: 1.8484, Test acccuracy: 0.6117\n","--- Epoch 38 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8770\n","Train batch: 200, Train loss: 1.8660\n","Train batch: 300, Train loss: 1.9341\n","Train batch: 400, Train loss: 1.9781\n","Train batch: 500, Train loss: 1.7712\n","Train batch: 600, Train loss: 1.9531\n","Train batch: 700, Train loss: 1.7920\n","Train loss: 1.8665, Train acccuracy: 0.5931\n","Test loss: 1.8530, Test acccuracy: 0.6073\n","--- Epoch 39 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8672\n","Train batch: 200, Train loss: 1.8364\n","Train batch: 300, Train loss: 1.9180\n","Train batch: 400, Train loss: 1.8309\n","Train batch: 500, Train loss: 1.9599\n","Train batch: 600, Train loss: 1.9176\n","Train batch: 700, Train loss: 1.8011\n","Train loss: 1.8589, Train acccuracy: 0.6007\n","Test loss: 1.8525, Test acccuracy: 0.6078\n","--- Epoch 40 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8224\n","Train batch: 200, Train loss: 1.8606\n","Train batch: 300, Train loss: 1.8991\n","Train batch: 400, Train loss: 1.9112\n","Train batch: 500, Train loss: 1.9432\n","Train batch: 600, Train loss: 1.7860\n","Train batch: 700, Train loss: 1.8640\n","Train loss: 1.8645, Train acccuracy: 0.5953\n","Test loss: 1.8584, Test acccuracy: 0.6015\n","--- Epoch 41 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8447\n","Train batch: 200, Train loss: 1.8746\n","Train batch: 300, Train loss: 1.8618\n","Train batch: 400, Train loss: 1.8212\n","Train batch: 500, Train loss: 1.8805\n","Train batch: 600, Train loss: 1.8603\n","Train batch: 700, Train loss: 1.8628\n","Train loss: 1.8553, Train acccuracy: 0.6050\n","Test loss: 1.8605, Test acccuracy: 0.5991\n","--- Epoch 42 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8405\n","Train batch: 200, Train loss: 1.8369\n","Train batch: 300, Train loss: 1.8095\n","Train batch: 400, Train loss: 1.8335\n","Train batch: 500, Train loss: 1.9604\n","Train batch: 600, Train loss: 1.9314\n","Train batch: 700, Train loss: 1.8565\n","Train loss: 1.8572, Train acccuracy: 0.6026\n","Test loss: 1.8622, Test acccuracy: 0.5974\n","--- Epoch 43 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7808\n","Train batch: 200, Train loss: 1.8513\n","Train batch: 300, Train loss: 1.9437\n","Train batch: 400, Train loss: 1.7598\n","Train batch: 500, Train loss: 1.8550\n","Train batch: 600, Train loss: 1.8323\n","Train batch: 700, Train loss: 1.9438\n","Train loss: 1.8553, Train acccuracy: 0.6048\n","Test loss: 1.8473, Test acccuracy: 0.6128\n","--- Epoch 44 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7719\n","Train batch: 200, Train loss: 1.8248\n","Train batch: 300, Train loss: 1.9274\n","Train batch: 400, Train loss: 2.0143\n","Train batch: 500, Train loss: 1.8325\n","Train batch: 600, Train loss: 1.7417\n","Train batch: 700, Train loss: 1.9380\n","Train loss: 1.8586, Train acccuracy: 0.6015\n","Test loss: 1.8524, Test acccuracy: 0.6079\n","--- Epoch 45 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7592\n","Train batch: 200, Train loss: 1.9118\n","Train batch: 300, Train loss: 1.9152\n","Train batch: 400, Train loss: 1.8833\n","Train batch: 500, Train loss: 1.8586\n","Train batch: 600, Train loss: 1.8811\n","Train batch: 700, Train loss: 1.8591\n","Train loss: 1.8508, Train acccuracy: 0.6093\n","Test loss: 1.8456, Test acccuracy: 0.6146\n","--- Epoch 46 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9127\n","Train batch: 200, Train loss: 1.8023\n","Train batch: 300, Train loss: 1.8627\n","Train batch: 400, Train loss: 1.7983\n","Train batch: 500, Train loss: 1.8350\n","Train batch: 600, Train loss: 1.8592\n","Train batch: 700, Train loss: 1.8382\n","Train loss: 1.8504, Train acccuracy: 0.6094\n","Test loss: 1.8500, Test acccuracy: 0.6100\n","--- Epoch 47 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8274\n","Train batch: 200, Train loss: 1.8654\n","Train batch: 300, Train loss: 1.8929\n","Train batch: 400, Train loss: 1.8804\n","Train batch: 500, Train loss: 1.8650\n","Train batch: 600, Train loss: 1.8551\n","Train batch: 700, Train loss: 1.8354\n","Train loss: 1.8527, Train acccuracy: 0.6073\n","Test loss: 1.8530, Test acccuracy: 0.6068\n","--- Epoch 48 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8286\n","Train batch: 200, Train loss: 1.7460\n","Train batch: 300, Train loss: 1.7988\n","Train batch: 400, Train loss: 1.8676\n","Train batch: 500, Train loss: 1.8100\n","Train batch: 600, Train loss: 1.8992\n","Train batch: 700, Train loss: 1.8449\n","Train loss: 1.8531, Train acccuracy: 0.6067\n","Test loss: 1.8429, Test acccuracy: 0.6169\n","--- Epoch 49 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8665\n","Train batch: 200, Train loss: 1.8962\n","Train batch: 300, Train loss: 1.8528\n","Train batch: 400, Train loss: 1.8258\n","Train batch: 500, Train loss: 1.8828\n","Train batch: 600, Train loss: 1.7973\n","Train batch: 700, Train loss: 1.8423\n","Train loss: 1.8519, Train acccuracy: 0.6085\n","Test loss: 1.8720, Test acccuracy: 0.5878\n","--- Epoch 50 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7539\n","Train batch: 200, Train loss: 1.8974\n","Train batch: 300, Train loss: 1.8379\n","Train batch: 400, Train loss: 1.9282\n","Train batch: 500, Train loss: 1.7535\n","Train batch: 600, Train loss: 1.8577\n","Train batch: 700, Train loss: 1.8940\n","Train loss: 1.8570, Train acccuracy: 0.6032\n","Test loss: 1.8474, Test acccuracy: 0.6129\n"]}],"source":["train_loss, test_loss = [], []\n","train_accu, test_accu = [], []\n","\n","for epoch in range(1, num_epoch + 1):\n","    print('--- Epoch {} --- (No L2 regularization)'.format(epoch))\n","    trloss, traccu = train(mlp50, trainloader, optimizer, loss_func, device)\n","    teloss, teaccu = test(mlp50, trainloader, loss_func, device)\n","    train_loss.append(trloss)\n","    train_accu.append(traccu)\n","    test_loss.append(teloss)\n","    test_accu.append(teaccu)\n","\n","np.savetxt('train-50.txt', np.vstack([train_loss, train_accu]))\n","np.savetxt('test-50.txt', np.vstack([test_loss, test_accu]))"]},{"cell_type":"markdown","metadata":{"id":"usNWO9Akv722"},"source":["2. `num_epoch` is 250 (without L2 regularization)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1648878732206,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"8ZqVHvO9v722"},"outputs":[],"source":["mlp250 = MLP(3, width, height).to(device)\n","optimizer = optim.Adam(mlp250.parameters(), lr=lr)\n","loss_func = nn.CrossEntropyLoss()\n","num_epoch = 250"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1600702,"status":"ok","timestamp":1648880332904,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"d4LyU6Ucv722","outputId":"581a7900-b56f-44ba-8f45-1ae816bf3222"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Epoch 1 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1694\n","Train batch: 200, Train loss: 2.0751\n","Train batch: 300, Train loss: 2.0717\n","Train batch: 400, Train loss: 2.0465\n","Train batch: 500, Train loss: 2.1582\n","Train batch: 600, Train loss: 2.0783\n","Train batch: 700, Train loss: 2.0229\n","Train loss: 2.1129, Train acccuracy: 0.3401\n","Test loss: 2.0701, Test acccuracy: 0.3861\n","--- Epoch 2 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0278\n","Train batch: 200, Train loss: 2.0994\n","Train batch: 300, Train loss: 2.0962\n","Train batch: 400, Train loss: 2.0318\n","Train batch: 500, Train loss: 2.0306\n","Train batch: 600, Train loss: 1.9750\n","Train batch: 700, Train loss: 1.9456\n","Train loss: 2.0499, Train acccuracy: 0.4063\n","Test loss: 2.0418, Test acccuracy: 0.4120\n","--- Epoch 3 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0853\n","Train batch: 200, Train loss: 1.8514\n","Train batch: 300, Train loss: 2.0537\n","Train batch: 400, Train loss: 2.0546\n","Train batch: 500, Train loss: 1.8954\n","Train batch: 600, Train loss: 2.1060\n","Train batch: 700, Train loss: 2.0024\n","Train loss: 2.0248, Train acccuracy: 0.4311\n","Test loss: 2.0177, Test acccuracy: 0.4373\n","--- Epoch 4 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9934\n","Train batch: 200, Train loss: 2.0930\n","Train batch: 300, Train loss: 1.9246\n","Train batch: 400, Train loss: 2.0315\n","Train batch: 500, Train loss: 1.9902\n","Train batch: 600, Train loss: 1.9944\n","Train batch: 700, Train loss: 2.0386\n","Train loss: 2.0050, Train acccuracy: 0.4519\n","Test loss: 2.0146, Test acccuracy: 0.4420\n","--- Epoch 5 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0216\n","Train batch: 200, Train loss: 2.0231\n","Train batch: 300, Train loss: 1.9635\n","Train batch: 400, Train loss: 2.1129\n","Train batch: 500, Train loss: 1.9961\n","Train batch: 600, Train loss: 1.9267\n","Train batch: 700, Train loss: 1.9661\n","Train loss: 1.9928, Train acccuracy: 0.4642\n","Test loss: 2.0088, Test acccuracy: 0.4468\n","--- Epoch 6 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0364\n","Train batch: 200, Train loss: 1.9238\n","Train batch: 300, Train loss: 2.0476\n","Train batch: 400, Train loss: 1.9112\n","Train batch: 500, Train loss: 1.9150\n","Train batch: 600, Train loss: 1.9702\n","Train batch: 700, Train loss: 2.0289\n","Train loss: 1.9785, Train acccuracy: 0.4784\n","Test loss: 2.0082, Test acccuracy: 0.4485\n","--- Epoch 7 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0425\n","Train batch: 200, Train loss: 1.9608\n","Train batch: 300, Train loss: 2.0814\n","Train batch: 400, Train loss: 2.0101\n","Train batch: 500, Train loss: 2.0667\n","Train batch: 600, Train loss: 1.9259\n","Train batch: 700, Train loss: 1.9891\n","Train loss: 1.9707, Train acccuracy: 0.4870\n","Test loss: 1.9927, Test acccuracy: 0.4632\n","--- Epoch 8 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0725\n","Train batch: 200, Train loss: 1.9654\n","Train batch: 300, Train loss: 1.9846\n","Train batch: 400, Train loss: 1.9670\n","Train batch: 500, Train loss: 1.9721\n","Train batch: 600, Train loss: 1.9379\n","Train batch: 700, Train loss: 2.0480\n","Train loss: 1.9598, Train acccuracy: 0.4981\n","Test loss: 1.9856, Test acccuracy: 0.4707\n","--- Epoch 9 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9349\n","Train batch: 200, Train loss: 1.9527\n","Train batch: 300, Train loss: 1.8536\n","Train batch: 400, Train loss: 1.9014\n","Train batch: 500, Train loss: 1.8784\n","Train batch: 600, Train loss: 1.9935\n","Train batch: 700, Train loss: 1.9522\n","Train loss: 1.9498, Train acccuracy: 0.5079\n","Test loss: 1.9794, Test acccuracy: 0.4777\n","--- Epoch 10 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9518\n","Train batch: 200, Train loss: 1.9735\n","Train batch: 300, Train loss: 1.9937\n","Train batch: 400, Train loss: 1.9628\n","Train batch: 500, Train loss: 1.9595\n","Train batch: 600, Train loss: 1.9217\n","Train batch: 700, Train loss: 1.9348\n","Train loss: 1.9414, Train acccuracy: 0.5175\n","Test loss: 1.9803, Test acccuracy: 0.4765\n","--- Epoch 11 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8597\n","Train batch: 200, Train loss: 1.9640\n","Train batch: 300, Train loss: 1.9456\n","Train batch: 400, Train loss: 1.8836\n","Train batch: 500, Train loss: 1.8330\n","Train batch: 600, Train loss: 1.9990\n","Train batch: 700, Train loss: 1.8718\n","Train loss: 1.9374, Train acccuracy: 0.5214\n","Test loss: 1.9834, Test acccuracy: 0.4749\n","--- Epoch 12 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0555\n","Train batch: 200, Train loss: 2.0031\n","Train batch: 300, Train loss: 1.9957\n","Train batch: 400, Train loss: 2.0097\n","Train batch: 500, Train loss: 1.9878\n","Train batch: 600, Train loss: 1.9401\n","Train batch: 700, Train loss: 1.9482\n","Train loss: 1.9359, Train acccuracy: 0.5228\n","Test loss: 1.9757, Test acccuracy: 0.4813\n","--- Epoch 13 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9370\n","Train batch: 200, Train loss: 1.8013\n","Train batch: 300, Train loss: 1.8370\n","Train batch: 400, Train loss: 1.9379\n","Train batch: 500, Train loss: 1.8855\n","Train batch: 600, Train loss: 2.0220\n","Train batch: 700, Train loss: 1.9218\n","Train loss: 1.9269, Train acccuracy: 0.5315\n","Test loss: 1.9719, Test acccuracy: 0.4864\n","--- Epoch 14 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9779\n","Train batch: 200, Train loss: 1.9124\n","Train batch: 300, Train loss: 1.9916\n","Train batch: 400, Train loss: 1.7899\n","Train batch: 500, Train loss: 1.9996\n","Train batch: 600, Train loss: 1.9577\n","Train batch: 700, Train loss: 1.9365\n","Train loss: 1.9210, Train acccuracy: 0.5383\n","Test loss: 1.9717, Test acccuracy: 0.4860\n","--- Epoch 15 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8512\n","Train batch: 200, Train loss: 1.9214\n","Train batch: 300, Train loss: 1.8763\n","Train batch: 400, Train loss: 1.9076\n","Train batch: 500, Train loss: 1.9165\n","Train batch: 600, Train loss: 1.8987\n","Train batch: 700, Train loss: 1.9461\n","Train loss: 1.9184, Train acccuracy: 0.5404\n","Test loss: 1.9745, Test acccuracy: 0.4846\n","--- Epoch 16 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9284\n","Train batch: 200, Train loss: 1.9298\n","Train batch: 300, Train loss: 1.8534\n","Train batch: 400, Train loss: 1.8651\n","Train batch: 500, Train loss: 1.8191\n","Train batch: 600, Train loss: 1.8900\n","Train batch: 700, Train loss: 1.8561\n","Train loss: 1.9158, Train acccuracy: 0.5427\n","Test loss: 1.9711, Test acccuracy: 0.4867\n","--- Epoch 17 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8464\n","Train batch: 200, Train loss: 1.9101\n","Train batch: 300, Train loss: 1.8400\n","Train batch: 400, Train loss: 1.9623\n","Train batch: 500, Train loss: 2.0449\n","Train batch: 600, Train loss: 1.8769\n","Train batch: 700, Train loss: 1.9556\n","Train loss: 1.9138, Train acccuracy: 0.5451\n","Test loss: 1.9741, Test acccuracy: 0.4844\n","--- Epoch 18 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9569\n","Train batch: 200, Train loss: 1.8310\n","Train batch: 300, Train loss: 1.9737\n","Train batch: 400, Train loss: 1.8985\n","Train batch: 500, Train loss: 1.9716\n","Train batch: 600, Train loss: 1.8253\n","Train batch: 700, Train loss: 1.9601\n","Train loss: 1.9073, Train acccuracy: 0.5518\n","Test loss: 1.9705, Test acccuracy: 0.4871\n","--- Epoch 19 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9190\n","Train batch: 200, Train loss: 1.9460\n","Train batch: 300, Train loss: 1.9027\n","Train batch: 400, Train loss: 1.8719\n","Train batch: 500, Train loss: 1.9182\n","Train batch: 600, Train loss: 1.9141\n","Train batch: 700, Train loss: 1.9161\n","Train loss: 1.9031, Train acccuracy: 0.5565\n","Test loss: 1.9745, Test acccuracy: 0.4839\n","--- Epoch 20 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9640\n","Train batch: 200, Train loss: 2.0094\n","Train batch: 300, Train loss: 1.8166\n","Train batch: 400, Train loss: 1.8216\n","Train batch: 500, Train loss: 1.9314\n","Train batch: 600, Train loss: 1.7871\n","Train batch: 700, Train loss: 1.8830\n","Train loss: 1.8953, Train acccuracy: 0.5639\n","Test loss: 1.9641, Test acccuracy: 0.4930\n","--- Epoch 21 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9089\n","Train batch: 200, Train loss: 1.9315\n","Train batch: 300, Train loss: 1.9624\n","Train batch: 400, Train loss: 1.9484\n","Train batch: 500, Train loss: 1.8490\n","Train batch: 600, Train loss: 1.8539\n","Train batch: 700, Train loss: 1.8188\n","Train loss: 1.8961, Train acccuracy: 0.5631\n","Test loss: 1.9672, Test acccuracy: 0.4900\n","--- Epoch 22 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9085\n","Train batch: 200, Train loss: 1.7425\n","Train batch: 300, Train loss: 1.9265\n","Train batch: 400, Train loss: 1.9588\n","Train batch: 500, Train loss: 1.9016\n","Train batch: 600, Train loss: 1.8611\n","Train batch: 700, Train loss: 1.9318\n","Train loss: 1.8947, Train acccuracy: 0.5651\n","Test loss: 1.9628, Test acccuracy: 0.4959\n","--- Epoch 23 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8603\n","Train batch: 200, Train loss: 1.8505\n","Train batch: 300, Train loss: 1.9291\n","Train batch: 400, Train loss: 1.9624\n","Train batch: 500, Train loss: 1.8418\n","Train batch: 600, Train loss: 1.9575\n","Train batch: 700, Train loss: 1.8251\n","Train loss: 1.8967, Train acccuracy: 0.5628\n","Test loss: 1.9644, Test acccuracy: 0.4930\n","--- Epoch 24 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9790\n","Train batch: 200, Train loss: 1.9426\n","Train batch: 300, Train loss: 1.8657\n","Train batch: 400, Train loss: 1.9556\n","Train batch: 500, Train loss: 1.8713\n","Train batch: 600, Train loss: 1.8610\n","Train batch: 700, Train loss: 1.8212\n","Train loss: 1.8895, Train acccuracy: 0.5690\n","Test loss: 1.9669, Test acccuracy: 0.4909\n","--- Epoch 25 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8438\n","Train batch: 200, Train loss: 1.8833\n","Train batch: 300, Train loss: 1.8661\n","Train batch: 400, Train loss: 1.8863\n","Train batch: 500, Train loss: 1.9085\n","Train batch: 600, Train loss: 1.7988\n","Train batch: 700, Train loss: 1.8348\n","Train loss: 1.8901, Train acccuracy: 0.5693\n","Test loss: 1.9671, Test acccuracy: 0.4912\n","--- Epoch 26 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8650\n","Train batch: 200, Train loss: 1.8547\n","Train batch: 300, Train loss: 1.8345\n","Train batch: 400, Train loss: 1.8128\n","Train batch: 500, Train loss: 1.8328\n","Train batch: 600, Train loss: 1.9064\n","Train batch: 700, Train loss: 1.7899\n","Train loss: 1.8875, Train acccuracy: 0.5720\n","Test loss: 1.9522, Test acccuracy: 0.5057\n","--- Epoch 27 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8699\n","Train batch: 200, Train loss: 1.8576\n","Train batch: 300, Train loss: 1.8559\n","Train batch: 400, Train loss: 1.9072\n","Train batch: 500, Train loss: 1.8829\n","Train batch: 600, Train loss: 1.7507\n","Train batch: 700, Train loss: 1.8867\n","Train loss: 1.8812, Train acccuracy: 0.5784\n","Test loss: 1.9722, Test acccuracy: 0.4860\n","--- Epoch 28 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9046\n","Train batch: 200, Train loss: 1.7874\n","Train batch: 300, Train loss: 1.8001\n","Train batch: 400, Train loss: 1.8668\n","Train batch: 500, Train loss: 1.9392\n","Train batch: 600, Train loss: 1.9129\n","Train batch: 700, Train loss: 1.7662\n","Train loss: 1.8824, Train acccuracy: 0.5771\n","Test loss: 1.9547, Test acccuracy: 0.5029\n","--- Epoch 29 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8445\n","Train batch: 200, Train loss: 1.8068\n","Train batch: 300, Train loss: 1.8791\n","Train batch: 400, Train loss: 1.8147\n","Train batch: 500, Train loss: 1.8712\n","Train batch: 600, Train loss: 1.7543\n","Train batch: 700, Train loss: 1.7620\n","Train loss: 1.8755, Train acccuracy: 0.5843\n","Test loss: 1.9633, Test acccuracy: 0.4947\n","--- Epoch 30 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0479\n","Train batch: 200, Train loss: 1.8633\n","Train batch: 300, Train loss: 1.8680\n","Train batch: 400, Train loss: 1.9388\n","Train batch: 500, Train loss: 1.9861\n","Train batch: 600, Train loss: 2.0762\n","Train batch: 700, Train loss: 1.9317\n","Train loss: 1.8760, Train acccuracy: 0.5838\n","Test loss: 1.9607, Test acccuracy: 0.4988\n","--- Epoch 31 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7939\n","Train batch: 200, Train loss: 1.8673\n","Train batch: 300, Train loss: 1.8739\n","Train batch: 400, Train loss: 1.9110\n","Train batch: 500, Train loss: 1.8153\n","Train batch: 600, Train loss: 1.8484\n","Train batch: 700, Train loss: 1.9167\n","Train loss: 1.8739, Train acccuracy: 0.5855\n","Test loss: 1.9576, Test acccuracy: 0.5015\n","--- Epoch 32 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8586\n","Train batch: 200, Train loss: 1.8737\n","Train batch: 300, Train loss: 1.7709\n","Train batch: 400, Train loss: 1.8575\n","Train batch: 500, Train loss: 1.8627\n","Train batch: 600, Train loss: 1.8978\n","Train batch: 700, Train loss: 1.7577\n","Train loss: 1.8741, Train acccuracy: 0.5857\n","Test loss: 1.9695, Test acccuracy: 0.4890\n","--- Epoch 33 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9475\n","Train batch: 200, Train loss: 1.8472\n","Train batch: 300, Train loss: 1.8831\n","Train batch: 400, Train loss: 1.8729\n","Train batch: 500, Train loss: 1.8347\n","Train batch: 600, Train loss: 1.9093\n","Train batch: 700, Train loss: 1.8078\n","Train loss: 1.8725, Train acccuracy: 0.5876\n","Test loss: 1.9692, Test acccuracy: 0.4899\n","--- Epoch 34 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9720\n","Train batch: 200, Train loss: 1.8225\n","Train batch: 300, Train loss: 1.9219\n","Train batch: 400, Train loss: 1.7723\n","Train batch: 500, Train loss: 1.9423\n","Train batch: 600, Train loss: 1.8627\n","Train batch: 700, Train loss: 1.8768\n","Train loss: 1.8703, Train acccuracy: 0.5893\n","Test loss: 1.9710, Test acccuracy: 0.4870\n","--- Epoch 35 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9463\n","Train batch: 200, Train loss: 1.7105\n","Train batch: 300, Train loss: 1.8922\n","Train batch: 400, Train loss: 1.9493\n","Train batch: 500, Train loss: 1.9533\n","Train batch: 600, Train loss: 1.9378\n","Train batch: 700, Train loss: 1.9105\n","Train loss: 1.8677, Train acccuracy: 0.5923\n","Test loss: 1.9552, Test acccuracy: 0.5046\n","--- Epoch 36 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8112\n","Train batch: 200, Train loss: 2.0078\n","Train batch: 300, Train loss: 1.9323\n","Train batch: 400, Train loss: 1.8450\n","Train batch: 500, Train loss: 1.8660\n","Train batch: 600, Train loss: 1.8562\n","Train batch: 700, Train loss: 1.8457\n","Train loss: 1.8601, Train acccuracy: 0.5994\n","Test loss: 1.9584, Test acccuracy: 0.5009\n","--- Epoch 37 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7755\n","Train batch: 200, Train loss: 1.9540\n","Train batch: 300, Train loss: 1.8183\n","Train batch: 400, Train loss: 1.9141\n","Train batch: 500, Train loss: 1.9654\n","Train batch: 600, Train loss: 1.9526\n","Train batch: 700, Train loss: 1.9305\n","Train loss: 1.8667, Train acccuracy: 0.5931\n","Test loss: 1.9560, Test acccuracy: 0.5028\n","--- Epoch 38 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9238\n","Train batch: 200, Train loss: 1.8644\n","Train batch: 300, Train loss: 1.8305\n","Train batch: 400, Train loss: 1.9043\n","Train batch: 500, Train loss: 1.8230\n","Train batch: 600, Train loss: 1.8994\n","Train batch: 700, Train loss: 1.8517\n","Train loss: 1.8616, Train acccuracy: 0.5978\n","Test loss: 1.9693, Test acccuracy: 0.4894\n","--- Epoch 39 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8731\n","Train batch: 200, Train loss: 1.7890\n","Train batch: 300, Train loss: 1.7273\n","Train batch: 400, Train loss: 1.8714\n","Train batch: 500, Train loss: 1.8683\n","Train batch: 600, Train loss: 1.8796\n","Train batch: 700, Train loss: 1.8648\n","Train loss: 1.8596, Train acccuracy: 0.5994\n","Test loss: 1.9516, Test acccuracy: 0.5073\n","--- Epoch 40 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8435\n","Train batch: 200, Train loss: 1.9088\n","Train batch: 300, Train loss: 1.8631\n","Train batch: 400, Train loss: 1.8890\n","Train batch: 500, Train loss: 1.8556\n","Train batch: 600, Train loss: 1.7146\n","Train batch: 700, Train loss: 1.8448\n","Train loss: 1.8595, Train acccuracy: 0.5999\n","Test loss: 1.9560, Test acccuracy: 0.5047\n","--- Epoch 41 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7860\n","Train batch: 200, Train loss: 1.7548\n","Train batch: 300, Train loss: 1.8358\n","Train batch: 400, Train loss: 1.9396\n","Train batch: 500, Train loss: 1.8970\n","Train batch: 600, Train loss: 1.8640\n","Train batch: 700, Train loss: 1.9861\n","Train loss: 1.8612, Train acccuracy: 0.5982\n","Test loss: 1.9580, Test acccuracy: 0.5004\n","--- Epoch 42 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8577\n","Train batch: 200, Train loss: 1.9218\n","Train batch: 300, Train loss: 1.8723\n","Train batch: 400, Train loss: 1.7582\n","Train batch: 500, Train loss: 1.8895\n","Train batch: 600, Train loss: 1.8338\n","Train batch: 700, Train loss: 1.8181\n","Train loss: 1.8592, Train acccuracy: 0.6003\n","Test loss: 1.9588, Test acccuracy: 0.5004\n","--- Epoch 43 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8885\n","Train batch: 200, Train loss: 1.8679\n","Train batch: 300, Train loss: 1.8176\n","Train batch: 400, Train loss: 1.8458\n","Train batch: 500, Train loss: 1.8051\n","Train batch: 600, Train loss: 1.9756\n","Train batch: 700, Train loss: 1.8353\n","Train loss: 1.8531, Train acccuracy: 0.6069\n","Test loss: 1.9596, Test acccuracy: 0.4995\n","--- Epoch 44 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7893\n","Train batch: 200, Train loss: 1.8655\n","Train batch: 300, Train loss: 1.8899\n","Train batch: 400, Train loss: 1.8234\n","Train batch: 500, Train loss: 1.8537\n","Train batch: 600, Train loss: 1.8348\n","Train batch: 700, Train loss: 1.7912\n","Train loss: 1.8589, Train acccuracy: 0.6009\n","Test loss: 1.9633, Test acccuracy: 0.4939\n","--- Epoch 45 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9433\n","Train batch: 200, Train loss: 1.8070\n","Train batch: 300, Train loss: 1.9031\n","Train batch: 400, Train loss: 1.9139\n","Train batch: 500, Train loss: 1.8624\n","Train batch: 600, Train loss: 1.8591\n","Train batch: 700, Train loss: 1.8743\n","Train loss: 1.8590, Train acccuracy: 0.6007\n","Test loss: 1.9569, Test acccuracy: 0.5033\n","--- Epoch 46 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8627\n","Train batch: 200, Train loss: 1.8021\n","Train batch: 300, Train loss: 1.8647\n","Train batch: 400, Train loss: 1.7507\n","Train batch: 500, Train loss: 1.7862\n","Train batch: 600, Train loss: 1.7998\n","Train batch: 700, Train loss: 1.9324\n","Train loss: 1.8572, Train acccuracy: 0.6029\n","Test loss: 1.9575, Test acccuracy: 0.5005\n","--- Epoch 47 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8407\n","Train batch: 200, Train loss: 1.8081\n","Train batch: 300, Train loss: 1.9155\n","Train batch: 400, Train loss: 1.8678\n","Train batch: 500, Train loss: 1.9078\n","Train batch: 600, Train loss: 1.8710\n","Train batch: 700, Train loss: 1.8968\n","Train loss: 1.8525, Train acccuracy: 0.6075\n","Test loss: 1.9624, Test acccuracy: 0.4960\n","--- Epoch 48 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8699\n","Train batch: 200, Train loss: 1.8785\n","Train batch: 300, Train loss: 1.7700\n","Train batch: 400, Train loss: 1.8995\n","Train batch: 500, Train loss: 1.8163\n","Train batch: 600, Train loss: 1.8761\n","Train batch: 700, Train loss: 1.8448\n","Train loss: 1.8530, Train acccuracy: 0.6069\n","Test loss: 1.9620, Test acccuracy: 0.4980\n","--- Epoch 49 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8513\n","Train batch: 200, Train loss: 1.8226\n","Train batch: 300, Train loss: 1.8767\n","Train batch: 400, Train loss: 1.8249\n","Train batch: 500, Train loss: 1.9170\n","Train batch: 600, Train loss: 1.9268\n","Train batch: 700, Train loss: 1.8098\n","Train loss: 1.8522, Train acccuracy: 0.6079\n","Test loss: 1.9547, Test acccuracy: 0.5048\n","--- Epoch 50 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8286\n","Train batch: 200, Train loss: 1.8347\n","Train batch: 300, Train loss: 1.8565\n","Train batch: 400, Train loss: 1.8556\n","Train batch: 500, Train loss: 1.7620\n","Train batch: 600, Train loss: 1.8205\n","Train batch: 700, Train loss: 1.7384\n","Train loss: 1.8536, Train acccuracy: 0.6067\n","Test loss: 1.9510, Test acccuracy: 0.5084\n","--- Epoch 51 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7581\n","Train batch: 200, Train loss: 1.8293\n","Train batch: 300, Train loss: 1.9364\n","Train batch: 400, Train loss: 1.7967\n","Train batch: 500, Train loss: 1.7556\n","Train batch: 600, Train loss: 1.9227\n","Train batch: 700, Train loss: 1.8060\n","Train loss: 1.8490, Train acccuracy: 0.6109\n","Test loss: 1.9672, Test acccuracy: 0.4926\n","--- Epoch 52 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8936\n","Train batch: 200, Train loss: 1.8796\n","Train batch: 300, Train loss: 1.8834\n","Train batch: 400, Train loss: 1.8833\n","Train batch: 500, Train loss: 1.9053\n","Train batch: 600, Train loss: 1.7741\n","Train batch: 700, Train loss: 1.9506\n","Train loss: 1.8561, Train acccuracy: 0.6039\n","Test loss: 1.9599, Test acccuracy: 0.4986\n","--- Epoch 53 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8587\n","Train batch: 200, Train loss: 1.9395\n","Train batch: 300, Train loss: 1.8123\n","Train batch: 400, Train loss: 1.8825\n","Train batch: 500, Train loss: 1.8448\n","Train batch: 600, Train loss: 1.8125\n","Train batch: 700, Train loss: 1.8054\n","Train loss: 1.8571, Train acccuracy: 0.6030\n","Test loss: 1.9813, Test acccuracy: 0.4782\n","--- Epoch 54 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8349\n","Train batch: 200, Train loss: 1.8745\n","Train batch: 300, Train loss: 1.8423\n","Train batch: 400, Train loss: 1.8373\n","Train batch: 500, Train loss: 1.9430\n","Train batch: 600, Train loss: 1.9146\n","Train batch: 700, Train loss: 1.8287\n","Train loss: 1.8571, Train acccuracy: 0.6031\n","Test loss: 1.9630, Test acccuracy: 0.4959\n","--- Epoch 55 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7978\n","Train batch: 200, Train loss: 1.8305\n","Train batch: 300, Train loss: 1.8354\n","Train batch: 400, Train loss: 1.8159\n","Train batch: 500, Train loss: 1.9713\n","Train batch: 600, Train loss: 1.8674\n","Train batch: 700, Train loss: 1.7398\n","Train loss: 1.8513, Train acccuracy: 0.6090\n","Test loss: 1.9704, Test acccuracy: 0.4903\n","--- Epoch 56 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7587\n","Train batch: 200, Train loss: 1.9283\n","Train batch: 300, Train loss: 1.8514\n","Train batch: 400, Train loss: 1.9908\n","Train batch: 500, Train loss: 1.8395\n","Train batch: 600, Train loss: 1.8544\n","Train batch: 700, Train loss: 1.7418\n","Train loss: 1.8488, Train acccuracy: 0.6114\n","Test loss: 1.9599, Test acccuracy: 0.5000\n","--- Epoch 57 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8765\n","Train batch: 200, Train loss: 1.8720\n","Train batch: 300, Train loss: 1.9456\n","Train batch: 400, Train loss: 1.8798\n","Train batch: 500, Train loss: 1.9303\n","Train batch: 600, Train loss: 1.7877\n","Train batch: 700, Train loss: 1.8709\n","Train loss: 1.8503, Train acccuracy: 0.6093\n","Test loss: 1.9638, Test acccuracy: 0.4965\n","--- Epoch 58 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8505\n","Train batch: 200, Train loss: 1.7918\n","Train batch: 300, Train loss: 1.8121\n","Train batch: 400, Train loss: 1.9271\n","Train batch: 500, Train loss: 1.8056\n","Train batch: 600, Train loss: 1.8486\n","Train batch: 700, Train loss: 1.7329\n","Train loss: 1.8520, Train acccuracy: 0.6085\n","Test loss: 1.9556, Test acccuracy: 0.5029\n","--- Epoch 59 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8181\n","Train batch: 200, Train loss: 1.8518\n","Train batch: 300, Train loss: 1.8932\n","Train batch: 400, Train loss: 1.8184\n","Train batch: 500, Train loss: 1.7218\n","Train batch: 600, Train loss: 1.8879\n","Train batch: 700, Train loss: 1.8486\n","Train loss: 1.8476, Train acccuracy: 0.6127\n","Test loss: 1.9509, Test acccuracy: 0.5099\n","--- Epoch 60 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8203\n","Train batch: 200, Train loss: 1.7429\n","Train batch: 300, Train loss: 1.8789\n","Train batch: 400, Train loss: 1.8350\n","Train batch: 500, Train loss: 1.8969\n","Train batch: 600, Train loss: 1.8981\n","Train batch: 700, Train loss: 1.7940\n","Train loss: 1.8560, Train acccuracy: 0.6038\n","Test loss: 1.9611, Test acccuracy: 0.4986\n","--- Epoch 61 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7927\n","Train batch: 200, Train loss: 1.8082\n","Train batch: 300, Train loss: 1.7891\n","Train batch: 400, Train loss: 1.8212\n","Train batch: 500, Train loss: 1.9115\n","Train batch: 600, Train loss: 1.8664\n","Train batch: 700, Train loss: 1.7828\n","Train loss: 1.8539, Train acccuracy: 0.6063\n","Test loss: 1.9587, Test acccuracy: 0.5013\n","--- Epoch 62 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8336\n","Train batch: 200, Train loss: 1.7972\n","Train batch: 300, Train loss: 1.8052\n","Train batch: 400, Train loss: 1.8770\n","Train batch: 500, Train loss: 1.8665\n","Train batch: 600, Train loss: 1.9223\n","Train batch: 700, Train loss: 1.7720\n","Train loss: 1.8448, Train acccuracy: 0.6152\n","Test loss: 1.9563, Test acccuracy: 0.5047\n","--- Epoch 63 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8243\n","Train batch: 200, Train loss: 1.8560\n","Train batch: 300, Train loss: 1.8200\n","Train batch: 400, Train loss: 1.9304\n","Train batch: 500, Train loss: 1.8522\n","Train batch: 600, Train loss: 1.8537\n","Train batch: 700, Train loss: 1.8174\n","Train loss: 1.8522, Train acccuracy: 0.6084\n","Test loss: 1.9547, Test acccuracy: 0.5048\n","--- Epoch 64 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0288\n","Train batch: 200, Train loss: 1.7180\n","Train batch: 300, Train loss: 1.8820\n","Train batch: 400, Train loss: 1.8450\n","Train batch: 500, Train loss: 1.8043\n","Train batch: 600, Train loss: 1.8459\n","Train batch: 700, Train loss: 1.7901\n","Train loss: 1.8477, Train acccuracy: 0.6125\n","Test loss: 1.9565, Test acccuracy: 0.5039\n","--- Epoch 65 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8509\n","Train batch: 200, Train loss: 1.9142\n","Train batch: 300, Train loss: 1.9151\n","Train batch: 400, Train loss: 1.8505\n","Train batch: 500, Train loss: 1.9136\n","Train batch: 600, Train loss: 1.8647\n","Train batch: 700, Train loss: 1.7271\n","Train loss: 1.8469, Train acccuracy: 0.6134\n","Test loss: 1.9560, Test acccuracy: 0.5026\n","--- Epoch 66 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8360\n","Train batch: 200, Train loss: 1.8573\n","Train batch: 300, Train loss: 1.8551\n","Train batch: 400, Train loss: 1.8359\n","Train batch: 500, Train loss: 1.7911\n","Train batch: 600, Train loss: 1.8170\n","Train batch: 700, Train loss: 1.7895\n","Train loss: 1.8428, Train acccuracy: 0.6176\n","Test loss: 1.9645, Test acccuracy: 0.4955\n","--- Epoch 67 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7671\n","Train batch: 200, Train loss: 1.8725\n","Train batch: 300, Train loss: 1.8348\n","Train batch: 400, Train loss: 1.8250\n","Train batch: 500, Train loss: 1.8077\n","Train batch: 600, Train loss: 1.8101\n","Train batch: 700, Train loss: 1.8790\n","Train loss: 1.8470, Train acccuracy: 0.6136\n","Test loss: 1.9635, Test acccuracy: 0.4964\n","--- Epoch 68 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7597\n","Train batch: 200, Train loss: 1.8251\n","Train batch: 300, Train loss: 2.0269\n","Train batch: 400, Train loss: 1.8444\n","Train batch: 500, Train loss: 1.9057\n","Train batch: 600, Train loss: 1.7960\n","Train batch: 700, Train loss: 1.8189\n","Train loss: 1.8487, Train acccuracy: 0.6113\n","Test loss: 1.9602, Test acccuracy: 0.4990\n","--- Epoch 69 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8410\n","Train batch: 200, Train loss: 1.9942\n","Train batch: 300, Train loss: 1.9750\n","Train batch: 400, Train loss: 1.8491\n","Train batch: 500, Train loss: 1.7731\n","Train batch: 600, Train loss: 1.8605\n","Train batch: 700, Train loss: 1.8139\n","Train loss: 1.8473, Train acccuracy: 0.6129\n","Test loss: 1.9561, Test acccuracy: 0.5048\n","--- Epoch 70 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8815\n","Train batch: 200, Train loss: 1.7796\n","Train batch: 300, Train loss: 1.8978\n","Train batch: 400, Train loss: 1.7892\n","Train batch: 500, Train loss: 1.8689\n","Train batch: 600, Train loss: 1.9129\n","Train batch: 700, Train loss: 1.8805\n","Train loss: 1.8598, Train acccuracy: 0.6008\n","Test loss: 1.9689, Test acccuracy: 0.4922\n","--- Epoch 71 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8354\n","Train batch: 200, Train loss: 1.8244\n","Train batch: 300, Train loss: 1.8876\n","Train batch: 400, Train loss: 1.8807\n","Train batch: 500, Train loss: 1.8443\n","Train batch: 600, Train loss: 1.9100\n","Train batch: 700, Train loss: 1.7934\n","Train loss: 1.8555, Train acccuracy: 0.6048\n","Test loss: 1.9631, Test acccuracy: 0.4976\n","--- Epoch 72 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8058\n","Train batch: 200, Train loss: 1.8606\n","Train batch: 300, Train loss: 1.8674\n","Train batch: 400, Train loss: 1.7835\n","Train batch: 500, Train loss: 1.8356\n","Train batch: 600, Train loss: 1.8068\n","Train batch: 700, Train loss: 1.9692\n","Train loss: 1.8573, Train acccuracy: 0.6027\n","Test loss: 1.9679, Test acccuracy: 0.4917\n","--- Epoch 73 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7881\n","Train batch: 200, Train loss: 1.8990\n","Train batch: 300, Train loss: 1.8899\n","Train batch: 400, Train loss: 1.8048\n","Train batch: 500, Train loss: 1.8886\n","Train batch: 600, Train loss: 1.8155\n","Train batch: 700, Train loss: 1.7747\n","Train loss: 1.8568, Train acccuracy: 0.6037\n","Test loss: 1.9659, Test acccuracy: 0.4951\n","--- Epoch 74 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9262\n","Train batch: 200, Train loss: 1.9186\n","Train batch: 300, Train loss: 1.8062\n","Train batch: 400, Train loss: 1.8826\n","Train batch: 500, Train loss: 1.8175\n","Train batch: 600, Train loss: 1.8205\n","Train batch: 700, Train loss: 1.8515\n","Train loss: 1.8586, Train acccuracy: 0.6022\n","Test loss: 1.9671, Test acccuracy: 0.4936\n","--- Epoch 75 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8497\n","Train batch: 200, Train loss: 1.7920\n","Train batch: 300, Train loss: 1.7770\n","Train batch: 400, Train loss: 1.8014\n","Train batch: 500, Train loss: 1.8641\n","Train batch: 600, Train loss: 1.9309\n","Train batch: 700, Train loss: 1.8810\n","Train loss: 1.8558, Train acccuracy: 0.6048\n","Test loss: 1.9747, Test acccuracy: 0.4853\n","--- Epoch 76 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8971\n","Train batch: 200, Train loss: 1.9008\n","Train batch: 300, Train loss: 1.9155\n","Train batch: 400, Train loss: 1.8512\n","Train batch: 500, Train loss: 1.8593\n","Train batch: 600, Train loss: 1.7945\n","Train batch: 700, Train loss: 1.8165\n","Train loss: 1.8531, Train acccuracy: 0.6076\n","Test loss: 1.9662, Test acccuracy: 0.4943\n","--- Epoch 77 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8393\n","Train batch: 200, Train loss: 1.7425\n","Train batch: 300, Train loss: 1.8940\n","Train batch: 400, Train loss: 1.9451\n","Train batch: 500, Train loss: 1.8200\n","Train batch: 600, Train loss: 1.8681\n","Train batch: 700, Train loss: 1.8674\n","Train loss: 1.8549, Train acccuracy: 0.6056\n","Test loss: 1.9617, Test acccuracy: 0.4991\n","--- Epoch 78 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0228\n","Train batch: 200, Train loss: 1.9130\n","Train batch: 300, Train loss: 1.8827\n","Train batch: 400, Train loss: 1.8831\n","Train batch: 500, Train loss: 1.7807\n","Train batch: 600, Train loss: 1.8040\n","Train batch: 700, Train loss: 1.8167\n","Train loss: 1.8564, Train acccuracy: 0.6041\n","Test loss: 1.9671, Test acccuracy: 0.4934\n","--- Epoch 79 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8355\n","Train batch: 200, Train loss: 1.8482\n","Train batch: 300, Train loss: 1.8513\n","Train batch: 400, Train loss: 1.9126\n","Train batch: 500, Train loss: 1.8363\n","Train batch: 600, Train loss: 1.8976\n","Train batch: 700, Train loss: 1.8650\n","Train loss: 1.8576, Train acccuracy: 0.6030\n","Test loss: 1.9560, Test acccuracy: 0.5051\n","--- Epoch 80 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8488\n","Train batch: 200, Train loss: 1.8566\n","Train batch: 300, Train loss: 1.8215\n","Train batch: 400, Train loss: 1.8829\n","Train batch: 500, Train loss: 1.8256\n","Train batch: 600, Train loss: 1.8993\n","Train batch: 700, Train loss: 1.8986\n","Train loss: 1.8700, Train acccuracy: 0.5906\n","Test loss: 1.9639, Test acccuracy: 0.4955\n","--- Epoch 81 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8046\n","Train batch: 200, Train loss: 1.8672\n","Train batch: 300, Train loss: 1.8836\n","Train batch: 400, Train loss: 1.7440\n","Train batch: 500, Train loss: 1.8696\n","Train batch: 600, Train loss: 1.8664\n","Train batch: 700, Train loss: 1.7694\n","Train loss: 1.8598, Train acccuracy: 0.6008\n","Test loss: 1.9662, Test acccuracy: 0.4946\n","--- Epoch 82 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8044\n","Train batch: 200, Train loss: 1.8210\n","Train batch: 300, Train loss: 1.8688\n","Train batch: 400, Train loss: 1.9050\n","Train batch: 500, Train loss: 1.8976\n","Train batch: 600, Train loss: 1.9770\n","Train batch: 700, Train loss: 1.8058\n","Train loss: 1.8654, Train acccuracy: 0.5952\n","Test loss: 1.9567, Test acccuracy: 0.5049\n","--- Epoch 83 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8626\n","Train batch: 200, Train loss: 1.8049\n","Train batch: 300, Train loss: 1.8615\n","Train batch: 400, Train loss: 1.9003\n","Train batch: 500, Train loss: 1.9558\n","Train batch: 600, Train loss: 1.7733\n","Train batch: 700, Train loss: 1.9134\n","Train loss: 1.8662, Train acccuracy: 0.5948\n","Test loss: 1.9714, Test acccuracy: 0.4891\n","--- Epoch 84 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8362\n","Train batch: 200, Train loss: 1.7642\n","Train batch: 300, Train loss: 1.8819\n","Train batch: 400, Train loss: 1.9574\n","Train batch: 500, Train loss: 1.8673\n","Train batch: 600, Train loss: 1.7534\n","Train batch: 700, Train loss: 1.9165\n","Train loss: 1.8674, Train acccuracy: 0.5930\n","Test loss: 1.9626, Test acccuracy: 0.4980\n","--- Epoch 85 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8128\n","Train batch: 200, Train loss: 1.8379\n","Train batch: 300, Train loss: 1.9610\n","Train batch: 400, Train loss: 1.8660\n","Train batch: 500, Train loss: 1.9127\n","Train batch: 600, Train loss: 1.8113\n","Train batch: 700, Train loss: 1.8685\n","Train loss: 1.8623, Train acccuracy: 0.5981\n","Test loss: 1.9684, Test acccuracy: 0.4930\n","--- Epoch 86 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7551\n","Train batch: 200, Train loss: 1.9102\n","Train batch: 300, Train loss: 1.8784\n","Train batch: 400, Train loss: 1.8517\n","Train batch: 500, Train loss: 1.7893\n","Train batch: 600, Train loss: 1.7922\n","Train batch: 700, Train loss: 1.9033\n","Train loss: 1.8593, Train acccuracy: 0.6013\n","Test loss: 1.9678, Test acccuracy: 0.4930\n","--- Epoch 87 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9116\n","Train batch: 200, Train loss: 1.9961\n","Train batch: 300, Train loss: 1.8232\n","Train batch: 400, Train loss: 1.9605\n","Train batch: 500, Train loss: 1.9101\n","Train batch: 600, Train loss: 1.8510\n","Train batch: 700, Train loss: 1.9535\n","Train loss: 1.8619, Train acccuracy: 0.5984\n","Test loss: 1.9600, Test acccuracy: 0.5006\n","--- Epoch 88 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9640\n","Train batch: 200, Train loss: 1.9465\n","Train batch: 300, Train loss: 1.7574\n","Train batch: 400, Train loss: 1.9274\n","Train batch: 500, Train loss: 1.9605\n","Train batch: 600, Train loss: 1.9140\n","Train batch: 700, Train loss: 1.9553\n","Train loss: 1.8719, Train acccuracy: 0.5885\n","Test loss: 1.9621, Test acccuracy: 0.4996\n","--- Epoch 89 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9603\n","Train batch: 200, Train loss: 1.8048\n","Train batch: 300, Train loss: 1.9582\n","Train batch: 400, Train loss: 1.9575\n","Train batch: 500, Train loss: 1.9830\n","Train batch: 600, Train loss: 1.8673\n","Train batch: 700, Train loss: 1.9297\n","Train loss: 1.8693, Train acccuracy: 0.5912\n","Test loss: 1.9793, Test acccuracy: 0.4809\n","--- Epoch 90 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 1.7681\n","Train batch: 300, Train loss: 1.8526\n","Train batch: 400, Train loss: 1.9611\n","Train batch: 500, Train loss: 1.8970\n","Train batch: 600, Train loss: 1.8003\n","Train batch: 700, Train loss: 1.8530\n","Train loss: 1.8789, Train acccuracy: 0.5816\n","Test loss: 1.9635, Test acccuracy: 0.4970\n","--- Epoch 91 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8676\n","Train batch: 200, Train loss: 1.8284\n","Train batch: 300, Train loss: 1.8451\n","Train batch: 400, Train loss: 1.8029\n","Train batch: 500, Train loss: 1.8048\n","Train batch: 600, Train loss: 1.8667\n","Train batch: 700, Train loss: 1.8513\n","Train loss: 1.8702, Train acccuracy: 0.5905\n","Test loss: 1.9695, Test acccuracy: 0.4913\n","--- Epoch 92 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8356\n","Train batch: 200, Train loss: 1.8059\n","Train batch: 300, Train loss: 1.9143\n","Train batch: 400, Train loss: 1.8209\n","Train batch: 500, Train loss: 1.8481\n","Train batch: 600, Train loss: 1.9781\n","Train batch: 700, Train loss: 1.8986\n","Train loss: 1.8693, Train acccuracy: 0.5914\n","Test loss: 1.9726, Test acccuracy: 0.4886\n","--- Epoch 93 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7888\n","Train batch: 200, Train loss: 1.8774\n","Train batch: 300, Train loss: 1.7494\n","Train batch: 400, Train loss: 1.9143\n","Train batch: 500, Train loss: 1.8352\n","Train batch: 600, Train loss: 1.8671\n","Train batch: 700, Train loss: 1.8911\n","Train loss: 1.8736, Train acccuracy: 0.5875\n","Test loss: 1.9661, Test acccuracy: 0.4940\n","--- Epoch 94 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8826\n","Train batch: 200, Train loss: 1.8043\n","Train batch: 300, Train loss: 1.9463\n","Train batch: 400, Train loss: 1.8244\n","Train batch: 500, Train loss: 1.9430\n","Train batch: 600, Train loss: 1.9948\n","Train batch: 700, Train loss: 1.8349\n","Train loss: 1.8912, Train acccuracy: 0.5693\n","Test loss: 1.9700, Test acccuracy: 0.4896\n","--- Epoch 95 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8662\n","Train batch: 200, Train loss: 1.8838\n","Train batch: 300, Train loss: 1.8671\n","Train batch: 400, Train loss: 1.7587\n","Train batch: 500, Train loss: 1.8351\n","Train batch: 600, Train loss: 1.8987\n","Train batch: 700, Train loss: 1.8067\n","Train loss: 1.8778, Train acccuracy: 0.5827\n","Test loss: 1.9751, Test acccuracy: 0.4868\n","--- Epoch 96 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9296\n","Train batch: 200, Train loss: 1.9014\n","Train batch: 300, Train loss: 1.8725\n","Train batch: 400, Train loss: 1.8517\n","Train batch: 500, Train loss: 1.8536\n","Train batch: 600, Train loss: 1.8049\n","Train batch: 700, Train loss: 1.8830\n","Train loss: 1.8805, Train acccuracy: 0.5798\n","Test loss: 2.0028, Test acccuracy: 0.4586\n","--- Epoch 97 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7579\n","Train batch: 200, Train loss: 1.8205\n","Train batch: 300, Train loss: 1.9410\n","Train batch: 400, Train loss: 1.9135\n","Train batch: 500, Train loss: 1.8262\n","Train batch: 600, Train loss: 1.8766\n","Train batch: 700, Train loss: 1.8258\n","Train loss: 1.8850, Train acccuracy: 0.5757\n","Test loss: 1.9727, Test acccuracy: 0.4892\n","--- Epoch 98 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8931\n","Train batch: 200, Train loss: 2.0184\n","Train batch: 300, Train loss: 1.9306\n","Train batch: 400, Train loss: 2.0385\n","Train batch: 500, Train loss: 1.8829\n","Train batch: 600, Train loss: 1.8473\n","Train batch: 700, Train loss: 1.8361\n","Train loss: 1.8975, Train acccuracy: 0.5632\n","Test loss: 1.9761, Test acccuracy: 0.4844\n","--- Epoch 99 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8517\n","Train batch: 200, Train loss: 1.8050\n","Train batch: 300, Train loss: 1.8830\n","Train batch: 400, Train loss: 1.9092\n","Train batch: 500, Train loss: 1.9284\n","Train batch: 600, Train loss: 1.8621\n","Train batch: 700, Train loss: 1.9705\n","Train loss: 1.8857, Train acccuracy: 0.5748\n","Test loss: 1.9718, Test acccuracy: 0.4891\n","--- Epoch 100 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9611\n","Train batch: 200, Train loss: 1.8830\n","Train batch: 300, Train loss: 1.8984\n","Train batch: 400, Train loss: 1.8628\n","Train batch: 500, Train loss: 1.9449\n","Train batch: 600, Train loss: 1.8982\n","Train batch: 700, Train loss: 1.7562\n","Train loss: 1.8818, Train acccuracy: 0.5790\n","Test loss: 1.9786, Test acccuracy: 0.4819\n","--- Epoch 101 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7734\n","Train batch: 200, Train loss: 1.8965\n","Train batch: 300, Train loss: 1.9468\n","Train batch: 400, Train loss: 2.0235\n","Train batch: 500, Train loss: 1.8518\n","Train batch: 600, Train loss: 1.9299\n","Train batch: 700, Train loss: 1.7736\n","Train loss: 1.8880, Train acccuracy: 0.5728\n","Test loss: 1.9781, Test acccuracy: 0.4823\n","--- Epoch 102 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8291\n","Train batch: 200, Train loss: 1.8406\n","Train batch: 300, Train loss: 1.8823\n","Train batch: 400, Train loss: 1.8524\n","Train batch: 500, Train loss: 1.8197\n","Train batch: 600, Train loss: 1.8830\n","Train batch: 700, Train loss: 1.9455\n","Train loss: 1.8951, Train acccuracy: 0.5657\n","Test loss: 1.9915, Test acccuracy: 0.4699\n","--- Epoch 103 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9142\n","Train batch: 200, Train loss: 1.8986\n","Train batch: 300, Train loss: 1.7935\n","Train batch: 400, Train loss: 1.8762\n","Train batch: 500, Train loss: 1.8049\n","Train batch: 600, Train loss: 1.9765\n","Train batch: 700, Train loss: 1.8306\n","Train loss: 1.8980, Train acccuracy: 0.5627\n","Test loss: 1.9751, Test acccuracy: 0.4844\n","--- Epoch 104 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 1.8674\n","Train batch: 300, Train loss: 1.9138\n","Train batch: 400, Train loss: 1.9143\n","Train batch: 500, Train loss: 1.8404\n","Train batch: 600, Train loss: 1.8205\n","Train batch: 700, Train loss: 1.8849\n","Train loss: 1.9004, Train acccuracy: 0.5604\n","Test loss: 1.9694, Test acccuracy: 0.4925\n","--- Epoch 105 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8360\n","Train batch: 200, Train loss: 1.9298\n","Train batch: 300, Train loss: 1.8518\n","Train batch: 400, Train loss: 1.8518\n","Train batch: 500, Train loss: 1.8674\n","Train batch: 600, Train loss: 1.8205\n","Train batch: 700, Train loss: 1.8690\n","Train loss: 1.8968, Train acccuracy: 0.5638\n","Test loss: 1.9887, Test acccuracy: 0.4723\n","--- Epoch 106 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8356\n","Train batch: 200, Train loss: 1.9612\n","Train batch: 300, Train loss: 1.9295\n","Train batch: 400, Train loss: 2.0393\n","Train batch: 500, Train loss: 1.8516\n","Train batch: 600, Train loss: 1.7854\n","Train batch: 700, Train loss: 1.8518\n","Train loss: 1.9072, Train acccuracy: 0.5536\n","Test loss: 1.9746, Test acccuracy: 0.4862\n","--- Epoch 107 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7603\n","Train batch: 200, Train loss: 1.9134\n","Train batch: 300, Train loss: 1.6997\n","Train batch: 400, Train loss: 1.9752\n","Train batch: 500, Train loss: 1.9143\n","Train batch: 600, Train loss: 1.9294\n","Train batch: 700, Train loss: 1.9454\n","Train loss: 1.8905, Train acccuracy: 0.5704\n","Test loss: 1.9804, Test acccuracy: 0.4812\n","--- Epoch 108 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8205\n","Train batch: 200, Train loss: 2.0078\n","Train batch: 300, Train loss: 1.8679\n","Train batch: 400, Train loss: 1.9298\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 1.8205\n","Train batch: 700, Train loss: 1.9296\n","Train loss: 1.8942, Train acccuracy: 0.5669\n","Test loss: 1.9799, Test acccuracy: 0.4808\n","--- Epoch 109 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8518\n","Train batch: 200, Train loss: 1.8674\n","Train batch: 300, Train loss: 1.9143\n","Train batch: 400, Train loss: 1.9312\n","Train batch: 500, Train loss: 1.8881\n","Train batch: 600, Train loss: 1.8441\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 1.9028, Train acccuracy: 0.5580\n","Test loss: 1.9836, Test acccuracy: 0.4768\n","--- Epoch 110 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7736\n","Train batch: 200, Train loss: 1.8518\n","Train batch: 300, Train loss: 1.9450\n","Train batch: 400, Train loss: 1.9479\n","Train batch: 500, Train loss: 2.0379\n","Train batch: 600, Train loss: 1.8830\n","Train batch: 700, Train loss: 1.9299\n","Train loss: 1.9185, Train acccuracy: 0.5421\n","Test loss: 1.9850, Test acccuracy: 0.4749\n","--- Epoch 111 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8677\n","Train batch: 200, Train loss: 1.7678\n","Train batch: 300, Train loss: 1.9920\n","Train batch: 400, Train loss: 1.9455\n","Train batch: 500, Train loss: 1.8394\n","Train batch: 600, Train loss: 1.8517\n","Train batch: 700, Train loss: 1.9019\n","Train loss: 1.8974, Train acccuracy: 0.5634\n","Test loss: 1.9802, Test acccuracy: 0.4823\n","--- Epoch 112 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9450\n","Train batch: 200, Train loss: 1.9455\n","Train batch: 300, Train loss: 1.9299\n","Train batch: 400, Train loss: 1.9932\n","Train batch: 500, Train loss: 1.9295\n","Train batch: 600, Train loss: 1.8830\n","Train batch: 700, Train loss: 1.8832\n","Train loss: 1.9007, Train acccuracy: 0.5602\n","Test loss: 1.9847, Test acccuracy: 0.4759\n","--- Epoch 113 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9754\n","Train batch: 200, Train loss: 1.8985\n","Train batch: 300, Train loss: 1.9001\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.9782\n","Train batch: 700, Train loss: 1.9499\n","Train loss: 1.9056, Train acccuracy: 0.5552\n","Test loss: 1.9877, Test acccuracy: 0.4741\n","--- Epoch 114 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7589\n","Train batch: 200, Train loss: 1.9298\n","Train batch: 300, Train loss: 1.9469\n","Train batch: 400, Train loss: 1.8674\n","Train batch: 500, Train loss: 1.9142\n","Train batch: 600, Train loss: 1.9002\n","Train batch: 700, Train loss: 1.8831\n","Train loss: 1.9045, Train acccuracy: 0.5565\n","Test loss: 1.9813, Test acccuracy: 0.4805\n","--- Epoch 115 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0384\n","Train batch: 200, Train loss: 1.9298\n","Train batch: 300, Train loss: 1.9098\n","Train batch: 400, Train loss: 1.8849\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 1.9447\n","Train batch: 700, Train loss: 1.9611\n","Train loss: 1.9133, Train acccuracy: 0.5474\n","Test loss: 2.0154, Test acccuracy: 0.4462\n","--- Epoch 116 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9606\n","Train batch: 200, Train loss: 1.9611\n","Train batch: 300, Train loss: 2.0152\n","Train batch: 400, Train loss: 1.9447\n","Train batch: 500, Train loss: 1.8830\n","Train batch: 600, Train loss: 1.8986\n","Train batch: 700, Train loss: 1.9614\n","Train loss: 1.9339, Train acccuracy: 0.5269\n","Test loss: 1.9953, Test acccuracy: 0.4667\n","--- Epoch 117 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9005\n","Train batch: 200, Train loss: 1.8201\n","Train batch: 300, Train loss: 1.9766\n","Train batch: 400, Train loss: 2.0062\n","Train batch: 500, Train loss: 1.8867\n","Train batch: 600, Train loss: 1.9456\n","Train batch: 700, Train loss: 1.9452\n","Train loss: 1.9244, Train acccuracy: 0.5368\n","Test loss: 2.0103, Test acccuracy: 0.4511\n","--- Epoch 118 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 1.8361\n","Train batch: 300, Train loss: 1.9297\n","Train batch: 400, Train loss: 1.9923\n","Train batch: 500, Train loss: 1.8979\n","Train batch: 600, Train loss: 2.0075\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 1.9245, Train acccuracy: 0.5363\n","Test loss: 1.9973, Test acccuracy: 0.4638\n","--- Epoch 119 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9610\n","Train batch: 200, Train loss: 1.9455\n","Train batch: 300, Train loss: 1.8987\n","Train batch: 400, Train loss: 1.9611\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.8361\n","Train batch: 700, Train loss: 1.9611\n","Train loss: 1.9262, Train acccuracy: 0.5347\n","Test loss: 1.9838, Test acccuracy: 0.4781\n","--- Epoch 120 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9537\n","Train batch: 200, Train loss: 1.8830\n","Train batch: 300, Train loss: 1.9606\n","Train batch: 400, Train loss: 1.9297\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 1.7750\n","Train loss: 1.9278, Train acccuracy: 0.5330\n","Test loss: 1.9986, Test acccuracy: 0.4621\n","--- Epoch 121 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9612\n","Train batch: 200, Train loss: 1.8830\n","Train batch: 300, Train loss: 1.8830\n","Train batch: 400, Train loss: 1.8987\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 1.9612\n","Train batch: 700, Train loss: 1.9768\n","Train loss: 1.9155, Train acccuracy: 0.5455\n","Test loss: 1.9860, Test acccuracy: 0.4733\n","--- Epoch 122 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9609\n","Train batch: 200, Train loss: 1.9299\n","Train batch: 300, Train loss: 2.0235\n","Train batch: 400, Train loss: 2.0236\n","Train batch: 500, Train loss: 1.8841\n","Train batch: 600, Train loss: 1.8986\n","Train batch: 700, Train loss: 1.8759\n","Train loss: 1.9317, Train acccuracy: 0.5291\n","Test loss: 2.0101, Test acccuracy: 0.4519\n","--- Epoch 123 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9299\n","Train batch: 200, Train loss: 1.9751\n","Train batch: 300, Train loss: 1.8986\n","Train batch: 400, Train loss: 1.9616\n","Train batch: 500, Train loss: 1.7867\n","Train batch: 600, Train loss: 1.9557\n","Train batch: 700, Train loss: 2.0236\n","Train loss: 1.9384, Train acccuracy: 0.5223\n","Test loss: 2.0197, Test acccuracy: 0.4419\n","--- Epoch 124 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9299\n","Train batch: 200, Train loss: 1.8674\n","Train batch: 300, Train loss: 1.8671\n","Train batch: 400, Train loss: 1.8820\n","Train batch: 500, Train loss: 1.9612\n","Train batch: 600, Train loss: 1.9316\n","Train batch: 700, Train loss: 2.0540\n","Train loss: 1.9394, Train acccuracy: 0.5214\n","Test loss: 2.0129, Test acccuracy: 0.4491\n","--- Epoch 125 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9143\n","Train batch: 200, Train loss: 1.9919\n","Train batch: 300, Train loss: 1.9611\n","Train batch: 400, Train loss: 1.8987\n","Train batch: 500, Train loss: 1.8361\n","Train batch: 600, Train loss: 1.9759\n","Train batch: 700, Train loss: 1.9764\n","Train loss: 1.9421, Train acccuracy: 0.5188\n","Test loss: 2.0003, Test acccuracy: 0.4614\n","--- Epoch 126 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9143\n","Train batch: 200, Train loss: 1.9470\n","Train batch: 300, Train loss: 2.0703\n","Train batch: 400, Train loss: 2.0706\n","Train batch: 500, Train loss: 2.0698\n","Train batch: 600, Train loss: 1.8830\n","Train batch: 700, Train loss: 2.0236\n","Train loss: 1.9527, Train acccuracy: 0.5082\n","Test loss: 1.9946, Test acccuracy: 0.4665\n","--- Epoch 127 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9299\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 1.8832\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 1.9297\n","Train batch: 700, Train loss: 1.9299\n","Train loss: 1.9524, Train acccuracy: 0.5087\n","Test loss: 2.0087, Test acccuracy: 0.4512\n","--- Epoch 128 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9143\n","Train batch: 200, Train loss: 2.0543\n","Train batch: 300, Train loss: 1.8203\n","Train batch: 400, Train loss: 1.9610\n","Train batch: 500, Train loss: 1.9186\n","Train batch: 600, Train loss: 1.8518\n","Train batch: 700, Train loss: 1.9610\n","Train loss: 1.9430, Train acccuracy: 0.5180\n","Test loss: 2.0060, Test acccuracy: 0.4543\n","--- Epoch 129 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8861\n","Train batch: 200, Train loss: 2.0390\n","Train batch: 300, Train loss: 1.9299\n","Train batch: 400, Train loss: 1.9140\n","Train batch: 500, Train loss: 1.8674\n","Train batch: 600, Train loss: 2.0066\n","Train batch: 700, Train loss: 1.9308\n","Train loss: 1.9533, Train acccuracy: 0.5080\n","Test loss: 2.0026, Test acccuracy: 0.4572\n","--- Epoch 130 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9647\n","Train batch: 200, Train loss: 1.8669\n","Train batch: 300, Train loss: 1.9611\n","Train batch: 400, Train loss: 1.9454\n","Train batch: 500, Train loss: 2.1643\n","Train batch: 600, Train loss: 2.0106\n","Train batch: 700, Train loss: 1.8986\n","Train loss: 1.9493, Train acccuracy: 0.5116\n","Test loss: 1.9967, Test acccuracy: 0.4641\n","--- Epoch 131 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9148\n","Train batch: 200, Train loss: 2.0545\n","Train batch: 300, Train loss: 1.9294\n","Train batch: 400, Train loss: 1.8674\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 1.9299\n","Train batch: 700, Train loss: 1.9299\n","Train loss: 1.9466, Train acccuracy: 0.5144\n","Test loss: 2.0004, Test acccuracy: 0.4603\n","--- Epoch 132 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8830\n","Train batch: 200, Train loss: 1.8319\n","Train batch: 300, Train loss: 1.8518\n","Train batch: 400, Train loss: 2.0389\n","Train batch: 500, Train loss: 2.0391\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 2.0548\n","Train loss: 1.9434, Train acccuracy: 0.5179\n","Test loss: 2.0377, Test acccuracy: 0.4246\n","--- Epoch 133 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8683\n","Train batch: 200, Train loss: 1.8518\n","Train batch: 300, Train loss: 1.9608\n","Train batch: 400, Train loss: 1.8986\n","Train batch: 500, Train loss: 2.0569\n","Train batch: 600, Train loss: 1.8049\n","Train batch: 700, Train loss: 1.9137\n","Train loss: 1.9528, Train acccuracy: 0.5082\n","Test loss: 1.9906, Test acccuracy: 0.4696\n","--- Epoch 134 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9305\n","Train batch: 200, Train loss: 1.8362\n","Train batch: 300, Train loss: 1.9455\n","Train batch: 400, Train loss: 1.9297\n","Train batch: 500, Train loss: 1.9706\n","Train batch: 600, Train loss: 2.0239\n","Train batch: 700, Train loss: 1.8361\n","Train loss: 1.9538, Train acccuracy: 0.5070\n","Test loss: 2.0111, Test acccuracy: 0.4498\n","--- Epoch 135 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9768\n","Train batch: 200, Train loss: 1.8825\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 1.9611\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 1.9295\n","Train loss: 1.9514, Train acccuracy: 0.5095\n","Test loss: 2.0299, Test acccuracy: 0.4318\n","--- Epoch 136 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9923\n","Train batch: 200, Train loss: 1.9563\n","Train batch: 300, Train loss: 2.0393\n","Train batch: 400, Train loss: 1.9456\n","Train batch: 500, Train loss: 1.7893\n","Train batch: 600, Train loss: 1.9613\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 1.9715, Train acccuracy: 0.4894\n","Test loss: 2.0149, Test acccuracy: 0.4463\n","--- Epoch 137 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9142\n","Train batch: 200, Train loss: 1.9299\n","Train batch: 300, Train loss: 1.9455\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 1.9679\n","Train batch: 700, Train loss: 1.9767\n","Train loss: 1.9640, Train acccuracy: 0.4973\n","Test loss: 2.0137, Test acccuracy: 0.4484\n","--- Epoch 138 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9299\n","Train batch: 200, Train loss: 1.8516\n","Train batch: 300, Train loss: 1.9394\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 1.9611\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 1.9612\n","Train loss: 1.9520, Train acccuracy: 0.5088\n","Test loss: 2.0055, Test acccuracy: 0.4558\n","--- Epoch 139 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9611\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.0393\n","Train batch: 400, Train loss: 1.8987\n","Train batch: 500, Train loss: 1.7737\n","Train batch: 600, Train loss: 1.9762\n","Train batch: 700, Train loss: 1.8205\n","Train loss: 1.9483, Train acccuracy: 0.5128\n","Test loss: 2.0223, Test acccuracy: 0.4380\n","--- Epoch 140 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8830\n","Train batch: 200, Train loss: 1.9494\n","Train batch: 300, Train loss: 1.9611\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 1.9975\n","Train batch: 700, Train loss: 2.0236\n","Train loss: 1.9842, Train acccuracy: 0.4768\n","Test loss: 2.0494, Test acccuracy: 0.4116\n","--- Epoch 141 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9455\n","Train batch: 200, Train loss: 1.9768\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 2.0256\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.9299\n","Train batch: 700, Train loss: 1.9455\n","Train loss: 1.9882, Train acccuracy: 0.4729\n","Test loss: 2.0211, Test acccuracy: 0.4389\n","--- Epoch 142 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0079\n","Train batch: 200, Train loss: 1.9612\n","Train batch: 300, Train loss: 1.9916\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 1.9260\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.0388\n","Train loss: 1.9997, Train acccuracy: 0.4616\n","Test loss: 2.0389, Test acccuracy: 0.4223\n","--- Epoch 143 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0236\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 1.9905\n","Train batch: 400, Train loss: 1.9612\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 1.9143\n","Train batch: 700, Train loss: 1.9143\n","Train loss: 1.9820, Train acccuracy: 0.4791\n","Test loss: 2.0184, Test acccuracy: 0.4426\n","--- Epoch 144 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 1.9455\n","Train batch: 300, Train loss: 1.9299\n","Train batch: 400, Train loss: 1.7737\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 1.9886\n","Train batch: 700, Train loss: 1.9741\n","Train loss: 1.9788, Train acccuracy: 0.4823\n","Test loss: 2.0413, Test acccuracy: 0.4191\n","--- Epoch 145 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9924\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 1.9295\n","Train batch: 500, Train loss: 1.8674\n","Train batch: 600, Train loss: 1.9612\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 1.9678, Train acccuracy: 0.4933\n","Test loss: 2.0183, Test acccuracy: 0.4424\n","--- Epoch 146 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.7892\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.0236\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 2.0476\n","Train batch: 600, Train loss: 1.9764\n","Train batch: 700, Train loss: 2.0694\n","Train loss: 1.9829, Train acccuracy: 0.4782\n","Test loss: 2.0251, Test acccuracy: 0.4358\n","--- Epoch 147 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8673\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 1.9455\n","Train batch: 500, Train loss: 1.9770\n","Train batch: 600, Train loss: 2.0729\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 1.9774, Train acccuracy: 0.4838\n","Test loss: 2.0265, Test acccuracy: 0.4348\n","--- Epoch 148 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 1.9139\n","Train batch: 400, Train loss: 1.9713\n","Train batch: 500, Train loss: 1.8200\n","Train batch: 600, Train loss: 1.8987\n","Train batch: 700, Train loss: 1.9629\n","Train loss: 1.9578, Train acccuracy: 0.5031\n","Test loss: 2.0032, Test acccuracy: 0.4576\n","--- Epoch 149 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9768\n","Train batch: 200, Train loss: 1.8361\n","Train batch: 300, Train loss: 1.8987\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 2.0352\n","Train batch: 700, Train loss: 1.8518\n","Train loss: 1.9606, Train acccuracy: 0.5006\n","Test loss: 2.0136, Test acccuracy: 0.4473\n","--- Epoch 150 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 1.9455\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 1.9611\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 1.9932\n","Train batch: 700, Train loss: 2.0393\n","Train loss: 1.9710, Train acccuracy: 0.4903\n","Test loss: 2.0299, Test acccuracy: 0.4321\n","--- Epoch 151 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9110\n","Train batch: 200, Train loss: 1.9612\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 1.9455\n","Train batch: 500, Train loss: 2.0859\n","Train batch: 600, Train loss: 1.9870\n","Train batch: 700, Train loss: 1.9455\n","Train loss: 1.9879, Train acccuracy: 0.4733\n","Test loss: 2.0430, Test acccuracy: 0.4181\n","--- Epoch 152 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9519\n","Train batch: 200, Train loss: 1.8518\n","Train batch: 300, Train loss: 1.9623\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 1.9143\n","Train loss: 1.9823, Train acccuracy: 0.4788\n","Test loss: 2.0197, Test acccuracy: 0.4423\n","--- Epoch 153 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9299\n","Train batch: 200, Train loss: 2.0076\n","Train batch: 300, Train loss: 2.0236\n","Train batch: 400, Train loss: 1.9143\n","Train batch: 500, Train loss: 1.9455\n","Train batch: 600, Train loss: 2.0510\n","Train batch: 700, Train loss: 2.0238\n","Train loss: 1.9772, Train acccuracy: 0.4837\n","Test loss: 2.0178, Test acccuracy: 0.4437\n","--- Epoch 154 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0393\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 1.8987\n","Train batch: 600, Train loss: 2.0237\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 1.9775, Train acccuracy: 0.4838\n","Test loss: 2.0289, Test acccuracy: 0.4322\n","--- Epoch 155 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8518\n","Train batch: 200, Train loss: 1.9770\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 2.0235\n","Train loss: 1.9779, Train acccuracy: 0.4831\n","Test loss: 2.0280, Test acccuracy: 0.4327\n","--- Epoch 156 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9924\n","Train batch: 200, Train loss: 2.1325\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.7893\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 1.9906, Train acccuracy: 0.4706\n","Test loss: 2.0175, Test acccuracy: 0.4436\n","--- Epoch 157 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9923\n","Train batch: 200, Train loss: 1.9299\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 1.8984\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 2.0236\n","Train batch: 700, Train loss: 2.0384\n","Train loss: 1.9727, Train acccuracy: 0.4882\n","Test loss: 2.0321, Test acccuracy: 0.4302\n","--- Epoch 158 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9612\n","Train batch: 200, Train loss: 1.9768\n","Train batch: 300, Train loss: 1.9763\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 1.9612\n","Train batch: 600, Train loss: 1.9299\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 1.9855, Train acccuracy: 0.4755\n","Test loss: 2.0201, Test acccuracy: 0.4411\n","--- Epoch 159 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 1.8674\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 1.9455\n","Train batch: 700, Train loss: 1.9455\n","Train loss: 1.9815, Train acccuracy: 0.4796\n","Test loss: 2.0351, Test acccuracy: 0.4256\n","--- Epoch 160 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8987\n","Train batch: 200, Train loss: 1.9299\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 2.0705\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 1.9814, Train acccuracy: 0.4797\n","Test loss: 2.0275, Test acccuracy: 0.4338\n","--- Epoch 161 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.0075\n","Train batch: 300, Train loss: 1.9919\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 2.0705\n","Train batch: 600, Train loss: 1.9455\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0049, Train acccuracy: 0.4562\n","Test loss: 2.0430, Test acccuracy: 0.4182\n","--- Epoch 162 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 1.9295\n","Train batch: 400, Train loss: 1.9923\n","Train batch: 500, Train loss: 2.1012\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 2.0081\n","Train loss: 1.9975, Train acccuracy: 0.4637\n","Test loss: 2.0602, Test acccuracy: 0.4005\n","--- Epoch 163 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9143\n","Train batch: 200, Train loss: 2.0236\n","Train batch: 300, Train loss: 2.0234\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 1.9611\n","Train batch: 700, Train loss: 1.8830\n","Train loss: 1.9983, Train acccuracy: 0.4630\n","Test loss: 2.0228, Test acccuracy: 0.4383\n","--- Epoch 164 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9612\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 1.8518\n","Train batch: 400, Train loss: 1.9793\n","Train batch: 500, Train loss: 1.9296\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 1.9774, Train acccuracy: 0.4839\n","Test loss: 2.0312, Test acccuracy: 0.4306\n","--- Epoch 165 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0393\n","Train batch: 200, Train loss: 1.9638\n","Train batch: 300, Train loss: 1.8987\n","Train batch: 400, Train loss: 2.0861\n","Train batch: 500, Train loss: 1.9612\n","Train batch: 600, Train loss: 2.0393\n","Train batch: 700, Train loss: 1.9494\n","Train loss: 2.0004, Train acccuracy: 0.4606\n","Test loss: 2.0491, Test acccuracy: 0.4113\n","--- Epoch 166 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 2.0861\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.1014\n","Train batch: 700, Train loss: 1.9762\n","Train loss: 2.0440, Train acccuracy: 0.4173\n","Test loss: 2.0638, Test acccuracy: 0.3962\n","--- Epoch 167 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9924\n","Train batch: 200, Train loss: 2.0859\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 2.0393\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 1.9768\n","Train loss: 2.0189, Train acccuracy: 0.4422\n","Test loss: 2.0387, Test acccuracy: 0.4225\n","--- Epoch 168 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0393\n","Train batch: 200, Train loss: 1.9612\n","Train batch: 300, Train loss: 1.9612\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 2.1329\n","Train loss: 2.0135, Train acccuracy: 0.4478\n","Test loss: 2.0539, Test acccuracy: 0.4077\n","--- Epoch 169 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 1.9767\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.8987\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 2.0196, Train acccuracy: 0.4416\n","Test loss: 2.0277, Test acccuracy: 0.4334\n","--- Epoch 170 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1330\n","Train batch: 200, Train loss: 2.1330\n","Train batch: 300, Train loss: 1.9143\n","Train batch: 400, Train loss: 1.9768\n","Train batch: 500, Train loss: 2.0701\n","Train batch: 600, Train loss: 1.9456\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 1.9905, Train acccuracy: 0.4708\n","Test loss: 2.0320, Test acccuracy: 0.4286\n","--- Epoch 171 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0232\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 1.8987\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 1.9612\n","Train loss: 1.9927, Train acccuracy: 0.4685\n","Test loss: 2.0438, Test acccuracy: 0.4172\n","--- Epoch 172 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.0393\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 1.9162\n","Train batch: 600, Train loss: 2.0393\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 2.0040, Train acccuracy: 0.4570\n","Test loss: 2.0357, Test acccuracy: 0.4253\n","--- Epoch 173 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0235\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 1.9768\n","Train batch: 500, Train loss: 1.9455\n","Train batch: 600, Train loss: 2.0393\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0163, Train acccuracy: 0.4449\n","Test loss: 2.0430, Test acccuracy: 0.4170\n","--- Epoch 174 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 2.1174\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 1.9455\n","Train loss: 2.0053, Train acccuracy: 0.4556\n","Test loss: 2.0364, Test acccuracy: 0.4244\n","--- Epoch 175 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1161\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 2.0855\n","Train batch: 500, Train loss: 1.9610\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 2.0702\n","Train loss: 1.9956, Train acccuracy: 0.4655\n","Test loss: 2.0245, Test acccuracy: 0.4373\n","--- Epoch 176 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0856\n","Train batch: 200, Train loss: 1.9299\n","Train batch: 300, Train loss: 1.9612\n","Train batch: 400, Train loss: 1.9612\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 1.8362\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 2.0076, Train acccuracy: 0.4535\n","Test loss: 2.0532, Test acccuracy: 0.4077\n","--- Epoch 177 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9924\n","Train batch: 200, Train loss: 2.1174\n","Train batch: 300, Train loss: 2.1486\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 2.0862\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 2.0862\n","Train loss: 2.0345, Train acccuracy: 0.4264\n","Test loss: 2.0503, Test acccuracy: 0.4103\n","--- Epoch 178 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 1.9612\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 1.9142\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 2.0087, Train acccuracy: 0.4523\n","Test loss: 2.0438, Test acccuracy: 0.4184\n","--- Epoch 179 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 1.9612\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.9612\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0080, Train acccuracy: 0.4532\n","Test loss: 2.0393, Test acccuracy: 0.4224\n","--- Epoch 180 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 1.9768\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.1018\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 2.0314, Train acccuracy: 0.4299\n","Test loss: 2.0668, Test acccuracy: 0.3950\n","--- Epoch 181 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1330\n","Train batch: 200, Train loss: 2.1018\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 2.0405, Train acccuracy: 0.4205\n","Test loss: 2.0623, Test acccuracy: 0.3976\n","--- Epoch 182 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0233\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.0393\n","Train batch: 400, Train loss: 1.9954\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 2.0296, Train acccuracy: 0.4317\n","Test loss: 2.0455, Test acccuracy: 0.4154\n","--- Epoch 183 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9455\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 2.0233\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 2.0277, Train acccuracy: 0.4331\n","Test loss: 2.0648, Test acccuracy: 0.3966\n","--- Epoch 184 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9768\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 1.8830\n","Train batch: 400, Train loss: 1.9768\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 2.0862\n","Train batch: 700, Train loss: 2.0393\n","Train loss: 2.0224, Train acccuracy: 0.4388\n","Test loss: 2.0489, Test acccuracy: 0.4129\n","--- Epoch 185 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.1487\n","Train batch: 400, Train loss: 2.0543\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 1.9768\n","Train loss: 2.0344, Train acccuracy: 0.4269\n","Test loss: 2.0668, Test acccuracy: 0.3958\n","--- Epoch 186 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1330\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 1.9612\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 1.9143\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 2.0311, Train acccuracy: 0.4299\n","Test loss: 2.0419, Test acccuracy: 0.4192\n","--- Epoch 187 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1486\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 1.9455\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0022, Train acccuracy: 0.4590\n","Test loss: 2.0284, Test acccuracy: 0.4324\n","--- Epoch 188 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.0705\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0549\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 2.0128, Train acccuracy: 0.4486\n","Test loss: 2.0468, Test acccuracy: 0.4139\n","--- Epoch 189 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1473\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 1.9455\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 1.9455\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 2.0177, Train acccuracy: 0.4433\n","Test loss: 2.0448, Test acccuracy: 0.4175\n","--- Epoch 190 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 1.9768\n","Train batch: 300, Train loss: 1.9612\n","Train batch: 400, Train loss: 2.0543\n","Train batch: 500, Train loss: 2.1174\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 1.9768\n","Train loss: 2.0248, Train acccuracy: 0.4364\n","Test loss: 2.0713, Test acccuracy: 0.3898\n","--- Epoch 191 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8981\n","Train batch: 200, Train loss: 1.9143\n","Train batch: 300, Train loss: 1.9775\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 2.0705\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0366, Train acccuracy: 0.4246\n","Test loss: 2.0945, Test acccuracy: 0.3668\n","--- Epoch 192 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 2.0705\n","Train batch: 600, Train loss: 2.0236\n","Train batch: 700, Train loss: 2.0705\n","Train loss: 2.0466, Train acccuracy: 0.4145\n","Test loss: 2.0877, Test acccuracy: 0.3731\n","--- Epoch 193 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.2268\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 2.1330\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 1.9299\n","Train loss: 2.0704, Train acccuracy: 0.3907\n","Test loss: 2.0895, Test acccuracy: 0.3708\n","--- Epoch 194 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1018\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 2.0393\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.2424\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0683, Train acccuracy: 0.3930\n","Test loss: 2.0951, Test acccuracy: 0.3655\n","--- Epoch 195 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 2.1018\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 2.0457, Train acccuracy: 0.4153\n","Test loss: 2.0591, Test acccuracy: 0.4031\n","--- Epoch 196 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1018\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 2.0861\n","Train batch: 500, Train loss: 2.1955\n","Train batch: 600, Train loss: 2.0237\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 2.0593, Train acccuracy: 0.4017\n","Test loss: 2.0858, Test acccuracy: 0.3744\n","--- Epoch 197 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1643\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.1020\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.0549\n","Train batch: 600, Train loss: 2.1330\n","Train batch: 700, Train loss: 2.1170\n","Train loss: 2.0561, Train acccuracy: 0.4053\n","Test loss: 2.0634, Test acccuracy: 0.3973\n","--- Epoch 198 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0205\n","Train batch: 200, Train loss: 1.9612\n","Train batch: 300, Train loss: 2.1173\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 2.0862\n","Train batch: 600, Train loss: 1.9299\n","Train batch: 700, Train loss: 2.0392\n","Train loss: 2.0319, Train acccuracy: 0.4290\n","Test loss: 2.0455, Test acccuracy: 0.4161\n","--- Epoch 199 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 2.0862\n","Train batch: 600, Train loss: 1.9449\n","Train batch: 700, Train loss: 1.8987\n","Train loss: 2.0300, Train acccuracy: 0.4313\n","Test loss: 2.0447, Test acccuracy: 0.4158\n","--- Epoch 200 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 1.9143\n","Train batch: 300, Train loss: 1.9611\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 2.0862\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 2.0476, Train acccuracy: 0.4137\n","Test loss: 2.0828, Test acccuracy: 0.3780\n","--- Epoch 201 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0861\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 1.9299\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.0862\n","Train loss: 2.0564, Train acccuracy: 0.4049\n","Test loss: 2.0572, Test acccuracy: 0.4041\n","--- Epoch 202 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.0393\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 2.0237\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 2.0394, Train acccuracy: 0.4217\n","Test loss: 2.0638, Test acccuracy: 0.3982\n","--- Epoch 203 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0393\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 2.2112\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 1.9763\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.0393\n","Train loss: 2.0333, Train acccuracy: 0.4278\n","Test loss: 2.0540, Test acccuracy: 0.4060\n","--- Epoch 204 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8830\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 2.1799\n","Train loss: 2.0437, Train acccuracy: 0.4176\n","Test loss: 2.0495, Test acccuracy: 0.4112\n","--- Epoch 205 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 1.9612\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 1.9143\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0252, Train acccuracy: 0.4359\n","Test loss: 2.0456, Test acccuracy: 0.4154\n","--- Epoch 206 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.0393\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 2.0705\n","Train batch: 600, Train loss: 1.9299\n","Train batch: 700, Train loss: 1.9924\n","Train loss: 2.0352, Train acccuracy: 0.4261\n","Test loss: 2.0589, Test acccuracy: 0.4022\n","--- Epoch 207 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9612\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 1.9299\n","Train batch: 500, Train loss: 2.1174\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.1955\n","Train loss: 2.0274, Train acccuracy: 0.4337\n","Test loss: 2.0391, Test acccuracy: 0.4213\n","--- Epoch 208 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.8987\n","Train batch: 200, Train loss: 1.9298\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 2.1487\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.0862\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 2.0310, Train acccuracy: 0.4303\n","Test loss: 2.0785, Test acccuracy: 0.3823\n","--- Epoch 209 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1019\n","Train batch: 200, Train loss: 2.1174\n","Train batch: 300, Train loss: 1.9924\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 2.1174\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 1.9838\n","Train loss: 2.0589, Train acccuracy: 0.4024\n","Test loss: 2.0719, Test acccuracy: 0.3888\n","--- Epoch 210 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 2.1330\n","Train batch: 400, Train loss: 2.1799\n","Train batch: 500, Train loss: 2.0549\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.0548\n","Train loss: 2.0745, Train acccuracy: 0.3866\n","Test loss: 2.1010, Test acccuracy: 0.3601\n","--- Epoch 211 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1330\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 2.1018\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.0549\n","Train batch: 600, Train loss: 2.1018\n","Train batch: 700, Train loss: 1.9768\n","Train loss: 2.0588, Train acccuracy: 0.4023\n","Test loss: 2.0785, Test acccuracy: 0.3815\n","--- Epoch 212 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0393\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 1.9612\n","Train batch: 400, Train loss: 1.9455\n","Train batch: 500, Train loss: 2.0862\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 2.1133\n","Train loss: 2.0475, Train acccuracy: 0.4135\n","Test loss: 2.0483, Test acccuracy: 0.4130\n","--- Epoch 213 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1174\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 2.1174\n","Train batch: 500, Train loss: 2.1330\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 2.1487\n","Train loss: 2.0816, Train acccuracy: 0.3797\n","Test loss: 2.1053, Test acccuracy: 0.3561\n","--- Epoch 214 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.1018\n","Train batch: 300, Train loss: 2.1330\n","Train batch: 400, Train loss: 2.0393\n","Train batch: 500, Train loss: 2.1330\n","Train batch: 600, Train loss: 2.1330\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 2.1000, Train acccuracy: 0.3610\n","Test loss: 2.1065, Test acccuracy: 0.3542\n","--- Epoch 215 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 2.0237\n","Train batch: 500, Train loss: 2.1799\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.1330\n","Train loss: 2.0837, Train acccuracy: 0.3776\n","Test loss: 2.1002, Test acccuracy: 0.3602\n","--- Epoch 216 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1799\n","Train batch: 200, Train loss: 2.1018\n","Train batch: 300, Train loss: 2.1330\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.0237\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0855, Train acccuracy: 0.3756\n","Test loss: 2.1021, Test acccuracy: 0.3590\n","--- Epoch 217 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.2112\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.1487\n","Train batch: 400, Train loss: 2.1643\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 2.1643\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 2.0918, Train acccuracy: 0.3694\n","Test loss: 2.1077, Test acccuracy: 0.3539\n","--- Epoch 218 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 2.1643\n","Train batch: 300, Train loss: 2.0705\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 1.9455\n","Train batch: 700, Train loss: 2.0391\n","Train loss: 2.0676, Train acccuracy: 0.3936\n","Test loss: 2.0727, Test acccuracy: 0.3882\n","--- Epoch 219 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1174\n","Train batch: 200, Train loss: 2.1174\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 1.8830\n","Train batch: 500, Train loss: 2.0861\n","Train batch: 600, Train loss: 2.0862\n","Train batch: 700, Train loss: 2.1487\n","Train loss: 2.0655, Train acccuracy: 0.3957\n","Test loss: 2.1156, Test acccuracy: 0.3460\n","--- Epoch 220 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0861\n","Train batch: 200, Train loss: 2.1487\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 2.1643\n","Train batch: 500, Train loss: 1.9455\n","Train batch: 600, Train loss: 1.9768\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0869, Train acccuracy: 0.3743\n","Test loss: 2.0887, Test acccuracy: 0.3730\n","--- Epoch 221 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1018\n","Train batch: 200, Train loss: 2.1018\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.1330\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 2.0237\n","Train batch: 700, Train loss: 2.0864\n","Train loss: 2.0583, Train acccuracy: 0.4028\n","Test loss: 2.0742, Test acccuracy: 0.3873\n","--- Epoch 222 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0097\n","Train batch: 300, Train loss: 1.9768\n","Train batch: 400, Train loss: 2.1018\n","Train batch: 500, Train loss: 2.1018\n","Train batch: 600, Train loss: 2.1487\n","Train batch: 700, Train loss: 2.0393\n","Train loss: 2.0553, Train acccuracy: 0.4057\n","Test loss: 2.0641, Test acccuracy: 0.3966\n","--- Epoch 223 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 2.1330\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.0862\n","Train batch: 700, Train loss: 2.1643\n","Train loss: 2.0492, Train acccuracy: 0.4118\n","Test loss: 2.0649, Test acccuracy: 0.3963\n","--- Epoch 224 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 2.1017\n","Train batch: 500, Train loss: 2.0549\n","Train batch: 600, Train loss: 2.0080\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0506, Train acccuracy: 0.4105\n","Test loss: 2.0666, Test acccuracy: 0.3947\n","--- Epoch 225 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0393\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 1.9603\n","Train batch: 400, Train loss: 1.9924\n","Train batch: 500, Train loss: 2.1330\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 2.1174\n","Train loss: 2.0638, Train acccuracy: 0.3973\n","Test loss: 2.0949, Test acccuracy: 0.3668\n","--- Epoch 226 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1643\n","Train batch: 200, Train loss: 2.0080\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 2.1018\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0660, Train acccuracy: 0.3950\n","Test loss: 2.0828, Test acccuracy: 0.3786\n","--- Epoch 227 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.1018\n","Train batch: 400, Train loss: 2.1643\n","Train batch: 500, Train loss: 2.1018\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 2.0080\n","Train loss: 2.0794, Train acccuracy: 0.3817\n","Test loss: 2.1022, Test acccuracy: 0.3589\n","--- Epoch 228 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1174\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.1018\n","Train batch: 400, Train loss: 2.0077\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 2.1330\n","Train batch: 700, Train loss: 2.0549\n","Train loss: 2.0788, Train acccuracy: 0.3822\n","Test loss: 2.0890, Test acccuracy: 0.3718\n","--- Epoch 229 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 2.1643\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 2.1018\n","Train batch: 700, Train loss: 2.1958\n","Train loss: 2.0830, Train acccuracy: 0.3781\n","Test loss: 2.0935, Test acccuracy: 0.3669\n","--- Epoch 230 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.1018\n","Train batch: 400, Train loss: 2.1018\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.1643\n","Train batch: 700, Train loss: 2.1799\n","Train loss: 2.0852, Train acccuracy: 0.3759\n","Test loss: 2.1011, Test acccuracy: 0.3600\n","--- Epoch 231 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.1330\n","Train batch: 300, Train loss: 2.1330\n","Train batch: 400, Train loss: 2.0705\n","Train batch: 500, Train loss: 2.1330\n","Train batch: 600, Train loss: 2.0862\n","Train batch: 700, Train loss: 2.1487\n","Train loss: 2.1049, Train acccuracy: 0.3562\n","Test loss: 2.1230, Test acccuracy: 0.3377\n","--- Epoch 232 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 2.0577\n","Train batch: 500, Train loss: 2.1643\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 2.1955\n","Train loss: 2.0911, Train acccuracy: 0.3701\n","Test loss: 2.1075, Test acccuracy: 0.3535\n","--- Epoch 233 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.1330\n","Train batch: 300, Train loss: 2.0080\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 2.1487\n","Train batch: 600, Train loss: 2.1955\n","Train batch: 700, Train loss: 2.2112\n","Train loss: 2.0892, Train acccuracy: 0.3720\n","Test loss: 2.1139, Test acccuracy: 0.3459\n","--- Epoch 234 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0237\n","Train batch: 200, Train loss: 2.1174\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.0549\n","Train batch: 500, Train loss: 2.0549\n","Train batch: 600, Train loss: 2.0861\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 2.0862, Train acccuracy: 0.3751\n","Test loss: 2.0984, Test acccuracy: 0.3630\n","--- Epoch 235 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0549\n","Train batch: 300, Train loss: 2.0549\n","Train batch: 400, Train loss: 2.1174\n","Train batch: 500, Train loss: 2.1955\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 2.2268\n","Train loss: 2.0785, Train acccuracy: 0.3824\n","Test loss: 2.0767, Test acccuracy: 0.3836\n","--- Epoch 236 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1330\n","Train batch: 200, Train loss: 2.0393\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 1.9612\n","Train batch: 500, Train loss: 2.0237\n","Train batch: 600, Train loss: 1.9924\n","Train batch: 700, Train loss: 2.0237\n","Train loss: 2.0583, Train acccuracy: 0.4029\n","Test loss: 2.0741, Test acccuracy: 0.3871\n","--- Epoch 237 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9299\n","Train batch: 200, Train loss: 2.1643\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 1.9455\n","Train batch: 500, Train loss: 1.9924\n","Train batch: 600, Train loss: 2.1018\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0569, Train acccuracy: 0.4042\n","Test loss: 2.0777, Test acccuracy: 0.3829\n","--- Epoch 238 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 1.9924\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.0393\n","Train batch: 500, Train loss: 2.1174\n","Train batch: 600, Train loss: 2.0788\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0574, Train acccuracy: 0.4038\n","Test loss: 2.0840, Test acccuracy: 0.3772\n","--- Epoch 239 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.1018\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 2.1955\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.0862\n","Train batch: 700, Train loss: 2.1487\n","Train loss: 2.0652, Train acccuracy: 0.3957\n","Test loss: 2.0765, Test acccuracy: 0.3844\n","--- Epoch 240 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0080\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.1330\n","Train batch: 600, Train loss: 2.1018\n","Train batch: 700, Train loss: 2.1955\n","Train loss: 2.0983, Train acccuracy: 0.3628\n","Test loss: 2.1381, Test acccuracy: 0.3225\n","--- Epoch 241 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.1955\n","Train batch: 300, Train loss: 2.1487\n","Train batch: 400, Train loss: 2.0080\n","Train batch: 500, Train loss: 2.1174\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.1487\n","Train loss: 2.1236, Train acccuracy: 0.3375\n","Test loss: 2.1061, Test acccuracy: 0.3543\n","--- Epoch 242 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9768\n","Train batch: 200, Train loss: 2.1643\n","Train batch: 300, Train loss: 2.0237\n","Train batch: 400, Train loss: 2.1799\n","Train batch: 500, Train loss: 2.1018\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.1174\n","Train loss: 2.0908, Train acccuracy: 0.3702\n","Test loss: 2.0924, Test acccuracy: 0.3691\n","--- Epoch 243 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0549\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.1487\n","Train batch: 400, Train loss: 2.0393\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.0705\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0843, Train acccuracy: 0.3769\n","Test loss: 2.0948, Test acccuracy: 0.3662\n","--- Epoch 244 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0862\n","Train batch: 200, Train loss: 2.0862\n","Train batch: 300, Train loss: 2.1018\n","Train batch: 400, Train loss: 2.1643\n","Train batch: 500, Train loss: 1.9768\n","Train batch: 600, Train loss: 2.1169\n","Train batch: 700, Train loss: 2.1330\n","Train loss: 2.0747, Train acccuracy: 0.3863\n","Test loss: 2.0817, Test acccuracy: 0.3794\n","--- Epoch 245 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.0705\n","Train batch: 200, Train loss: 2.0705\n","Train batch: 300, Train loss: 2.1329\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.0393\n","Train batch: 600, Train loss: 2.1330\n","Train batch: 700, Train loss: 2.1174\n","Train loss: 2.0791, Train acccuracy: 0.3821\n","Test loss: 2.1048, Test acccuracy: 0.3571\n","--- Epoch 246 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1643\n","Train batch: 200, Train loss: 2.0237\n","Train batch: 300, Train loss: 2.1330\n","Train batch: 400, Train loss: 2.1018\n","Train batch: 500, Train loss: 2.1487\n","Train batch: 600, Train loss: 2.1799\n","Train batch: 700, Train loss: 2.0393\n","Train loss: 2.0970, Train acccuracy: 0.3641\n","Test loss: 2.1103, Test acccuracy: 0.3513\n","--- Epoch 247 --- (No L2 regularization)\n","Train batch: 100, Train loss: 1.9143\n","Train batch: 200, Train loss: 2.2112\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.1018\n","Train batch: 600, Train loss: 2.1174\n","Train batch: 700, Train loss: 2.1330\n","Train loss: 2.1047, Train acccuracy: 0.3564\n","Test loss: 2.1313, Test acccuracy: 0.3299\n","--- Epoch 248 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.2112\n","Train batch: 200, Train loss: 2.1955\n","Train batch: 300, Train loss: 2.1643\n","Train batch: 400, Train loss: 1.9768\n","Train batch: 500, Train loss: 2.1174\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 2.1330\n","Train loss: 2.1088, Train acccuracy: 0.3523\n","Test loss: 2.1132, Test acccuracy: 0.3475\n","--- Epoch 249 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1487\n","Train batch: 200, Train loss: 1.9455\n","Train batch: 300, Train loss: 2.1174\n","Train batch: 400, Train loss: 2.1486\n","Train batch: 500, Train loss: 2.0080\n","Train batch: 600, Train loss: 2.0549\n","Train batch: 700, Train loss: 2.0393\n","Train loss: 2.0916, Train acccuracy: 0.3694\n","Test loss: 2.0963, Test acccuracy: 0.3657\n","--- Epoch 250 --- (No L2 regularization)\n","Train batch: 100, Train loss: 2.1018\n","Train batch: 200, Train loss: 2.1643\n","Train batch: 300, Train loss: 2.0862\n","Train batch: 400, Train loss: 2.0862\n","Train batch: 500, Train loss: 2.1168\n","Train batch: 600, Train loss: 2.0237\n","Train batch: 700, Train loss: 2.1018\n","Train loss: 2.0792, Train acccuracy: 0.3820\n","Test loss: 2.1003, Test acccuracy: 0.3598\n"]}],"source":["train_loss, test_loss = [], []\n","train_accu, test_accu = [], []\n","\n","for epoch in range(1, num_epoch + 1):\n","    print('--- Epoch {} --- (No L2 regularization)'.format(epoch))\n","    trloss, traccu = train(mlp250, trainloader, optimizer, loss_func, device)\n","    teloss, teaccu = test(mlp250, testloader, loss_func, device)\n","\n","    train_loss.append(trloss)\n","    train_accu.append(traccu)\n","    test_loss.append(teloss)\n","    test_accu.append(teaccu)\n","\n","np.savetxt('train-250.txt', np.vstack([train_loss, train_accu]))\n","np.savetxt('test-250.txt', np.vstack([test_loss, test_accu]))"]},{"cell_type":"markdown","metadata":{"id":"kjxg-pluv723"},"source":["1. `num_epoch` is 50 (with L2 regularization)"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1648880332905,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"twfshscFv723"},"outputs":[],"source":["mlp50 = MLP(3, width, height).to(device)\n","optimizer = optim.Adam(mlp50.parameters(), lr=lr, weight_decay=l2_lambda)\n","loss_func = nn.CrossEntropyLoss()\n","num_epoch = 50"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322542,"status":"ok","timestamp":1648880655427,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"f_8gQ9vuv723","outputId":"a930f80f-682e-41ce-b804-b8f280fc911f"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Epoch 1 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2884\n","Train batch: 200, Train loss: 2.2751\n","Train batch: 300, Train loss: 2.2817\n","Train batch: 400, Train loss: 2.2316\n","Train batch: 500, Train loss: 2.2530\n","Train batch: 600, Train loss: 2.2458\n","Train batch: 700, Train loss: 2.2627\n","Train loss: 2.2729, Train acccuracy: 0.1583\n","Test loss: 2.2639, Test acccuracy: 0.1648\n","--- Epoch 2 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2943\n","Train batch: 200, Train loss: 2.2411\n","Train batch: 300, Train loss: 2.2649\n","Train batch: 400, Train loss: 2.2604\n","Train batch: 500, Train loss: 2.2514\n","Train batch: 600, Train loss: 2.2615\n","Train batch: 700, Train loss: 2.2605\n","Train loss: 2.2623, Train acccuracy: 0.1717\n","Test loss: 2.2622, Test acccuracy: 0.1758\n","--- Epoch 3 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2661\n","Train batch: 200, Train loss: 2.2941\n","Train batch: 300, Train loss: 2.2745\n","Train batch: 400, Train loss: 2.2691\n","Train batch: 500, Train loss: 2.2646\n","Train batch: 600, Train loss: 2.2318\n","Train batch: 700, Train loss: 2.2947\n","Train loss: 2.2612, Train acccuracy: 0.1786\n","Test loss: 2.2612, Test acccuracy: 0.1778\n","--- Epoch 4 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2288\n","Train batch: 200, Train loss: 2.2478\n","Train batch: 300, Train loss: 2.2490\n","Train batch: 400, Train loss: 2.2588\n","Train batch: 500, Train loss: 2.2354\n","Train batch: 600, Train loss: 2.2698\n","Train batch: 700, Train loss: 2.2753\n","Train loss: 2.2603, Train acccuracy: 0.1797\n","Test loss: 2.2604, Test acccuracy: 0.1794\n","--- Epoch 5 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2553\n","Train batch: 200, Train loss: 2.2759\n","Train batch: 300, Train loss: 2.2183\n","Train batch: 400, Train loss: 2.2394\n","Train batch: 500, Train loss: 2.2484\n","Train batch: 600, Train loss: 2.2356\n","Train batch: 700, Train loss: 2.2704\n","Train loss: 2.2601, Train acccuracy: 0.1794\n","Test loss: 2.2597, Test acccuracy: 0.1776\n","--- Epoch 6 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2674\n","Train batch: 200, Train loss: 2.2302\n","Train batch: 300, Train loss: 2.2517\n","Train batch: 400, Train loss: 2.2346\n","Train batch: 500, Train loss: 2.2326\n","Train batch: 600, Train loss: 2.2784\n","Train batch: 700, Train loss: 2.2543\n","Train loss: 2.2597, Train acccuracy: 0.1799\n","Test loss: 2.2607, Test acccuracy: 0.1771\n","--- Epoch 7 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2764\n","Train batch: 200, Train loss: 2.2417\n","Train batch: 300, Train loss: 2.2526\n","Train batch: 400, Train loss: 2.2174\n","Train batch: 500, Train loss: 2.2587\n","Train batch: 600, Train loss: 2.2871\n","Train batch: 700, Train loss: 2.2678\n","Train loss: 2.2598, Train acccuracy: 0.1801\n","Test loss: 2.2608, Test acccuracy: 0.1786\n","--- Epoch 8 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2795\n","Train batch: 200, Train loss: 2.2764\n","Train batch: 300, Train loss: 2.2742\n","Train batch: 400, Train loss: 2.2642\n","Train batch: 500, Train loss: 2.2430\n","Train batch: 600, Train loss: 2.2519\n","Train batch: 700, Train loss: 2.2765\n","Train loss: 2.2595, Train acccuracy: 0.1798\n","Test loss: 2.2592, Test acccuracy: 0.1772\n","--- Epoch 9 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2456\n","Train batch: 200, Train loss: 2.2320\n","Train batch: 300, Train loss: 2.2416\n","Train batch: 400, Train loss: 2.2632\n","Train batch: 500, Train loss: 2.2755\n","Train batch: 600, Train loss: 2.2801\n","Train batch: 700, Train loss: 2.2684\n","Train loss: 2.2596, Train acccuracy: 0.1790\n","Test loss: 2.2607, Test acccuracy: 0.1783\n","--- Epoch 10 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2578\n","Train batch: 200, Train loss: 2.2596\n","Train batch: 300, Train loss: 2.2655\n","Train batch: 400, Train loss: 2.2500\n","Train batch: 500, Train loss: 2.2873\n","Train batch: 600, Train loss: 2.2972\n","Train batch: 700, Train loss: 2.2513\n","Train loss: 2.2594, Train acccuracy: 0.1801\n","Test loss: 2.2614, Test acccuracy: 0.1805\n","--- Epoch 11 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2316\n","Train batch: 200, Train loss: 2.2638\n","Train batch: 300, Train loss: 2.2891\n","Train batch: 400, Train loss: 2.2388\n","Train batch: 500, Train loss: 2.2753\n","Train batch: 600, Train loss: 2.2610\n","Train batch: 700, Train loss: 2.2387\n","Train loss: 2.2592, Train acccuracy: 0.1795\n","Test loss: 2.2618, Test acccuracy: 0.1808\n","--- Epoch 12 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2645\n","Train batch: 200, Train loss: 2.2309\n","Train batch: 300, Train loss: 2.2649\n","Train batch: 400, Train loss: 2.2864\n","Train batch: 500, Train loss: 2.2748\n","Train batch: 600, Train loss: 2.2551\n","Train batch: 700, Train loss: 2.2372\n","Train loss: 2.2590, Train acccuracy: 0.1797\n","Test loss: 2.2610, Test acccuracy: 0.1805\n","--- Epoch 13 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2469\n","Train batch: 200, Train loss: 2.2554\n","Train batch: 300, Train loss: 2.2331\n","Train batch: 400, Train loss: 2.2630\n","Train batch: 500, Train loss: 2.2606\n","Train batch: 600, Train loss: 2.2229\n","Train batch: 700, Train loss: 2.2700\n","Train loss: 2.2591, Train acccuracy: 0.1800\n","Test loss: 2.2598, Test acccuracy: 0.1788\n","--- Epoch 14 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2766\n","Train batch: 200, Train loss: 2.2726\n","Train batch: 300, Train loss: 2.2746\n","Train batch: 400, Train loss: 2.2012\n","Train batch: 500, Train loss: 2.2568\n","Train batch: 600, Train loss: 2.2551\n","Train batch: 700, Train loss: 2.2660\n","Train loss: 2.2590, Train acccuracy: 0.1796\n","Test loss: 2.2600, Test acccuracy: 0.1769\n","--- Epoch 15 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2584\n","Train batch: 200, Train loss: 2.2461\n","Train batch: 300, Train loss: 2.2725\n","Train batch: 400, Train loss: 2.2629\n","Train batch: 500, Train loss: 2.2569\n","Train batch: 600, Train loss: 2.2504\n","Train batch: 700, Train loss: 2.2513\n","Train loss: 2.2591, Train acccuracy: 0.1796\n","Test loss: 2.2598, Test acccuracy: 0.1793\n","--- Epoch 16 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2371\n","Train batch: 200, Train loss: 2.2819\n","Train batch: 300, Train loss: 2.2461\n","Train batch: 400, Train loss: 2.2720\n","Train batch: 500, Train loss: 2.2920\n","Train batch: 600, Train loss: 2.2517\n","Train batch: 700, Train loss: 2.2837\n","Train loss: 2.2592, Train acccuracy: 0.1801\n","Test loss: 2.2605, Test acccuracy: 0.1789\n","--- Epoch 17 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2724\n","Train batch: 200, Train loss: 2.2854\n","Train batch: 300, Train loss: 2.2543\n","Train batch: 400, Train loss: 2.2655\n","Train batch: 500, Train loss: 2.1977\n","Train batch: 600, Train loss: 2.2760\n","Train batch: 700, Train loss: 2.2581\n","Train loss: 2.2593, Train acccuracy: 0.1792\n","Test loss: 2.2609, Test acccuracy: 0.1790\n","--- Epoch 18 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2643\n","Train batch: 200, Train loss: 2.2729\n","Train batch: 300, Train loss: 2.2801\n","Train batch: 400, Train loss: 2.2712\n","Train batch: 500, Train loss: 2.2058\n","Train batch: 600, Train loss: 2.2038\n","Train batch: 700, Train loss: 2.2325\n","Train loss: 2.2590, Train acccuracy: 0.1800\n","Test loss: 2.2603, Test acccuracy: 0.1772\n","--- Epoch 19 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2172\n","Train batch: 200, Train loss: 2.2542\n","Train batch: 300, Train loss: 2.2767\n","Train batch: 400, Train loss: 2.2593\n","Train batch: 500, Train loss: 2.2475\n","Train batch: 600, Train loss: 2.2947\n","Train batch: 700, Train loss: 2.2770\n","Train loss: 2.2591, Train acccuracy: 0.1799\n","Test loss: 2.2606, Test acccuracy: 0.1773\n","--- Epoch 20 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2604\n","Train batch: 200, Train loss: 2.2698\n","Train batch: 300, Train loss: 2.2229\n","Train batch: 400, Train loss: 2.2478\n","Train batch: 500, Train loss: 2.2540\n","Train batch: 600, Train loss: 2.2359\n","Train batch: 700, Train loss: 2.2660\n","Train loss: 2.2591, Train acccuracy: 0.1804\n","Test loss: 2.2592, Test acccuracy: 0.1800\n","--- Epoch 21 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2626\n","Train batch: 200, Train loss: 2.2655\n","Train batch: 300, Train loss: 2.2664\n","Train batch: 400, Train loss: 2.2766\n","Train batch: 500, Train loss: 2.2352\n","Train batch: 600, Train loss: 2.2767\n","Train batch: 700, Train loss: 2.2737\n","Train loss: 2.2590, Train acccuracy: 0.1799\n","Test loss: 2.2600, Test acccuracy: 0.1778\n","--- Epoch 22 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2822\n","Train batch: 200, Train loss: 2.2616\n","Train batch: 300, Train loss: 2.2617\n","Train batch: 400, Train loss: 2.3081\n","Train batch: 500, Train loss: 2.2665\n","Train batch: 600, Train loss: 2.2535\n","Train batch: 700, Train loss: 2.2243\n","Train loss: 2.2592, Train acccuracy: 0.1800\n","Test loss: 2.2605, Test acccuracy: 0.1790\n","--- Epoch 23 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2978\n","Train batch: 200, Train loss: 2.2556\n","Train batch: 300, Train loss: 2.2443\n","Train batch: 400, Train loss: 2.2837\n","Train batch: 500, Train loss: 2.2739\n","Train batch: 600, Train loss: 2.2524\n","Train batch: 700, Train loss: 2.2187\n","Train loss: 2.2592, Train acccuracy: 0.1799\n","Test loss: 2.2596, Test acccuracy: 0.1770\n","--- Epoch 24 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2693\n","Train batch: 200, Train loss: 2.2888\n","Train batch: 300, Train loss: 2.2736\n","Train batch: 400, Train loss: 2.2643\n","Train batch: 500, Train loss: 2.2622\n","Train batch: 600, Train loss: 2.2668\n","Train batch: 700, Train loss: 2.2357\n","Train loss: 2.2591, Train acccuracy: 0.1800\n","Test loss: 2.2606, Test acccuracy: 0.1802\n","--- Epoch 25 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2643\n","Train batch: 200, Train loss: 2.2912\n","Train batch: 300, Train loss: 2.2644\n","Train batch: 400, Train loss: 2.2563\n","Train batch: 500, Train loss: 2.2627\n","Train batch: 600, Train loss: 2.2891\n","Train batch: 700, Train loss: 2.2708\n","Train loss: 2.2591, Train acccuracy: 0.1803\n","Test loss: 2.2598, Test acccuracy: 0.1770\n","--- Epoch 26 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2440\n","Train batch: 200, Train loss: 2.2676\n","Train batch: 300, Train loss: 2.2352\n","Train batch: 400, Train loss: 2.2408\n","Train batch: 500, Train loss: 2.2637\n","Train batch: 600, Train loss: 2.2442\n","Train batch: 700, Train loss: 2.2481\n","Train loss: 2.2592, Train acccuracy: 0.1800\n","Test loss: 2.2588, Test acccuracy: 0.1806\n","--- Epoch 27 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.3158\n","Train batch: 200, Train loss: 2.2884\n","Train batch: 300, Train loss: 2.2858\n","Train batch: 400, Train loss: 2.2090\n","Train batch: 500, Train loss: 2.2251\n","Train batch: 600, Train loss: 2.2882\n","Train batch: 700, Train loss: 2.2709\n","Train loss: 2.2592, Train acccuracy: 0.1794\n","Test loss: 2.2599, Test acccuracy: 0.1792\n","--- Epoch 28 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2870\n","Train batch: 200, Train loss: 2.2554\n","Train batch: 300, Train loss: 2.2675\n","Train batch: 400, Train loss: 2.2365\n","Train batch: 500, Train loss: 2.2529\n","Train batch: 600, Train loss: 2.2212\n","Train batch: 700, Train loss: 2.2552\n","Train loss: 2.2591, Train acccuracy: 0.1799\n","Test loss: 2.2598, Test acccuracy: 0.1790\n","--- Epoch 29 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2300\n","Train batch: 200, Train loss: 2.2994\n","Train batch: 300, Train loss: 2.2499\n","Train batch: 400, Train loss: 2.2666\n","Train batch: 500, Train loss: 2.2479\n","Train batch: 600, Train loss: 2.2402\n","Train batch: 700, Train loss: 2.2664\n","Train loss: 2.2593, Train acccuracy: 0.1797\n","Test loss: 2.2595, Test acccuracy: 0.1783\n","--- Epoch 30 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2512\n","Train batch: 200, Train loss: 2.2672\n","Train batch: 300, Train loss: 2.2834\n","Train batch: 400, Train loss: 2.2498\n","Train batch: 500, Train loss: 2.2291\n","Train batch: 600, Train loss: 2.2554\n","Train batch: 700, Train loss: 2.2500\n","Train loss: 2.2593, Train acccuracy: 0.1796\n","Test loss: 2.2599, Test acccuracy: 0.1788\n","--- Epoch 31 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2669\n","Train batch: 200, Train loss: 2.2705\n","Train batch: 300, Train loss: 2.2837\n","Train batch: 400, Train loss: 2.2588\n","Train batch: 500, Train loss: 2.2372\n","Train batch: 600, Train loss: 2.2496\n","Train batch: 700, Train loss: 2.2408\n","Train loss: 2.2590, Train acccuracy: 0.1799\n","Test loss: 2.2608, Test acccuracy: 0.1762\n","--- Epoch 32 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2597\n","Train batch: 200, Train loss: 2.2345\n","Train batch: 300, Train loss: 2.2396\n","Train batch: 400, Train loss: 2.2594\n","Train batch: 500, Train loss: 2.2851\n","Train batch: 600, Train loss: 2.2716\n","Train batch: 700, Train loss: 2.2547\n","Train loss: 2.2594, Train acccuracy: 0.1805\n","Test loss: 2.2605, Test acccuracy: 0.1778\n","--- Epoch 33 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2645\n","Train batch: 200, Train loss: 2.2805\n","Train batch: 300, Train loss: 2.2117\n","Train batch: 400, Train loss: 2.2423\n","Train batch: 500, Train loss: 2.2317\n","Train batch: 600, Train loss: 2.2715\n","Train batch: 700, Train loss: 2.2954\n","Train loss: 2.2590, Train acccuracy: 0.1801\n","Test loss: 2.2614, Test acccuracy: 0.1763\n","--- Epoch 34 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2687\n","Train batch: 200, Train loss: 2.2738\n","Train batch: 300, Train loss: 2.2706\n","Train batch: 400, Train loss: 2.2754\n","Train batch: 500, Train loss: 2.2427\n","Train batch: 600, Train loss: 2.2966\n","Train batch: 700, Train loss: 2.2442\n","Train loss: 2.2591, Train acccuracy: 0.1803\n","Test loss: 2.2605, Test acccuracy: 0.1775\n","--- Epoch 35 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2887\n","Train batch: 200, Train loss: 2.2396\n","Train batch: 300, Train loss: 2.2367\n","Train batch: 400, Train loss: 2.2798\n","Train batch: 500, Train loss: 2.2775\n","Train batch: 600, Train loss: 2.2451\n","Train batch: 700, Train loss: 2.2337\n","Train loss: 2.2592, Train acccuracy: 0.1799\n","Test loss: 2.2603, Test acccuracy: 0.1789\n","--- Epoch 36 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2710\n","Train batch: 200, Train loss: 2.2437\n","Train batch: 300, Train loss: 2.2914\n","Train batch: 400, Train loss: 2.2631\n","Train batch: 500, Train loss: 2.2538\n","Train batch: 600, Train loss: 2.2489\n","Train batch: 700, Train loss: 2.2352\n","Train loss: 2.2592, Train acccuracy: 0.1796\n","Test loss: 2.2598, Test acccuracy: 0.1792\n","--- Epoch 37 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2717\n","Train batch: 200, Train loss: 2.2716\n","Train batch: 300, Train loss: 2.2650\n","Train batch: 400, Train loss: 2.2515\n","Train batch: 500, Train loss: 2.2584\n","Train batch: 600, Train loss: 2.2828\n","Train batch: 700, Train loss: 2.2475\n","Train loss: 2.2592, Train acccuracy: 0.1800\n","Test loss: 2.2598, Test acccuracy: 0.1780\n","--- Epoch 38 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.3001\n","Train batch: 200, Train loss: 2.2351\n","Train batch: 300, Train loss: 2.2558\n","Train batch: 400, Train loss: 2.2780\n","Train batch: 500, Train loss: 2.2711\n","Train batch: 600, Train loss: 2.2674\n","Train batch: 700, Train loss: 2.2797\n","Train loss: 2.2593, Train acccuracy: 0.1798\n","Test loss: 2.2595, Test acccuracy: 0.1808\n","--- Epoch 39 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2935\n","Train batch: 200, Train loss: 2.2748\n","Train batch: 300, Train loss: 2.2394\n","Train batch: 400, Train loss: 2.2815\n","Train batch: 500, Train loss: 2.2444\n","Train batch: 600, Train loss: 2.2373\n","Train batch: 700, Train loss: 2.2899\n","Train loss: 2.2593, Train acccuracy: 0.1795\n","Test loss: 2.2599, Test acccuracy: 0.1787\n","--- Epoch 40 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2702\n","Train batch: 200, Train loss: 2.2387\n","Train batch: 300, Train loss: 2.2917\n","Train batch: 400, Train loss: 2.2852\n","Train batch: 500, Train loss: 2.2842\n","Train batch: 600, Train loss: 2.2491\n","Train batch: 700, Train loss: 2.2459\n","Train loss: 2.2592, Train acccuracy: 0.1799\n","Test loss: 2.2600, Test acccuracy: 0.1793\n","--- Epoch 41 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2592\n","Train batch: 200, Train loss: 2.2769\n","Train batch: 300, Train loss: 2.2420\n","Train batch: 400, Train loss: 2.2389\n","Train batch: 500, Train loss: 2.2683\n","Train batch: 600, Train loss: 2.2529\n","Train batch: 700, Train loss: 2.2689\n","Train loss: 2.2593, Train acccuracy: 0.1800\n","Test loss: 2.2604, Test acccuracy: 0.1791\n","--- Epoch 42 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2798\n","Train batch: 200, Train loss: 2.2196\n","Train batch: 300, Train loss: 2.2412\n","Train batch: 400, Train loss: 2.2829\n","Train batch: 500, Train loss: 2.2566\n","Train batch: 600, Train loss: 2.2789\n","Train batch: 700, Train loss: 2.2580\n","Train loss: 2.2594, Train acccuracy: 0.1798\n","Test loss: 2.2602, Test acccuracy: 0.1799\n","--- Epoch 43 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2791\n","Train batch: 200, Train loss: 2.2480\n","Train batch: 300, Train loss: 2.2436\n","Train batch: 400, Train loss: 2.2787\n","Train batch: 500, Train loss: 2.2800\n","Train batch: 600, Train loss: 2.2244\n","Train batch: 700, Train loss: 2.2758\n","Train loss: 2.2593, Train acccuracy: 0.1803\n","Test loss: 2.2616, Test acccuracy: 0.1786\n","--- Epoch 44 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2871\n","Train batch: 200, Train loss: 2.2647\n","Train batch: 300, Train loss: 2.2452\n","Train batch: 400, Train loss: 2.2193\n","Train batch: 500, Train loss: 2.2473\n","Train batch: 600, Train loss: 2.2483\n","Train batch: 700, Train loss: 2.2282\n","Train loss: 2.2594, Train acccuracy: 0.1799\n","Test loss: 2.2599, Test acccuracy: 0.1783\n","--- Epoch 45 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2426\n","Train batch: 200, Train loss: 2.2855\n","Train batch: 300, Train loss: 2.2645\n","Train batch: 400, Train loss: 2.2726\n","Train batch: 500, Train loss: 2.2799\n","Train batch: 600, Train loss: 2.2455\n","Train batch: 700, Train loss: 2.2816\n","Train loss: 2.2595, Train acccuracy: 0.1800\n","Test loss: 2.2605, Test acccuracy: 0.1801\n","--- Epoch 46 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2373\n","Train batch: 200, Train loss: 2.2598\n","Train batch: 300, Train loss: 2.2496\n","Train batch: 400, Train loss: 2.2521\n","Train batch: 500, Train loss: 2.2490\n","Train batch: 600, Train loss: 2.2576\n","Train batch: 700, Train loss: 2.2247\n","Train loss: 2.2593, Train acccuracy: 0.1796\n","Test loss: 2.2597, Test acccuracy: 0.1796\n","--- Epoch 47 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2309\n","Train batch: 200, Train loss: 2.2525\n","Train batch: 300, Train loss: 2.3026\n","Train batch: 400, Train loss: 2.2784\n","Train batch: 500, Train loss: 2.2629\n","Train batch: 600, Train loss: 2.2615\n","Train batch: 700, Train loss: 2.2359\n","Train loss: 2.2594, Train acccuracy: 0.1803\n","Test loss: 2.2601, Test acccuracy: 0.1776\n","--- Epoch 48 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2805\n","Train batch: 200, Train loss: 2.2727\n","Train batch: 300, Train loss: 2.2492\n","Train batch: 400, Train loss: 2.2894\n","Train batch: 500, Train loss: 2.2920\n","Train batch: 600, Train loss: 2.2551\n","Train batch: 700, Train loss: 2.2755\n","Train loss: 2.2594, Train acccuracy: 0.1803\n","Test loss: 2.2596, Test acccuracy: 0.1788\n","--- Epoch 49 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2565\n","Train batch: 200, Train loss: 2.2871\n","Train batch: 300, Train loss: 2.2859\n","Train batch: 400, Train loss: 2.2520\n","Train batch: 500, Train loss: 2.2694\n","Train batch: 600, Train loss: 2.2566\n","Train batch: 700, Train loss: 2.2666\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2603, Test acccuracy: 0.1802\n","--- Epoch 50 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2051\n","Train batch: 200, Train loss: 2.2663\n","Train batch: 300, Train loss: 2.2293\n","Train batch: 400, Train loss: 2.1941\n","Train batch: 500, Train loss: 2.2710\n","Train batch: 600, Train loss: 2.2288\n","Train batch: 700, Train loss: 2.2547\n","Train loss: 2.2594, Train acccuracy: 0.1800\n","Test loss: 2.2606, Test acccuracy: 0.1792\n"]}],"source":["train_loss, test_loss = [], []\n","train_accu, test_accu = [], []\n","\n","for epoch in range(1, num_epoch + 1):\n","    print('--- Epoch {} --- (With L2 regularization)'.format(epoch))\n","    trloss, traccu = train(mlp50, trainloader, optimizer, loss_func, device)\n","    teloss, teaccu = test(mlp50, testloader, loss_func, device)\n","\n","    train_loss.append(trloss)\n","    train_accu.append(traccu)\n","    test_loss.append(teloss)\n","    test_accu.append(teaccu)\n","\n","np.savetxt('train-50-l2.txt', np.vstack([train_loss, train_accu]))\n","np.savetxt('test-50-l2.txt', np.vstack([test_loss, test_accu]))"]},{"cell_type":"markdown","metadata":{"id":"xSlCUU6-v723"},"source":["1. `num_epoch` is 250 (with L2 regularization)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1648880655427,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"ui5r24auv724"},"outputs":[],"source":["mlp250 = MLP(3, width, height).to(device)\n","optimizer = optim.Adam(mlp250.parameters(), lr=lr, weight_decay=l2_lambda)\n","loss_func = nn.CrossEntropyLoss()\n","num_epoch = 250"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1648406,"status":"ok","timestamp":1648882303827,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"YyzCGhTRv724","outputId":"65fd9f0f-0eef-4219-c8c6-03db1f282d00"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Epoch 1 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2806\n","Train batch: 200, Train loss: 2.2553\n","Train batch: 300, Train loss: 2.2992\n","Train batch: 400, Train loss: 2.2296\n","Train batch: 500, Train loss: 2.2518\n","Train batch: 600, Train loss: 2.2614\n","Train batch: 700, Train loss: 2.2833\n","Train loss: 2.2669, Train acccuracy: 0.1648\n","Test loss: 2.2648, Test acccuracy: 0.1779\n","--- Epoch 2 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2473\n","Train batch: 200, Train loss: 2.2713\n","Train batch: 300, Train loss: 2.2885\n","Train batch: 400, Train loss: 2.2753\n","Train batch: 500, Train loss: 2.2510\n","Train batch: 600, Train loss: 2.2709\n","Train batch: 700, Train loss: 2.2473\n","Train loss: 2.2620, Train acccuracy: 0.1779\n","Test loss: 2.2634, Test acccuracy: 0.1774\n","--- Epoch 3 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2799\n","Train batch: 200, Train loss: 2.2767\n","Train batch: 300, Train loss: 2.2599\n","Train batch: 400, Train loss: 2.2490\n","Train batch: 500, Train loss: 2.2733\n","Train batch: 600, Train loss: 2.2756\n","Train batch: 700, Train loss: 2.2652\n","Train loss: 2.2610, Train acccuracy: 0.1789\n","Test loss: 2.2598, Test acccuracy: 0.1786\n","--- Epoch 4 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2566\n","Train batch: 200, Train loss: 2.2600\n","Train batch: 300, Train loss: 2.2660\n","Train batch: 400, Train loss: 2.1946\n","Train batch: 500, Train loss: 2.2377\n","Train batch: 600, Train loss: 2.2654\n","Train batch: 700, Train loss: 2.2864\n","Train loss: 2.2600, Train acccuracy: 0.1794\n","Test loss: 2.2599, Test acccuracy: 0.1779\n","--- Epoch 5 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2769\n","Train batch: 200, Train loss: 2.2764\n","Train batch: 300, Train loss: 2.2736\n","Train batch: 400, Train loss: 2.2735\n","Train batch: 500, Train loss: 2.2872\n","Train batch: 600, Train loss: 2.2893\n","Train batch: 700, Train loss: 2.2574\n","Train loss: 2.2596, Train acccuracy: 0.1799\n","Test loss: 2.2607, Test acccuracy: 0.1784\n","--- Epoch 6 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2733\n","Train batch: 200, Train loss: 2.2832\n","Train batch: 300, Train loss: 2.2709\n","Train batch: 400, Train loss: 2.2695\n","Train batch: 500, Train loss: 2.2690\n","Train batch: 600, Train loss: 2.2570\n","Train batch: 700, Train loss: 2.2868\n","Train loss: 2.2596, Train acccuracy: 0.1790\n","Test loss: 2.2601, Test acccuracy: 0.1798\n","--- Epoch 7 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2977\n","Train batch: 200, Train loss: 2.2617\n","Train batch: 300, Train loss: 2.2976\n","Train batch: 400, Train loss: 2.2531\n","Train batch: 500, Train loss: 2.2723\n","Train batch: 600, Train loss: 2.2458\n","Train batch: 700, Train loss: 2.2762\n","Train loss: 2.2596, Train acccuracy: 0.1797\n","Test loss: 2.2612, Test acccuracy: 0.1774\n","--- Epoch 8 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2415\n","Train batch: 200, Train loss: 2.2591\n","Train batch: 300, Train loss: 2.2632\n","Train batch: 400, Train loss: 2.2558\n","Train batch: 500, Train loss: 2.2616\n","Train batch: 600, Train loss: 2.2744\n","Train batch: 700, Train loss: 2.2463\n","Train loss: 2.2595, Train acccuracy: 0.1798\n","Test loss: 2.2608, Test acccuracy: 0.1799\n","--- Epoch 9 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2566\n","Train batch: 200, Train loss: 2.2591\n","Train batch: 300, Train loss: 2.2188\n","Train batch: 400, Train loss: 2.2763\n","Train batch: 500, Train loss: 2.2789\n","Train batch: 600, Train loss: 2.2755\n","Train batch: 700, Train loss: 2.2543\n","Train loss: 2.2595, Train acccuracy: 0.1802\n","Test loss: 2.2603, Test acccuracy: 0.1795\n","--- Epoch 10 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2578\n","Train batch: 200, Train loss: 2.2573\n","Train batch: 300, Train loss: 2.2609\n","Train batch: 400, Train loss: 2.2717\n","Train batch: 500, Train loss: 2.2886\n","Train batch: 600, Train loss: 2.2621\n","Train batch: 700, Train loss: 2.2549\n","Train loss: 2.2598, Train acccuracy: 0.1798\n","Test loss: 2.2606, Test acccuracy: 0.1780\n","--- Epoch 11 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2678\n","Train batch: 200, Train loss: 2.2352\n","Train batch: 300, Train loss: 2.2090\n","Train batch: 400, Train loss: 2.2570\n","Train batch: 500, Train loss: 2.2802\n","Train batch: 600, Train loss: 2.2745\n","Train batch: 700, Train loss: 2.2917\n","Train loss: 2.2596, Train acccuracy: 0.1800\n","Test loss: 2.2603, Test acccuracy: 0.1787\n","--- Epoch 12 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2278\n","Train batch: 200, Train loss: 2.2935\n","Train batch: 300, Train loss: 2.2510\n","Train batch: 400, Train loss: 2.2844\n","Train batch: 500, Train loss: 2.2688\n","Train batch: 600, Train loss: 2.2752\n","Train batch: 700, Train loss: 2.2391\n","Train loss: 2.2595, Train acccuracy: 0.1796\n","Test loss: 2.2599, Test acccuracy: 0.1794\n","--- Epoch 13 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2605\n","Train batch: 200, Train loss: 2.2655\n","Train batch: 300, Train loss: 2.2275\n","Train batch: 400, Train loss: 2.2536\n","Train batch: 500, Train loss: 2.2678\n","Train batch: 600, Train loss: 2.2378\n","Train batch: 700, Train loss: 2.2513\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2621, Test acccuracy: 0.1799\n","--- Epoch 14 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2558\n","Train batch: 200, Train loss: 2.2767\n","Train batch: 300, Train loss: 2.2422\n","Train batch: 400, Train loss: 2.2474\n","Train batch: 500, Train loss: 2.2711\n","Train batch: 600, Train loss: 2.2192\n","Train batch: 700, Train loss: 2.2190\n","Train loss: 2.2597, Train acccuracy: 0.1799\n","Test loss: 2.2622, Test acccuracy: 0.1797\n","--- Epoch 15 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2411\n","Train batch: 200, Train loss: 2.2415\n","Train batch: 300, Train loss: 2.2639\n","Train batch: 400, Train loss: 2.2332\n","Train batch: 500, Train loss: 2.2288\n","Train batch: 600, Train loss: 2.2862\n","Train batch: 700, Train loss: 2.2540\n","Train loss: 2.2594, Train acccuracy: 0.1798\n","Test loss: 2.2599, Test acccuracy: 0.1788\n","--- Epoch 16 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2623\n","Train batch: 200, Train loss: 2.2752\n","Train batch: 300, Train loss: 2.2639\n","Train batch: 400, Train loss: 2.2440\n","Train batch: 500, Train loss: 2.2651\n","Train batch: 600, Train loss: 2.2721\n","Train batch: 700, Train loss: 2.2608\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2613, Test acccuracy: 0.1788\n","--- Epoch 17 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2659\n","Train batch: 200, Train loss: 2.2281\n","Train batch: 300, Train loss: 2.2848\n","Train batch: 400, Train loss: 2.2700\n","Train batch: 500, Train loss: 2.2531\n","Train batch: 600, Train loss: 2.2923\n","Train batch: 700, Train loss: 2.2732\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2606, Test acccuracy: 0.1785\n","--- Epoch 18 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2672\n","Train batch: 200, Train loss: 2.2655\n","Train batch: 300, Train loss: 2.2733\n","Train batch: 400, Train loss: 2.2995\n","Train batch: 500, Train loss: 2.2124\n","Train batch: 600, Train loss: 2.2472\n","Train batch: 700, Train loss: 2.2879\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2597, Test acccuracy: 0.1793\n","--- Epoch 19 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2252\n","Train batch: 200, Train loss: 2.2508\n","Train batch: 300, Train loss: 2.2752\n","Train batch: 400, Train loss: 2.2418\n","Train batch: 500, Train loss: 2.2586\n","Train batch: 600, Train loss: 2.2611\n","Train batch: 700, Train loss: 2.2653\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2598, Test acccuracy: 0.1794\n","--- Epoch 20 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2824\n","Train batch: 200, Train loss: 2.2365\n","Train batch: 300, Train loss: 2.2772\n","Train batch: 400, Train loss: 2.2782\n","Train batch: 500, Train loss: 2.2571\n","Train batch: 600, Train loss: 2.2685\n","Train batch: 700, Train loss: 2.2933\n","Train loss: 2.2592, Train acccuracy: 0.1801\n","Test loss: 2.2602, Test acccuracy: 0.1786\n","--- Epoch 21 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2810\n","Train batch: 200, Train loss: 2.2941\n","Train batch: 300, Train loss: 2.2731\n","Train batch: 400, Train loss: 2.2924\n","Train batch: 500, Train loss: 2.2753\n","Train batch: 600, Train loss: 2.2670\n","Train batch: 700, Train loss: 2.2609\n","Train loss: 2.2597, Train acccuracy: 0.1793\n","Test loss: 2.2604, Test acccuracy: 0.1777\n","--- Epoch 22 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2945\n","Train batch: 200, Train loss: 2.2877\n","Train batch: 300, Train loss: 2.2342\n","Train batch: 400, Train loss: 2.2579\n","Train batch: 500, Train loss: 2.2762\n","Train batch: 600, Train loss: 2.2465\n","Train batch: 700, Train loss: 2.2638\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2610, Test acccuracy: 0.1776\n","--- Epoch 23 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2406\n","Train batch: 200, Train loss: 2.2890\n","Train batch: 300, Train loss: 2.2819\n","Train batch: 400, Train loss: 2.2381\n","Train batch: 500, Train loss: 2.2749\n","Train batch: 600, Train loss: 2.2345\n","Train batch: 700, Train loss: 2.2524\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2601, Test acccuracy: 0.1794\n","--- Epoch 24 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2579\n","Train batch: 200, Train loss: 2.2257\n","Train batch: 300, Train loss: 2.2567\n","Train batch: 400, Train loss: 2.2786\n","Train batch: 500, Train loss: 2.2743\n","Train batch: 600, Train loss: 2.2564\n","Train batch: 700, Train loss: 2.2447\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2604, Test acccuracy: 0.1787\n","--- Epoch 25 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2602\n","Train batch: 200, Train loss: 2.2307\n","Train batch: 300, Train loss: 2.3066\n","Train batch: 400, Train loss: 2.2567\n","Train batch: 500, Train loss: 2.2841\n","Train batch: 600, Train loss: 2.2696\n","Train batch: 700, Train loss: 2.2915\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2604, Test acccuracy: 0.1783\n","--- Epoch 26 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2870\n","Train batch: 200, Train loss: 2.2064\n","Train batch: 300, Train loss: 2.2662\n","Train batch: 400, Train loss: 2.2359\n","Train batch: 500, Train loss: 2.2523\n","Train batch: 600, Train loss: 2.2677\n","Train batch: 700, Train loss: 2.2683\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2604, Test acccuracy: 0.1782\n","--- Epoch 27 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2826\n","Train batch: 200, Train loss: 2.2493\n","Train batch: 300, Train loss: 2.2764\n","Train batch: 400, Train loss: 2.2647\n","Train batch: 500, Train loss: 2.2309\n","Train batch: 600, Train loss: 2.2693\n","Train batch: 700, Train loss: 2.2361\n","Train loss: 2.2596, Train acccuracy: 0.1792\n","Test loss: 2.2604, Test acccuracy: 0.1788\n","--- Epoch 28 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2360\n","Train batch: 200, Train loss: 2.2652\n","Train batch: 300, Train loss: 2.2552\n","Train batch: 400, Train loss: 2.2941\n","Train batch: 500, Train loss: 2.2481\n","Train batch: 600, Train loss: 2.2730\n","Train batch: 700, Train loss: 2.2474\n","Train loss: 2.2598, Train acccuracy: 0.1798\n","Test loss: 2.2597, Test acccuracy: 0.1793\n","--- Epoch 29 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2720\n","Train batch: 200, Train loss: 2.2617\n","Train batch: 300, Train loss: 2.2705\n","Train batch: 400, Train loss: 2.2828\n","Train batch: 500, Train loss: 2.2795\n","Train batch: 600, Train loss: 2.2549\n","Train batch: 700, Train loss: 2.2502\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2605, Test acccuracy: 0.1793\n","--- Epoch 30 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2899\n","Train batch: 200, Train loss: 2.2668\n","Train batch: 300, Train loss: 2.2597\n","Train batch: 400, Train loss: 2.2847\n","Train batch: 500, Train loss: 2.2388\n","Train batch: 600, Train loss: 2.2440\n","Train batch: 700, Train loss: 2.2675\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2602, Test acccuracy: 0.1782\n","--- Epoch 31 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2437\n","Train batch: 200, Train loss: 2.3020\n","Train batch: 300, Train loss: 2.2600\n","Train batch: 400, Train loss: 2.2653\n","Train batch: 500, Train loss: 2.2427\n","Train batch: 600, Train loss: 2.2715\n","Train batch: 700, Train loss: 2.2578\n","Train loss: 2.2598, Train acccuracy: 0.1791\n","Test loss: 2.2603, Test acccuracy: 0.1789\n","--- Epoch 32 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2608\n","Train batch: 200, Train loss: 2.2133\n","Train batch: 300, Train loss: 2.2752\n","Train batch: 400, Train loss: 2.2559\n","Train batch: 500, Train loss: 2.2193\n","Train batch: 600, Train loss: 2.2983\n","Train batch: 700, Train loss: 2.2807\n","Train loss: 2.2596, Train acccuracy: 0.1792\n","Test loss: 2.2621, Test acccuracy: 0.1784\n","--- Epoch 33 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2709\n","Train batch: 200, Train loss: 2.2735\n","Train batch: 300, Train loss: 2.2477\n","Train batch: 400, Train loss: 2.2271\n","Train batch: 500, Train loss: 2.2513\n","Train batch: 600, Train loss: 2.2632\n","Train batch: 700, Train loss: 2.2914\n","Train loss: 2.2598, Train acccuracy: 0.1793\n","Test loss: 2.2601, Test acccuracy: 0.1784\n","--- Epoch 34 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2551\n","Train batch: 200, Train loss: 2.2942\n","Train batch: 300, Train loss: 2.2755\n","Train batch: 400, Train loss: 2.2659\n","Train batch: 500, Train loss: 2.2893\n","Train batch: 600, Train loss: 2.2429\n","Train batch: 700, Train loss: 2.2698\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2607, Test acccuracy: 0.1791\n","--- Epoch 35 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2780\n","Train batch: 200, Train loss: 2.2783\n","Train batch: 300, Train loss: 2.2568\n","Train batch: 400, Train loss: 2.2755\n","Train batch: 500, Train loss: 2.2229\n","Train batch: 600, Train loss: 2.2614\n","Train batch: 700, Train loss: 2.2696\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2608, Test acccuracy: 0.1803\n","--- Epoch 36 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2707\n","Train batch: 200, Train loss: 2.2877\n","Train batch: 300, Train loss: 2.2496\n","Train batch: 400, Train loss: 2.2693\n","Train batch: 500, Train loss: 2.2412\n","Train batch: 600, Train loss: 2.2344\n","Train batch: 700, Train loss: 2.2505\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2611, Test acccuracy: 0.1783\n","--- Epoch 37 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2462\n","Train batch: 200, Train loss: 2.2612\n","Train batch: 300, Train loss: 2.2693\n","Train batch: 400, Train loss: 2.2323\n","Train batch: 500, Train loss: 2.2636\n","Train batch: 600, Train loss: 2.2328\n","Train batch: 700, Train loss: 2.2633\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2602, Test acccuracy: 0.1788\n","--- Epoch 38 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2762\n","Train batch: 200, Train loss: 2.2556\n","Train batch: 300, Train loss: 2.2505\n","Train batch: 400, Train loss: 2.2864\n","Train batch: 500, Train loss: 2.2530\n","Train batch: 600, Train loss: 2.2653\n","Train batch: 700, Train loss: 2.2734\n","Train loss: 2.2597, Train acccuracy: 0.1790\n","Test loss: 2.2604, Test acccuracy: 0.1788\n","--- Epoch 39 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2785\n","Train batch: 200, Train loss: 2.2276\n","Train batch: 300, Train loss: 2.2844\n","Train batch: 400, Train loss: 2.2632\n","Train batch: 500, Train loss: 2.2186\n","Train batch: 600, Train loss: 2.2896\n","Train batch: 700, Train loss: 2.2278\n","Train loss: 2.2599, Train acccuracy: 0.1792\n","Test loss: 2.2600, Test acccuracy: 0.1788\n","--- Epoch 40 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2443\n","Train batch: 200, Train loss: 2.2187\n","Train batch: 300, Train loss: 2.2894\n","Train batch: 400, Train loss: 2.2234\n","Train batch: 500, Train loss: 2.2680\n","Train batch: 600, Train loss: 2.2876\n","Train batch: 700, Train loss: 2.2783\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2598, Test acccuracy: 0.1788\n","--- Epoch 41 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2572\n","Train batch: 200, Train loss: 2.2830\n","Train batch: 300, Train loss: 2.1953\n","Train batch: 400, Train loss: 2.2775\n","Train batch: 500, Train loss: 2.2398\n","Train batch: 600, Train loss: 2.2536\n","Train batch: 700, Train loss: 2.2413\n","Train loss: 2.2597, Train acccuracy: 0.1803\n","Test loss: 2.2604, Test acccuracy: 0.1791\n","--- Epoch 42 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2421\n","Train batch: 200, Train loss: 2.2631\n","Train batch: 300, Train loss: 2.2980\n","Train batch: 400, Train loss: 2.2473\n","Train batch: 500, Train loss: 2.2950\n","Train batch: 600, Train loss: 2.2524\n","Train batch: 700, Train loss: 2.2393\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2610, Test acccuracy: 0.1788\n","--- Epoch 43 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2695\n","Train batch: 200, Train loss: 2.2121\n","Train batch: 300, Train loss: 2.2614\n","Train batch: 400, Train loss: 2.2377\n","Train batch: 500, Train loss: 2.2532\n","Train batch: 600, Train loss: 2.3025\n","Train batch: 700, Train loss: 2.2723\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2603, Test acccuracy: 0.1798\n","--- Epoch 44 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2580\n","Train batch: 200, Train loss: 2.2387\n","Train batch: 300, Train loss: 2.2685\n","Train batch: 400, Train loss: 2.2584\n","Train batch: 500, Train loss: 2.2563\n","Train batch: 600, Train loss: 2.2468\n","Train batch: 700, Train loss: 2.2831\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2607, Test acccuracy: 0.1798\n","--- Epoch 45 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.1807\n","Train batch: 200, Train loss: 2.2917\n","Train batch: 300, Train loss: 2.2581\n","Train batch: 400, Train loss: 2.2687\n","Train batch: 500, Train loss: 2.2272\n","Train batch: 600, Train loss: 2.2864\n","Train batch: 700, Train loss: 2.2823\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2608, Test acccuracy: 0.1787\n","--- Epoch 46 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2346\n","Train batch: 200, Train loss: 2.2266\n","Train batch: 300, Train loss: 2.2230\n","Train batch: 400, Train loss: 2.2923\n","Train batch: 500, Train loss: 2.2500\n","Train batch: 600, Train loss: 2.2971\n","Train batch: 700, Train loss: 2.2544\n","Train loss: 2.2600, Train acccuracy: 0.1798\n","Test loss: 2.2606, Test acccuracy: 0.1776\n","--- Epoch 47 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2410\n","Train batch: 200, Train loss: 2.2436\n","Train batch: 300, Train loss: 2.2623\n","Train batch: 400, Train loss: 2.2458\n","Train batch: 500, Train loss: 2.2824\n","Train batch: 600, Train loss: 2.2742\n","Train batch: 700, Train loss: 2.2694\n","Train loss: 2.2598, Train acccuracy: 0.1801\n","Test loss: 2.2607, Test acccuracy: 0.1786\n","--- Epoch 48 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2331\n","Train batch: 200, Train loss: 2.2798\n","Train batch: 300, Train loss: 2.2711\n","Train batch: 400, Train loss: 2.2891\n","Train batch: 500, Train loss: 2.2682\n","Train batch: 600, Train loss: 2.2669\n","Train batch: 700, Train loss: 2.2633\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2599, Test acccuracy: 0.1790\n","--- Epoch 49 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2419\n","Train batch: 200, Train loss: 2.2552\n","Train batch: 300, Train loss: 2.2726\n","Train batch: 400, Train loss: 2.2579\n","Train batch: 500, Train loss: 2.2626\n","Train batch: 600, Train loss: 2.2620\n","Train batch: 700, Train loss: 2.2799\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2597, Test acccuracy: 0.1785\n","--- Epoch 50 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2630\n","Train batch: 200, Train loss: 2.2578\n","Train batch: 300, Train loss: 2.2748\n","Train batch: 400, Train loss: 2.2910\n","Train batch: 500, Train loss: 2.2402\n","Train batch: 600, Train loss: 2.2710\n","Train batch: 700, Train loss: 2.2632\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2617, Test acccuracy: 0.1804\n","--- Epoch 51 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2509\n","Train batch: 200, Train loss: 2.2569\n","Train batch: 300, Train loss: 2.2699\n","Train batch: 400, Train loss: 2.2551\n","Train batch: 500, Train loss: 2.2419\n","Train batch: 600, Train loss: 2.2767\n","Train batch: 700, Train loss: 2.2927\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2597, Test acccuracy: 0.1784\n","--- Epoch 52 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2655\n","Train batch: 200, Train loss: 2.2856\n","Train batch: 300, Train loss: 2.2323\n","Train batch: 400, Train loss: 2.2569\n","Train batch: 500, Train loss: 2.2227\n","Train batch: 600, Train loss: 2.2964\n","Train batch: 700, Train loss: 2.2761\n","Train loss: 2.2596, Train acccuracy: 0.1797\n","Test loss: 2.2604, Test acccuracy: 0.1797\n","--- Epoch 53 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2666\n","Train batch: 200, Train loss: 2.2595\n","Train batch: 300, Train loss: 2.2454\n","Train batch: 400, Train loss: 2.3076\n","Train batch: 500, Train loss: 2.2412\n","Train batch: 600, Train loss: 2.2462\n","Train batch: 700, Train loss: 2.2667\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2603, Test acccuracy: 0.1785\n","--- Epoch 54 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2342\n","Train batch: 200, Train loss: 2.2813\n","Train batch: 300, Train loss: 2.2563\n","Train batch: 400, Train loss: 2.2495\n","Train batch: 500, Train loss: 2.2453\n","Train batch: 600, Train loss: 2.2185\n","Train batch: 700, Train loss: 2.2460\n","Train loss: 2.2599, Train acccuracy: 0.1793\n","Test loss: 2.2619, Test acccuracy: 0.1785\n","--- Epoch 55 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2558\n","Train batch: 200, Train loss: 2.2725\n","Train batch: 300, Train loss: 2.2579\n","Train batch: 400, Train loss: 2.2715\n","Train batch: 500, Train loss: 2.2605\n","Train batch: 600, Train loss: 2.2806\n","Train batch: 700, Train loss: 2.2575\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2601, Test acccuracy: 0.1796\n","--- Epoch 56 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2879\n","Train batch: 200, Train loss: 2.2522\n","Train batch: 300, Train loss: 2.2455\n","Train batch: 400, Train loss: 2.2390\n","Train batch: 500, Train loss: 2.2578\n","Train batch: 600, Train loss: 2.2493\n","Train batch: 700, Train loss: 2.2914\n","Train loss: 2.2599, Train acccuracy: 0.1789\n","Test loss: 2.2606, Test acccuracy: 0.1791\n","--- Epoch 57 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2905\n","Train batch: 200, Train loss: 2.2427\n","Train batch: 300, Train loss: 2.2859\n","Train batch: 400, Train loss: 2.2892\n","Train batch: 500, Train loss: 2.2731\n","Train batch: 600, Train loss: 2.2792\n","Train batch: 700, Train loss: 2.2253\n","Train loss: 2.2596, Train acccuracy: 0.1800\n","Test loss: 2.2610, Test acccuracy: 0.1776\n","--- Epoch 58 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2607\n","Train batch: 200, Train loss: 2.2581\n","Train batch: 300, Train loss: 2.2214\n","Train batch: 400, Train loss: 2.2482\n","Train batch: 500, Train loss: 2.2478\n","Train batch: 600, Train loss: 2.1940\n","Train batch: 700, Train loss: 2.1978\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2614, Test acccuracy: 0.1784\n","--- Epoch 59 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2381\n","Train batch: 200, Train loss: 2.2366\n","Train batch: 300, Train loss: 2.2475\n","Train batch: 400, Train loss: 2.2701\n","Train batch: 500, Train loss: 2.2797\n","Train batch: 600, Train loss: 2.2501\n","Train batch: 700, Train loss: 2.2121\n","Train loss: 2.2597, Train acccuracy: 0.1790\n","Test loss: 2.2607, Test acccuracy: 0.1790\n","--- Epoch 60 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2619\n","Train batch: 200, Train loss: 2.2743\n","Train batch: 300, Train loss: 2.2636\n","Train batch: 400, Train loss: 2.2858\n","Train batch: 500, Train loss: 2.2647\n","Train batch: 600, Train loss: 2.2862\n","Train batch: 700, Train loss: 2.2769\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2608, Test acccuracy: 0.1778\n","--- Epoch 61 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2581\n","Train batch: 200, Train loss: 2.2743\n","Train batch: 300, Train loss: 2.2849\n","Train batch: 400, Train loss: 2.2507\n","Train batch: 500, Train loss: 2.2423\n","Train batch: 600, Train loss: 2.2684\n","Train batch: 700, Train loss: 2.2649\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2601, Test acccuracy: 0.1789\n","--- Epoch 62 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2478\n","Train batch: 200, Train loss: 2.2279\n","Train batch: 300, Train loss: 2.2817\n","Train batch: 400, Train loss: 2.2709\n","Train batch: 500, Train loss: 2.2218\n","Train batch: 600, Train loss: 2.2708\n","Train batch: 700, Train loss: 2.2434\n","Train loss: 2.2597, Train acccuracy: 0.1793\n","Test loss: 2.2602, Test acccuracy: 0.1784\n","--- Epoch 63 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2869\n","Train batch: 200, Train loss: 2.2480\n","Train batch: 300, Train loss: 2.2876\n","Train batch: 400, Train loss: 2.2575\n","Train batch: 500, Train loss: 2.2380\n","Train batch: 600, Train loss: 2.2428\n","Train batch: 700, Train loss: 2.2477\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2605, Test acccuracy: 0.1776\n","--- Epoch 64 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2554\n","Train batch: 200, Train loss: 2.2902\n","Train batch: 300, Train loss: 2.2429\n","Train batch: 400, Train loss: 2.2540\n","Train batch: 500, Train loss: 2.2488\n","Train batch: 600, Train loss: 2.2399\n","Train batch: 700, Train loss: 2.2642\n","Train loss: 2.2599, Train acccuracy: 0.1797\n","Test loss: 2.2614, Test acccuracy: 0.1784\n","--- Epoch 65 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2429\n","Train batch: 200, Train loss: 2.2920\n","Train batch: 300, Train loss: 2.2782\n","Train batch: 400, Train loss: 2.2379\n","Train batch: 500, Train loss: 2.2447\n","Train batch: 600, Train loss: 2.2875\n","Train batch: 700, Train loss: 2.2446\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2606, Test acccuracy: 0.1780\n","--- Epoch 66 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2365\n","Train batch: 200, Train loss: 2.2826\n","Train batch: 300, Train loss: 2.2438\n","Train batch: 400, Train loss: 2.2761\n","Train batch: 500, Train loss: 2.2353\n","Train batch: 600, Train loss: 2.2497\n","Train batch: 700, Train loss: 2.2235\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2612, Test acccuracy: 0.1792\n","--- Epoch 67 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2596\n","Train batch: 200, Train loss: 2.2691\n","Train batch: 300, Train loss: 2.2683\n","Train batch: 400, Train loss: 2.2716\n","Train batch: 500, Train loss: 2.2570\n","Train batch: 600, Train loss: 2.2374\n","Train batch: 700, Train loss: 2.2481\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2604, Test acccuracy: 0.1782\n","--- Epoch 68 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2914\n","Train batch: 200, Train loss: 2.2749\n","Train batch: 300, Train loss: 2.2306\n","Train batch: 400, Train loss: 2.2683\n","Train batch: 500, Train loss: 2.2858\n","Train batch: 600, Train loss: 2.2515\n","Train batch: 700, Train loss: 2.2535\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2611, Test acccuracy: 0.1792\n","--- Epoch 69 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2153\n","Train batch: 200, Train loss: 2.2712\n","Train batch: 300, Train loss: 2.2280\n","Train batch: 400, Train loss: 2.2440\n","Train batch: 500, Train loss: 2.2723\n","Train batch: 600, Train loss: 2.2367\n","Train batch: 700, Train loss: 2.2952\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2602, Test acccuracy: 0.1786\n","--- Epoch 70 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2838\n","Train batch: 200, Train loss: 2.2776\n","Train batch: 300, Train loss: 2.2587\n","Train batch: 400, Train loss: 2.2587\n","Train batch: 500, Train loss: 2.2470\n","Train batch: 600, Train loss: 2.2477\n","Train batch: 700, Train loss: 2.2366\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2594, Test acccuracy: 0.1802\n","--- Epoch 71 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2723\n","Train batch: 200, Train loss: 2.2983\n","Train batch: 300, Train loss: 2.2460\n","Train batch: 400, Train loss: 2.2641\n","Train batch: 500, Train loss: 2.2846\n","Train batch: 600, Train loss: 2.2009\n","Train batch: 700, Train loss: 2.2714\n","Train loss: 2.2596, Train acccuracy: 0.1799\n","Test loss: 2.2610, Test acccuracy: 0.1765\n","--- Epoch 72 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2754\n","Train batch: 200, Train loss: 2.2799\n","Train batch: 300, Train loss: 2.2950\n","Train batch: 400, Train loss: 2.2184\n","Train batch: 500, Train loss: 2.2501\n","Train batch: 600, Train loss: 2.2436\n","Train batch: 700, Train loss: 2.2440\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2603, Test acccuracy: 0.1790\n","--- Epoch 73 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2412\n","Train batch: 200, Train loss: 2.2645\n","Train batch: 300, Train loss: 2.2680\n","Train batch: 400, Train loss: 2.2523\n","Train batch: 500, Train loss: 2.2932\n","Train batch: 600, Train loss: 2.2574\n","Train batch: 700, Train loss: 2.2734\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2601, Test acccuracy: 0.1778\n","--- Epoch 74 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2271\n","Train batch: 200, Train loss: 2.2224\n","Train batch: 300, Train loss: 2.2487\n","Train batch: 400, Train loss: 2.2937\n","Train batch: 500, Train loss: 2.2533\n","Train batch: 600, Train loss: 2.2339\n","Train batch: 700, Train loss: 2.2791\n","Train loss: 2.2595, Train acccuracy: 0.1792\n","Test loss: 2.2604, Test acccuracy: 0.1797\n","--- Epoch 75 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2333\n","Train batch: 200, Train loss: 2.2832\n","Train batch: 300, Train loss: 2.2558\n","Train batch: 400, Train loss: 2.2460\n","Train batch: 500, Train loss: 2.2207\n","Train batch: 600, Train loss: 2.3073\n","Train batch: 700, Train loss: 2.2434\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2612, Test acccuracy: 0.1767\n","--- Epoch 76 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2695\n","Train batch: 200, Train loss: 2.2832\n","Train batch: 300, Train loss: 2.2803\n","Train batch: 400, Train loss: 2.2705\n","Train batch: 500, Train loss: 2.2495\n","Train batch: 600, Train loss: 2.2026\n","Train batch: 700, Train loss: 2.2267\n","Train loss: 2.2595, Train acccuracy: 0.1800\n","Test loss: 2.2598, Test acccuracy: 0.1792\n","--- Epoch 77 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2655\n","Train batch: 200, Train loss: 2.2959\n","Train batch: 300, Train loss: 2.2683\n","Train batch: 400, Train loss: 2.2627\n","Train batch: 500, Train loss: 2.2464\n","Train batch: 600, Train loss: 2.2748\n","Train batch: 700, Train loss: 2.2559\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2604, Test acccuracy: 0.1786\n","--- Epoch 78 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2656\n","Train batch: 200, Train loss: 2.2252\n","Train batch: 300, Train loss: 2.2393\n","Train batch: 400, Train loss: 2.2657\n","Train batch: 500, Train loss: 2.2604\n","Train batch: 600, Train loss: 2.2874\n","Train batch: 700, Train loss: 2.2387\n","Train loss: 2.2597, Train acccuracy: 0.1791\n","Test loss: 2.2607, Test acccuracy: 0.1781\n","--- Epoch 79 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2457\n","Train batch: 200, Train loss: 2.2450\n","Train batch: 300, Train loss: 2.2509\n","Train batch: 400, Train loss: 2.2680\n","Train batch: 500, Train loss: 2.3081\n","Train batch: 600, Train loss: 2.2657\n","Train batch: 700, Train loss: 2.2623\n","Train loss: 2.2598, Train acccuracy: 0.1797\n","Test loss: 2.2605, Test acccuracy: 0.1773\n","--- Epoch 80 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2693\n","Train batch: 200, Train loss: 2.2462\n","Train batch: 300, Train loss: 2.2621\n","Train batch: 400, Train loss: 2.2665\n","Train batch: 500, Train loss: 2.2711\n","Train batch: 600, Train loss: 2.2988\n","Train batch: 700, Train loss: 2.2489\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2605, Test acccuracy: 0.1794\n","--- Epoch 81 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2831\n","Train batch: 200, Train loss: 2.2473\n","Train batch: 300, Train loss: 2.2703\n","Train batch: 400, Train loss: 2.2445\n","Train batch: 500, Train loss: 2.2827\n","Train batch: 600, Train loss: 2.2889\n","Train batch: 700, Train loss: 2.2548\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2600, Test acccuracy: 0.1784\n","--- Epoch 82 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2746\n","Train batch: 200, Train loss: 2.2660\n","Train batch: 300, Train loss: 2.2830\n","Train batch: 400, Train loss: 2.2648\n","Train batch: 500, Train loss: 2.2977\n","Train batch: 600, Train loss: 2.2422\n","Train batch: 700, Train loss: 2.2103\n","Train loss: 2.2598, Train acccuracy: 0.1796\n","Test loss: 2.2600, Test acccuracy: 0.1787\n","--- Epoch 83 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.3022\n","Train batch: 200, Train loss: 2.2747\n","Train batch: 300, Train loss: 2.3005\n","Train batch: 400, Train loss: 2.2678\n","Train batch: 500, Train loss: 2.2126\n","Train batch: 600, Train loss: 2.2783\n","Train batch: 700, Train loss: 2.2562\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2596, Test acccuracy: 0.1788\n","--- Epoch 84 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2503\n","Train batch: 200, Train loss: 2.2857\n","Train batch: 300, Train loss: 2.2309\n","Train batch: 400, Train loss: 2.2452\n","Train batch: 500, Train loss: 2.2444\n","Train batch: 600, Train loss: 2.2673\n","Train batch: 700, Train loss: 2.2913\n","Train loss: 2.2599, Train acccuracy: 0.1791\n","Test loss: 2.2606, Test acccuracy: 0.1799\n","--- Epoch 85 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2770\n","Train batch: 200, Train loss: 2.2558\n","Train batch: 300, Train loss: 2.2915\n","Train batch: 400, Train loss: 2.2156\n","Train batch: 500, Train loss: 2.2457\n","Train batch: 600, Train loss: 2.2836\n","Train batch: 700, Train loss: 2.3016\n","Train loss: 2.2598, Train acccuracy: 0.1801\n","Test loss: 2.2600, Test acccuracy: 0.1786\n","--- Epoch 86 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2207\n","Train batch: 200, Train loss: 2.2741\n","Train batch: 300, Train loss: 2.2372\n","Train batch: 400, Train loss: 2.2812\n","Train batch: 500, Train loss: 2.2279\n","Train batch: 600, Train loss: 2.2411\n","Train batch: 700, Train loss: 2.2502\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2609, Test acccuracy: 0.1791\n","--- Epoch 87 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2366\n","Train batch: 200, Train loss: 2.2286\n","Train batch: 300, Train loss: 2.2819\n","Train batch: 400, Train loss: 2.2642\n","Train batch: 500, Train loss: 2.2179\n","Train batch: 600, Train loss: 2.2329\n","Train batch: 700, Train loss: 2.2618\n","Train loss: 2.2598, Train acccuracy: 0.1793\n","Test loss: 2.2615, Test acccuracy: 0.1776\n","--- Epoch 88 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2526\n","Train batch: 200, Train loss: 2.2564\n","Train batch: 300, Train loss: 2.2409\n","Train batch: 400, Train loss: 2.2459\n","Train batch: 500, Train loss: 2.2553\n","Train batch: 600, Train loss: 2.2364\n","Train batch: 700, Train loss: 2.2583\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2598, Test acccuracy: 0.1795\n","--- Epoch 89 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2722\n","Train batch: 200, Train loss: 2.1857\n","Train batch: 300, Train loss: 2.2872\n","Train batch: 400, Train loss: 2.2919\n","Train batch: 500, Train loss: 2.2465\n","Train batch: 600, Train loss: 2.2985\n","Train batch: 700, Train loss: 2.2690\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2599, Test acccuracy: 0.1792\n","--- Epoch 90 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2669\n","Train batch: 200, Train loss: 2.2624\n","Train batch: 300, Train loss: 2.2500\n","Train batch: 400, Train loss: 2.2831\n","Train batch: 500, Train loss: 2.2716\n","Train batch: 600, Train loss: 2.2649\n","Train batch: 700, Train loss: 2.2597\n","Train loss: 2.2597, Train acccuracy: 0.1803\n","Test loss: 2.2602, Test acccuracy: 0.1783\n","--- Epoch 91 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2265\n","Train batch: 200, Train loss: 2.2762\n","Train batch: 300, Train loss: 2.2519\n","Train batch: 400, Train loss: 2.2459\n","Train batch: 500, Train loss: 2.2386\n","Train batch: 600, Train loss: 2.2985\n","Train batch: 700, Train loss: 2.2723\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2604, Test acccuracy: 0.1784\n","--- Epoch 92 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2309\n","Train batch: 200, Train loss: 2.2599\n","Train batch: 300, Train loss: 2.2693\n","Train batch: 400, Train loss: 2.2477\n","Train batch: 500, Train loss: 2.2527\n","Train batch: 600, Train loss: 2.2682\n","Train batch: 700, Train loss: 2.2706\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2609, Test acccuracy: 0.1776\n","--- Epoch 93 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2515\n","Train batch: 200, Train loss: 2.2523\n","Train batch: 300, Train loss: 2.2061\n","Train batch: 400, Train loss: 2.2803\n","Train batch: 500, Train loss: 2.2578\n","Train batch: 600, Train loss: 2.2546\n","Train batch: 700, Train loss: 2.2523\n","Train loss: 2.2598, Train acccuracy: 0.1793\n","Test loss: 2.2610, Test acccuracy: 0.1785\n","--- Epoch 94 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2993\n","Train batch: 200, Train loss: 2.2276\n","Train batch: 300, Train loss: 2.2705\n","Train batch: 400, Train loss: 2.2346\n","Train batch: 500, Train loss: 2.2764\n","Train batch: 600, Train loss: 2.2424\n","Train batch: 700, Train loss: 2.2419\n","Train loss: 2.2598, Train acccuracy: 0.1791\n","Test loss: 2.2602, Test acccuracy: 0.1796\n","--- Epoch 95 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2968\n","Train batch: 200, Train loss: 2.2561\n","Train batch: 300, Train loss: 2.2250\n","Train batch: 400, Train loss: 2.2574\n","Train batch: 500, Train loss: 2.2372\n","Train batch: 600, Train loss: 2.2477\n","Train batch: 700, Train loss: 2.2757\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2602, Test acccuracy: 0.1744\n","--- Epoch 96 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2511\n","Train batch: 200, Train loss: 2.2471\n","Train batch: 300, Train loss: 2.2903\n","Train batch: 400, Train loss: 2.2508\n","Train batch: 500, Train loss: 2.2727\n","Train batch: 600, Train loss: 2.2905\n","Train batch: 700, Train loss: 2.2882\n","Train loss: 2.2595, Train acccuracy: 0.1797\n","Test loss: 2.2610, Test acccuracy: 0.1780\n","--- Epoch 97 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2632\n","Train batch: 200, Train loss: 2.2797\n","Train batch: 300, Train loss: 2.2610\n","Train batch: 400, Train loss: 2.2793\n","Train batch: 500, Train loss: 2.2590\n","Train batch: 600, Train loss: 2.2450\n","Train batch: 700, Train loss: 2.2620\n","Train loss: 2.2598, Train acccuracy: 0.1792\n","Test loss: 2.2601, Test acccuracy: 0.1800\n","--- Epoch 98 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2726\n","Train batch: 200, Train loss: 2.2520\n","Train batch: 300, Train loss: 2.2983\n","Train batch: 400, Train loss: 2.2540\n","Train batch: 500, Train loss: 2.2710\n","Train batch: 600, Train loss: 2.2365\n","Train batch: 700, Train loss: 2.2531\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2604, Test acccuracy: 0.1788\n","--- Epoch 99 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2682\n","Train batch: 200, Train loss: 2.2711\n","Train batch: 300, Train loss: 2.2633\n","Train batch: 400, Train loss: 2.2506\n","Train batch: 500, Train loss: 2.2511\n","Train batch: 600, Train loss: 2.2972\n","Train batch: 700, Train loss: 2.2613\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2604, Test acccuracy: 0.1791\n","--- Epoch 100 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2881\n","Train batch: 200, Train loss: 2.2637\n","Train batch: 300, Train loss: 2.2765\n","Train batch: 400, Train loss: 2.2774\n","Train batch: 500, Train loss: 2.2897\n","Train batch: 600, Train loss: 2.2706\n","Train batch: 700, Train loss: 2.2434\n","Train loss: 2.2596, Train acccuracy: 0.1797\n","Test loss: 2.2614, Test acccuracy: 0.1782\n","--- Epoch 101 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2507\n","Train batch: 200, Train loss: 2.2532\n","Train batch: 300, Train loss: 2.2678\n","Train batch: 400, Train loss: 2.2943\n","Train batch: 500, Train loss: 2.2836\n","Train batch: 600, Train loss: 2.2116\n","Train batch: 700, Train loss: 2.2393\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2607, Test acccuracy: 0.1773\n","--- Epoch 102 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2761\n","Train batch: 200, Train loss: 2.2879\n","Train batch: 300, Train loss: 2.2687\n","Train batch: 400, Train loss: 2.3012\n","Train batch: 500, Train loss: 2.2246\n","Train batch: 600, Train loss: 2.2518\n","Train batch: 700, Train loss: 2.2486\n","Train loss: 2.2598, Train acccuracy: 0.1793\n","Test loss: 2.2612, Test acccuracy: 0.1792\n","--- Epoch 103 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2394\n","Train batch: 200, Train loss: 2.2510\n","Train batch: 300, Train loss: 2.2734\n","Train batch: 400, Train loss: 2.2170\n","Train batch: 500, Train loss: 2.2466\n","Train batch: 600, Train loss: 2.2702\n","Train batch: 700, Train loss: 2.2465\n","Train loss: 2.2597, Train acccuracy: 0.1801\n","Test loss: 2.2604, Test acccuracy: 0.1783\n","--- Epoch 104 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2742\n","Train batch: 200, Train loss: 2.2657\n","Train batch: 300, Train loss: 2.2719\n","Train batch: 400, Train loss: 2.2353\n","Train batch: 500, Train loss: 2.2722\n","Train batch: 600, Train loss: 2.2569\n","Train batch: 700, Train loss: 2.2651\n","Train loss: 2.2598, Train acccuracy: 0.1799\n","Test loss: 2.2596, Test acccuracy: 0.1777\n","--- Epoch 105 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2593\n","Train batch: 200, Train loss: 2.2379\n","Train batch: 300, Train loss: 2.3036\n","Train batch: 400, Train loss: 2.2473\n","Train batch: 500, Train loss: 2.2397\n","Train batch: 600, Train loss: 2.2735\n","Train batch: 700, Train loss: 2.2525\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2598, Test acccuracy: 0.1793\n","--- Epoch 106 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2556\n","Train batch: 200, Train loss: 2.2906\n","Train batch: 300, Train loss: 2.2487\n","Train batch: 400, Train loss: 2.2852\n","Train batch: 500, Train loss: 2.2880\n","Train batch: 600, Train loss: 2.2401\n","Train batch: 700, Train loss: 2.2584\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2614, Test acccuracy: 0.1790\n","--- Epoch 107 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2462\n","Train batch: 200, Train loss: 2.2590\n","Train batch: 300, Train loss: 2.2168\n","Train batch: 400, Train loss: 2.2463\n","Train batch: 500, Train loss: 2.2725\n","Train batch: 600, Train loss: 2.2542\n","Train batch: 700, Train loss: 2.2485\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2607, Test acccuracy: 0.1777\n","--- Epoch 108 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2583\n","Train batch: 200, Train loss: 2.2383\n","Train batch: 300, Train loss: 2.2630\n","Train batch: 400, Train loss: 2.2453\n","Train batch: 500, Train loss: 2.2756\n","Train batch: 600, Train loss: 2.2744\n","Train batch: 700, Train loss: 2.2412\n","Train loss: 2.2599, Train acccuracy: 0.1792\n","Test loss: 2.2611, Test acccuracy: 0.1792\n","--- Epoch 109 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2726\n","Train batch: 200, Train loss: 2.2633\n","Train batch: 300, Train loss: 2.2489\n","Train batch: 400, Train loss: 2.2281\n","Train batch: 500, Train loss: 2.1987\n","Train batch: 600, Train loss: 2.2597\n","Train batch: 700, Train loss: 2.2371\n","Train loss: 2.2595, Train acccuracy: 0.1800\n","Test loss: 2.2609, Test acccuracy: 0.1776\n","--- Epoch 110 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2262\n","Train batch: 200, Train loss: 2.2845\n","Train batch: 300, Train loss: 2.2473\n","Train batch: 400, Train loss: 2.2774\n","Train batch: 500, Train loss: 2.2569\n","Train batch: 600, Train loss: 2.2726\n","Train batch: 700, Train loss: 2.2858\n","Train loss: 2.2599, Train acccuracy: 0.1789\n","Test loss: 2.2608, Test acccuracy: 0.1789\n","--- Epoch 111 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2294\n","Train batch: 200, Train loss: 2.2474\n","Train batch: 300, Train loss: 2.2318\n","Train batch: 400, Train loss: 2.2446\n","Train batch: 500, Train loss: 2.2482\n","Train batch: 600, Train loss: 2.2348\n","Train batch: 700, Train loss: 2.2713\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2613, Test acccuracy: 0.1770\n","--- Epoch 112 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2488\n","Train batch: 200, Train loss: 2.2737\n","Train batch: 300, Train loss: 2.2478\n","Train batch: 400, Train loss: 2.2440\n","Train batch: 500, Train loss: 2.2685\n","Train batch: 600, Train loss: 2.2632\n","Train batch: 700, Train loss: 2.2553\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2602, Test acccuracy: 0.1786\n","--- Epoch 113 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2547\n","Train batch: 200, Train loss: 2.2515\n","Train batch: 300, Train loss: 2.2573\n","Train batch: 400, Train loss: 2.2592\n","Train batch: 500, Train loss: 2.2123\n","Train batch: 600, Train loss: 2.2576\n","Train batch: 700, Train loss: 2.2688\n","Train loss: 2.2597, Train acccuracy: 0.1793\n","Test loss: 2.2609, Test acccuracy: 0.1777\n","--- Epoch 114 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2373\n","Train batch: 200, Train loss: 2.2691\n","Train batch: 300, Train loss: 2.2419\n","Train batch: 400, Train loss: 2.2571\n","Train batch: 500, Train loss: 2.2508\n","Train batch: 600, Train loss: 2.2989\n","Train batch: 700, Train loss: 2.2470\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2603, Test acccuracy: 0.1790\n","--- Epoch 115 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2811\n","Train batch: 200, Train loss: 2.2867\n","Train batch: 300, Train loss: 2.2003\n","Train batch: 400, Train loss: 2.2602\n","Train batch: 500, Train loss: 2.2648\n","Train batch: 600, Train loss: 2.2767\n","Train batch: 700, Train loss: 2.2584\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2606, Test acccuracy: 0.1789\n","--- Epoch 116 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2554\n","Train batch: 200, Train loss: 2.2477\n","Train batch: 300, Train loss: 2.2700\n","Train batch: 400, Train loss: 2.2848\n","Train batch: 500, Train loss: 2.2501\n","Train batch: 600, Train loss: 2.2691\n","Train batch: 700, Train loss: 2.2814\n","Train loss: 2.2597, Train acccuracy: 0.1801\n","Test loss: 2.2606, Test acccuracy: 0.1778\n","--- Epoch 117 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2195\n","Train batch: 200, Train loss: 2.2897\n","Train batch: 300, Train loss: 2.2575\n","Train batch: 400, Train loss: 2.2447\n","Train batch: 500, Train loss: 2.2852\n","Train batch: 600, Train loss: 2.2643\n","Train batch: 700, Train loss: 2.2589\n","Train loss: 2.2597, Train acccuracy: 0.1791\n","Test loss: 2.2604, Test acccuracy: 0.1783\n","--- Epoch 118 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2856\n","Train batch: 200, Train loss: 2.2855\n","Train batch: 300, Train loss: 2.2381\n","Train batch: 400, Train loss: 2.2660\n","Train batch: 500, Train loss: 2.2621\n","Train batch: 600, Train loss: 2.2779\n","Train batch: 700, Train loss: 2.2352\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2612, Test acccuracy: 0.1783\n","--- Epoch 119 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2725\n","Train batch: 200, Train loss: 2.2582\n","Train batch: 300, Train loss: 2.2229\n","Train batch: 400, Train loss: 2.2353\n","Train batch: 500, Train loss: 2.2905\n","Train batch: 600, Train loss: 2.2593\n","Train batch: 700, Train loss: 2.2765\n","Train loss: 2.2598, Train acccuracy: 0.1796\n","Test loss: 2.2601, Test acccuracy: 0.1791\n","--- Epoch 120 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2664\n","Train batch: 200, Train loss: 2.2741\n","Train batch: 300, Train loss: 2.2669\n","Train batch: 400, Train loss: 2.2688\n","Train batch: 500, Train loss: 2.2630\n","Train batch: 600, Train loss: 2.2675\n","Train batch: 700, Train loss: 2.2679\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2605, Test acccuracy: 0.1783\n","--- Epoch 121 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2831\n","Train batch: 200, Train loss: 2.2702\n","Train batch: 300, Train loss: 2.2694\n","Train batch: 400, Train loss: 2.2426\n","Train batch: 500, Train loss: 2.2136\n","Train batch: 600, Train loss: 2.2636\n","Train batch: 700, Train loss: 2.2800\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2607, Test acccuracy: 0.1797\n","--- Epoch 122 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2594\n","Train batch: 200, Train loss: 2.2780\n","Train batch: 300, Train loss: 2.2622\n","Train batch: 400, Train loss: 2.2910\n","Train batch: 500, Train loss: 2.2435\n","Train batch: 600, Train loss: 2.2452\n","Train batch: 700, Train loss: 2.2778\n","Train loss: 2.2597, Train acccuracy: 0.1803\n","Test loss: 2.2607, Test acccuracy: 0.1781\n","--- Epoch 123 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2201\n","Train batch: 200, Train loss: 2.2813\n","Train batch: 300, Train loss: 2.2418\n","Train batch: 400, Train loss: 2.2341\n","Train batch: 500, Train loss: 2.2184\n","Train batch: 600, Train loss: 2.2609\n","Train batch: 700, Train loss: 2.2493\n","Train loss: 2.2598, Train acccuracy: 0.1791\n","Test loss: 2.2606, Test acccuracy: 0.1787\n","--- Epoch 124 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2559\n","Train batch: 200, Train loss: 2.2522\n","Train batch: 300, Train loss: 2.2537\n","Train batch: 400, Train loss: 2.2258\n","Train batch: 500, Train loss: 2.2234\n","Train batch: 600, Train loss: 2.2279\n","Train batch: 700, Train loss: 2.2533\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2601, Test acccuracy: 0.1773\n","--- Epoch 125 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2415\n","Train batch: 200, Train loss: 2.2580\n","Train batch: 300, Train loss: 2.2512\n","Train batch: 400, Train loss: 2.2838\n","Train batch: 500, Train loss: 2.2646\n","Train batch: 600, Train loss: 2.2681\n","Train batch: 700, Train loss: 2.2457\n","Train loss: 2.2598, Train acccuracy: 0.1791\n","Test loss: 2.2609, Test acccuracy: 0.1788\n","--- Epoch 126 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2507\n","Train batch: 200, Train loss: 2.2542\n","Train batch: 300, Train loss: 2.2230\n","Train batch: 400, Train loss: 2.2620\n","Train batch: 500, Train loss: 2.2567\n","Train batch: 600, Train loss: 2.2951\n","Train batch: 700, Train loss: 2.2853\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2600, Test acccuracy: 0.1790\n","--- Epoch 127 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2326\n","Train batch: 200, Train loss: 2.2895\n","Train batch: 300, Train loss: 2.2650\n","Train batch: 400, Train loss: 2.2812\n","Train batch: 500, Train loss: 2.2743\n","Train batch: 600, Train loss: 2.2537\n","Train batch: 700, Train loss: 2.2587\n","Train loss: 2.2595, Train acccuracy: 0.1791\n","Test loss: 2.2609, Test acccuracy: 0.1800\n","--- Epoch 128 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2331\n","Train batch: 200, Train loss: 2.2408\n","Train batch: 300, Train loss: 2.2624\n","Train batch: 400, Train loss: 2.2633\n","Train batch: 500, Train loss: 2.2871\n","Train batch: 600, Train loss: 2.2745\n","Train batch: 700, Train loss: 2.2682\n","Train loss: 2.2599, Train acccuracy: 0.1796\n","Test loss: 2.2608, Test acccuracy: 0.1783\n","--- Epoch 129 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2299\n","Train batch: 200, Train loss: 2.2919\n","Train batch: 300, Train loss: 2.2549\n","Train batch: 400, Train loss: 2.2703\n","Train batch: 500, Train loss: 2.3068\n","Train batch: 600, Train loss: 2.2565\n","Train batch: 700, Train loss: 2.2996\n","Train loss: 2.2597, Train acccuracy: 0.1793\n","Test loss: 2.2613, Test acccuracy: 0.1783\n","--- Epoch 130 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2590\n","Train batch: 200, Train loss: 2.2789\n","Train batch: 300, Train loss: 2.2605\n","Train batch: 400, Train loss: 2.2308\n","Train batch: 500, Train loss: 2.2441\n","Train batch: 600, Train loss: 2.2383\n","Train batch: 700, Train loss: 2.2724\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2598, Test acccuracy: 0.1796\n","--- Epoch 131 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2643\n","Train batch: 200, Train loss: 2.2579\n","Train batch: 300, Train loss: 2.2595\n","Train batch: 400, Train loss: 2.2752\n","Train batch: 500, Train loss: 2.2692\n","Train batch: 600, Train loss: 2.2709\n","Train batch: 700, Train loss: 2.2539\n","Train loss: 2.2595, Train acccuracy: 0.1798\n","Test loss: 2.2609, Test acccuracy: 0.1776\n","--- Epoch 132 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2698\n","Train batch: 200, Train loss: 2.2768\n","Train batch: 300, Train loss: 2.2795\n","Train batch: 400, Train loss: 2.2444\n","Train batch: 500, Train loss: 2.2833\n","Train batch: 600, Train loss: 2.2825\n","Train batch: 700, Train loss: 2.2702\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2618, Test acccuracy: 0.1794\n","--- Epoch 133 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2855\n","Train batch: 200, Train loss: 2.2890\n","Train batch: 300, Train loss: 2.2489\n","Train batch: 400, Train loss: 2.2603\n","Train batch: 500, Train loss: 2.2602\n","Train batch: 600, Train loss: 2.2595\n","Train batch: 700, Train loss: 2.2662\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2602, Test acccuracy: 0.1781\n","--- Epoch 134 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2424\n","Train batch: 200, Train loss: 2.2389\n","Train batch: 300, Train loss: 2.2551\n","Train batch: 400, Train loss: 2.2671\n","Train batch: 500, Train loss: 2.2365\n","Train batch: 600, Train loss: 2.2755\n","Train batch: 700, Train loss: 2.2438\n","Train loss: 2.2596, Train acccuracy: 0.1792\n","Test loss: 2.2604, Test acccuracy: 0.1795\n","--- Epoch 135 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2541\n","Train batch: 200, Train loss: 2.2440\n","Train batch: 300, Train loss: 2.2729\n","Train batch: 400, Train loss: 2.2606\n","Train batch: 500, Train loss: 2.2791\n","Train batch: 600, Train loss: 2.2345\n","Train batch: 700, Train loss: 2.2398\n","Train loss: 2.2598, Train acccuracy: 0.1793\n","Test loss: 2.2606, Test acccuracy: 0.1782\n","--- Epoch 136 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2355\n","Train batch: 200, Train loss: 2.2584\n","Train batch: 300, Train loss: 2.2775\n","Train batch: 400, Train loss: 2.2893\n","Train batch: 500, Train loss: 2.2822\n","Train batch: 600, Train loss: 2.2871\n","Train batch: 700, Train loss: 2.2522\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2605, Test acccuracy: 0.1792\n","--- Epoch 137 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2343\n","Train batch: 200, Train loss: 2.2434\n","Train batch: 300, Train loss: 2.2533\n","Train batch: 400, Train loss: 2.2570\n","Train batch: 500, Train loss: 2.2551\n","Train batch: 600, Train loss: 2.2595\n","Train batch: 700, Train loss: 2.2693\n","Train loss: 2.2597, Train acccuracy: 0.1802\n","Test loss: 2.2611, Test acccuracy: 0.1777\n","--- Epoch 138 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2541\n","Train batch: 200, Train loss: 2.2652\n","Train batch: 300, Train loss: 2.2616\n","Train batch: 400, Train loss: 2.2741\n","Train batch: 500, Train loss: 2.2341\n","Train batch: 600, Train loss: 2.2430\n","Train batch: 700, Train loss: 2.2753\n","Train loss: 2.2597, Train acccuracy: 0.1788\n","Test loss: 2.2618, Test acccuracy: 0.1801\n","--- Epoch 139 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2809\n","Train batch: 200, Train loss: 2.2789\n","Train batch: 300, Train loss: 2.2874\n","Train batch: 400, Train loss: 2.2586\n","Train batch: 500, Train loss: 2.2701\n","Train batch: 600, Train loss: 2.2506\n","Train batch: 700, Train loss: 2.2673\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2603, Test acccuracy: 0.1780\n","--- Epoch 140 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2749\n","Train batch: 200, Train loss: 2.2743\n","Train batch: 300, Train loss: 2.2459\n","Train batch: 400, Train loss: 2.2546\n","Train batch: 500, Train loss: 2.2868\n","Train batch: 600, Train loss: 2.2412\n","Train batch: 700, Train loss: 2.2517\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2602, Test acccuracy: 0.1795\n","--- Epoch 141 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2442\n","Train batch: 200, Train loss: 2.2554\n","Train batch: 300, Train loss: 2.2717\n","Train batch: 400, Train loss: 2.2739\n","Train batch: 500, Train loss: 2.2881\n","Train batch: 600, Train loss: 2.2685\n","Train batch: 700, Train loss: 2.2388\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2601, Test acccuracy: 0.1787\n","--- Epoch 142 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2907\n","Train batch: 200, Train loss: 2.2409\n","Train batch: 300, Train loss: 2.2140\n","Train batch: 400, Train loss: 2.2776\n","Train batch: 500, Train loss: 2.2941\n","Train batch: 600, Train loss: 2.2516\n","Train batch: 700, Train loss: 2.2376\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2602, Test acccuracy: 0.1783\n","--- Epoch 143 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2296\n","Train batch: 200, Train loss: 2.2508\n","Train batch: 300, Train loss: 2.2545\n","Train batch: 400, Train loss: 2.2784\n","Train batch: 500, Train loss: 2.2900\n","Train batch: 600, Train loss: 2.2407\n","Train batch: 700, Train loss: 2.2585\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2611, Test acccuracy: 0.1784\n","--- Epoch 144 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2451\n","Train batch: 200, Train loss: 2.2748\n","Train batch: 300, Train loss: 2.2735\n","Train batch: 400, Train loss: 2.2824\n","Train batch: 500, Train loss: 2.2539\n","Train batch: 600, Train loss: 2.2548\n","Train batch: 700, Train loss: 2.2649\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2603, Test acccuracy: 0.1780\n","--- Epoch 145 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2489\n","Train batch: 200, Train loss: 2.2542\n","Train batch: 300, Train loss: 2.2523\n","Train batch: 400, Train loss: 2.2637\n","Train batch: 500, Train loss: 2.2423\n","Train batch: 600, Train loss: 2.2745\n","Train batch: 700, Train loss: 2.2587\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2603, Test acccuracy: 0.1789\n","--- Epoch 146 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2733\n","Train batch: 200, Train loss: 2.2369\n","Train batch: 300, Train loss: 2.2577\n","Train batch: 400, Train loss: 2.2751\n","Train batch: 500, Train loss: 2.2424\n","Train batch: 600, Train loss: 2.2611\n","Train batch: 700, Train loss: 2.2360\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2605, Test acccuracy: 0.1784\n","--- Epoch 147 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2263\n","Train batch: 200, Train loss: 2.2102\n","Train batch: 300, Train loss: 2.2402\n","Train batch: 400, Train loss: 2.2633\n","Train batch: 500, Train loss: 2.2225\n","Train batch: 600, Train loss: 2.2582\n","Train batch: 700, Train loss: 2.2382\n","Train loss: 2.2595, Train acccuracy: 0.1792\n","Test loss: 2.2606, Test acccuracy: 0.1793\n","--- Epoch 148 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2718\n","Train batch: 200, Train loss: 2.2696\n","Train batch: 300, Train loss: 2.2504\n","Train batch: 400, Train loss: 2.2648\n","Train batch: 500, Train loss: 2.2521\n","Train batch: 600, Train loss: 2.2634\n","Train batch: 700, Train loss: 2.2302\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2601, Test acccuracy: 0.1781\n","--- Epoch 149 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2667\n","Train batch: 200, Train loss: 2.2652\n","Train batch: 300, Train loss: 2.2551\n","Train batch: 400, Train loss: 2.2476\n","Train batch: 500, Train loss: 2.2580\n","Train batch: 600, Train loss: 2.2922\n","Train batch: 700, Train loss: 2.2423\n","Train loss: 2.2597, Train acccuracy: 0.1799\n","Test loss: 2.2601, Test acccuracy: 0.1789\n","--- Epoch 150 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2582\n","Train batch: 200, Train loss: 2.2729\n","Train batch: 300, Train loss: 2.2828\n","Train batch: 400, Train loss: 2.2776\n","Train batch: 500, Train loss: 2.2605\n","Train batch: 600, Train loss: 2.2699\n","Train batch: 700, Train loss: 2.2781\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2603, Test acccuracy: 0.1790\n","--- Epoch 151 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2746\n","Train batch: 200, Train loss: 2.2825\n","Train batch: 300, Train loss: 2.2762\n","Train batch: 400, Train loss: 2.2911\n","Train batch: 500, Train loss: 2.2937\n","Train batch: 600, Train loss: 2.2644\n","Train batch: 700, Train loss: 2.2226\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2605, Test acccuracy: 0.1784\n","--- Epoch 152 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2914\n","Train batch: 200, Train loss: 2.2690\n","Train batch: 300, Train loss: 2.2491\n","Train batch: 400, Train loss: 2.2357\n","Train batch: 500, Train loss: 2.2610\n","Train batch: 600, Train loss: 2.2679\n","Train batch: 700, Train loss: 2.2593\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2603, Test acccuracy: 0.1783\n","--- Epoch 153 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2904\n","Train batch: 200, Train loss: 2.2595\n","Train batch: 300, Train loss: 2.2668\n","Train batch: 400, Train loss: 2.2480\n","Train batch: 500, Train loss: 2.2589\n","Train batch: 600, Train loss: 2.2723\n","Train batch: 700, Train loss: 2.2682\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2613, Test acccuracy: 0.1786\n","--- Epoch 154 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2185\n","Train batch: 200, Train loss: 2.2580\n","Train batch: 300, Train loss: 2.2410\n","Train batch: 400, Train loss: 2.2676\n","Train batch: 500, Train loss: 2.2884\n","Train batch: 600, Train loss: 2.2594\n","Train batch: 700, Train loss: 2.2700\n","Train loss: 2.2597, Train acccuracy: 0.1793\n","Test loss: 2.2600, Test acccuracy: 0.1793\n","--- Epoch 155 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2803\n","Train batch: 200, Train loss: 2.2908\n","Train batch: 300, Train loss: 2.2698\n","Train batch: 400, Train loss: 2.2732\n","Train batch: 500, Train loss: 2.2631\n","Train batch: 600, Train loss: 2.2991\n","Train batch: 700, Train loss: 2.2937\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2603, Test acccuracy: 0.1780\n","--- Epoch 156 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2802\n","Train batch: 200, Train loss: 2.2763\n","Train batch: 300, Train loss: 2.2409\n","Train batch: 400, Train loss: 2.2798\n","Train batch: 500, Train loss: 2.2469\n","Train batch: 600, Train loss: 2.2362\n","Train batch: 700, Train loss: 2.2680\n","Train loss: 2.2598, Train acccuracy: 0.1790\n","Test loss: 2.2609, Test acccuracy: 0.1777\n","--- Epoch 157 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2800\n","Train batch: 200, Train loss: 2.2812\n","Train batch: 300, Train loss: 2.2502\n","Train batch: 400, Train loss: 2.2812\n","Train batch: 500, Train loss: 2.2738\n","Train batch: 600, Train loss: 2.2731\n","Train batch: 700, Train loss: 2.2584\n","Train loss: 2.2595, Train acccuracy: 0.1795\n","Test loss: 2.2605, Test acccuracy: 0.1786\n","--- Epoch 158 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2720\n","Train batch: 200, Train loss: 2.2342\n","Train batch: 300, Train loss: 2.2799\n","Train batch: 400, Train loss: 2.2678\n","Train batch: 500, Train loss: 2.2486\n","Train batch: 600, Train loss: 2.2633\n","Train batch: 700, Train loss: 2.2671\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2604, Test acccuracy: 0.1791\n","--- Epoch 159 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2668\n","Train batch: 200, Train loss: 2.2980\n","Train batch: 300, Train loss: 2.2717\n","Train batch: 400, Train loss: 2.2294\n","Train batch: 500, Train loss: 2.2606\n","Train batch: 600, Train loss: 2.2449\n","Train batch: 700, Train loss: 2.2781\n","Train loss: 2.2599, Train acccuracy: 0.1791\n","Test loss: 2.2604, Test acccuracy: 0.1769\n","--- Epoch 160 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2310\n","Train batch: 200, Train loss: 2.2566\n","Train batch: 300, Train loss: 2.2331\n","Train batch: 400, Train loss: 2.2525\n","Train batch: 500, Train loss: 2.2673\n","Train batch: 600, Train loss: 2.2688\n","Train batch: 700, Train loss: 2.2487\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2601, Test acccuracy: 0.1788\n","--- Epoch 161 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2496\n","Train batch: 200, Train loss: 2.2184\n","Train batch: 300, Train loss: 2.2649\n","Train batch: 400, Train loss: 2.2804\n","Train batch: 500, Train loss: 2.2855\n","Train batch: 600, Train loss: 2.2251\n","Train batch: 700, Train loss: 2.2924\n","Train loss: 2.2596, Train acccuracy: 0.1799\n","Test loss: 2.2618, Test acccuracy: 0.1795\n","--- Epoch 162 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2127\n","Train batch: 200, Train loss: 2.2664\n","Train batch: 300, Train loss: 2.2332\n","Train batch: 400, Train loss: 2.2417\n","Train batch: 500, Train loss: 2.2688\n","Train batch: 600, Train loss: 2.2677\n","Train batch: 700, Train loss: 2.2808\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2609, Test acccuracy: 0.1776\n","--- Epoch 163 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2928\n","Train batch: 200, Train loss: 2.2242\n","Train batch: 300, Train loss: 2.2715\n","Train batch: 400, Train loss: 2.2298\n","Train batch: 500, Train loss: 2.2640\n","Train batch: 600, Train loss: 2.2289\n","Train batch: 700, Train loss: 2.2887\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2600, Test acccuracy: 0.1786\n","--- Epoch 164 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2928\n","Train batch: 200, Train loss: 2.2746\n","Train batch: 300, Train loss: 2.2936\n","Train batch: 400, Train loss: 2.2767\n","Train batch: 500, Train loss: 2.2165\n","Train batch: 600, Train loss: 2.2709\n","Train batch: 700, Train loss: 2.2693\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2613, Test acccuracy: 0.1764\n","--- Epoch 165 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2518\n","Train batch: 200, Train loss: 2.2682\n","Train batch: 300, Train loss: 2.2524\n","Train batch: 400, Train loss: 2.2569\n","Train batch: 500, Train loss: 2.2368\n","Train batch: 600, Train loss: 2.2725\n","Train batch: 700, Train loss: 2.2673\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2609, Test acccuracy: 0.1784\n","--- Epoch 166 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2160\n","Train batch: 200, Train loss: 2.2350\n","Train batch: 300, Train loss: 2.2709\n","Train batch: 400, Train loss: 2.2601\n","Train batch: 500, Train loss: 2.2468\n","Train batch: 600, Train loss: 2.2946\n","Train batch: 700, Train loss: 2.2788\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2610, Test acccuracy: 0.1786\n","--- Epoch 167 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2793\n","Train batch: 200, Train loss: 2.2645\n","Train batch: 300, Train loss: 2.2787\n","Train batch: 400, Train loss: 2.2375\n","Train batch: 500, Train loss: 2.2164\n","Train batch: 600, Train loss: 2.2653\n","Train batch: 700, Train loss: 2.2422\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2605, Test acccuracy: 0.1799\n","--- Epoch 168 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2863\n","Train batch: 200, Train loss: 2.2530\n","Train batch: 300, Train loss: 2.2343\n","Train batch: 400, Train loss: 2.2560\n","Train batch: 500, Train loss: 2.2746\n","Train batch: 600, Train loss: 2.2140\n","Train batch: 700, Train loss: 2.2432\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2613, Test acccuracy: 0.1785\n","--- Epoch 169 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2409\n","Train batch: 200, Train loss: 2.2611\n","Train batch: 300, Train loss: 2.2606\n","Train batch: 400, Train loss: 2.2711\n","Train batch: 500, Train loss: 2.2897\n","Train batch: 600, Train loss: 2.2350\n","Train batch: 700, Train loss: 2.2438\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2623, Test acccuracy: 0.1795\n","--- Epoch 170 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2795\n","Train batch: 200, Train loss: 2.2578\n","Train batch: 300, Train loss: 2.2680\n","Train batch: 400, Train loss: 2.2588\n","Train batch: 500, Train loss: 2.2845\n","Train batch: 600, Train loss: 2.2106\n","Train batch: 700, Train loss: 2.2630\n","Train loss: 2.2598, Train acccuracy: 0.1796\n","Test loss: 2.2600, Test acccuracy: 0.1796\n","--- Epoch 171 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2428\n","Train batch: 200, Train loss: 2.2911\n","Train batch: 300, Train loss: 2.2953\n","Train batch: 400, Train loss: 2.2843\n","Train batch: 500, Train loss: 2.2772\n","Train batch: 600, Train loss: 2.2700\n","Train batch: 700, Train loss: 2.2867\n","Train loss: 2.2594, Train acccuracy: 0.1799\n","Test loss: 2.2610, Test acccuracy: 0.1778\n","--- Epoch 172 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2780\n","Train batch: 200, Train loss: 2.2606\n","Train batch: 300, Train loss: 2.2418\n","Train batch: 400, Train loss: 2.2668\n","Train batch: 500, Train loss: 2.2233\n","Train batch: 600, Train loss: 2.2647\n","Train batch: 700, Train loss: 2.2703\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2604, Test acccuracy: 0.1786\n","--- Epoch 173 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2545\n","Train batch: 200, Train loss: 2.2419\n","Train batch: 300, Train loss: 2.2789\n","Train batch: 400, Train loss: 2.2446\n","Train batch: 500, Train loss: 2.2343\n","Train batch: 600, Train loss: 2.2643\n","Train batch: 700, Train loss: 2.2249\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2597, Test acccuracy: 0.1790\n","--- Epoch 174 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2409\n","Train batch: 200, Train loss: 2.2264\n","Train batch: 300, Train loss: 2.2903\n","Train batch: 400, Train loss: 2.2560\n","Train batch: 500, Train loss: 2.2532\n","Train batch: 600, Train loss: 2.2747\n","Train batch: 700, Train loss: 2.2377\n","Train loss: 2.2596, Train acccuracy: 0.1791\n","Test loss: 2.2604, Test acccuracy: 0.1786\n","--- Epoch 175 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2788\n","Train batch: 200, Train loss: 2.2719\n","Train batch: 300, Train loss: 2.2507\n","Train batch: 400, Train loss: 2.2799\n","Train batch: 500, Train loss: 2.2555\n","Train batch: 600, Train loss: 2.2032\n","Train batch: 700, Train loss: 2.2216\n","Train loss: 2.2598, Train acccuracy: 0.1798\n","Test loss: 2.2603, Test acccuracy: 0.1784\n","--- Epoch 176 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2373\n","Train batch: 200, Train loss: 2.3001\n","Train batch: 300, Train loss: 2.2549\n","Train batch: 400, Train loss: 2.2495\n","Train batch: 500, Train loss: 2.2635\n","Train batch: 600, Train loss: 2.2595\n","Train batch: 700, Train loss: 2.2361\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2602, Test acccuracy: 0.1777\n","--- Epoch 177 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2751\n","Train batch: 200, Train loss: 2.2534\n","Train batch: 300, Train loss: 2.2555\n","Train batch: 400, Train loss: 2.2482\n","Train batch: 500, Train loss: 2.2347\n","Train batch: 600, Train loss: 2.2191\n","Train batch: 700, Train loss: 2.2308\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2607, Test acccuracy: 0.1777\n","--- Epoch 178 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2413\n","Train batch: 200, Train loss: 2.2708\n","Train batch: 300, Train loss: 2.2230\n","Train batch: 400, Train loss: 2.2307\n","Train batch: 500, Train loss: 2.2791\n","Train batch: 600, Train loss: 2.2695\n","Train batch: 700, Train loss: 2.2357\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2612, Test acccuracy: 0.1787\n","--- Epoch 179 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2391\n","Train batch: 200, Train loss: 2.2856\n","Train batch: 300, Train loss: 2.2619\n","Train batch: 400, Train loss: 2.2015\n","Train batch: 500, Train loss: 2.2565\n","Train batch: 600, Train loss: 2.2764\n","Train batch: 700, Train loss: 2.2535\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2612, Test acccuracy: 0.1790\n","--- Epoch 180 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2071\n","Train batch: 200, Train loss: 2.2589\n","Train batch: 300, Train loss: 2.2130\n","Train batch: 400, Train loss: 2.2049\n","Train batch: 500, Train loss: 2.2767\n","Train batch: 600, Train loss: 2.2778\n","Train batch: 700, Train loss: 2.2535\n","Train loss: 2.2597, Train acccuracy: 0.1799\n","Test loss: 2.2603, Test acccuracy: 0.1790\n","--- Epoch 181 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2797\n","Train batch: 200, Train loss: 2.2309\n","Train batch: 300, Train loss: 2.2786\n","Train batch: 400, Train loss: 2.2696\n","Train batch: 500, Train loss: 2.2715\n","Train batch: 600, Train loss: 2.2692\n","Train batch: 700, Train loss: 2.2686\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2604, Test acccuracy: 0.1789\n","--- Epoch 182 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2697\n","Train batch: 200, Train loss: 2.2502\n","Train batch: 300, Train loss: 2.2286\n","Train batch: 400, Train loss: 2.2764\n","Train batch: 500, Train loss: 2.2824\n","Train batch: 600, Train loss: 2.2876\n","Train batch: 700, Train loss: 2.2864\n","Train loss: 2.2595, Train acccuracy: 0.1795\n","Test loss: 2.2606, Test acccuracy: 0.1795\n","--- Epoch 183 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2801\n","Train batch: 200, Train loss: 2.2480\n","Train batch: 300, Train loss: 2.2719\n","Train batch: 400, Train loss: 2.2425\n","Train batch: 500, Train loss: 2.2769\n","Train batch: 600, Train loss: 2.2751\n","Train batch: 700, Train loss: 2.2093\n","Train loss: 2.2598, Train acccuracy: 0.1796\n","Test loss: 2.2611, Test acccuracy: 0.1796\n","--- Epoch 184 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2567\n","Train batch: 200, Train loss: 2.2755\n","Train batch: 300, Train loss: 2.2930\n","Train batch: 400, Train loss: 2.2615\n","Train batch: 500, Train loss: 2.2474\n","Train batch: 600, Train loss: 2.2820\n","Train batch: 700, Train loss: 2.2858\n","Train loss: 2.2597, Train acccuracy: 0.1799\n","Test loss: 2.2604, Test acccuracy: 0.1783\n","--- Epoch 185 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2582\n","Train batch: 200, Train loss: 2.2400\n","Train batch: 300, Train loss: 2.2585\n","Train batch: 400, Train loss: 2.2338\n","Train batch: 500, Train loss: 2.2607\n","Train batch: 600, Train loss: 2.2552\n","Train batch: 700, Train loss: 2.2560\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2617, Test acccuracy: 0.1787\n","--- Epoch 186 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2407\n","Train batch: 200, Train loss: 2.2750\n","Train batch: 300, Train loss: 2.2795\n","Train batch: 400, Train loss: 2.2543\n","Train batch: 500, Train loss: 2.2791\n","Train batch: 600, Train loss: 2.2663\n","Train batch: 700, Train loss: 2.2651\n","Train loss: 2.2598, Train acccuracy: 0.1798\n","Test loss: 2.2601, Test acccuracy: 0.1780\n","--- Epoch 187 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2572\n","Train batch: 200, Train loss: 2.2458\n","Train batch: 300, Train loss: 2.2781\n","Train batch: 400, Train loss: 2.2756\n","Train batch: 500, Train loss: 2.2226\n","Train batch: 600, Train loss: 2.2730\n","Train batch: 700, Train loss: 2.2759\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2611, Test acccuracy: 0.1786\n","--- Epoch 188 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2454\n","Train batch: 200, Train loss: 2.2719\n","Train batch: 300, Train loss: 2.2632\n","Train batch: 400, Train loss: 2.2625\n","Train batch: 500, Train loss: 2.2625\n","Train batch: 600, Train loss: 2.2692\n","Train batch: 700, Train loss: 2.2096\n","Train loss: 2.2596, Train acccuracy: 0.1797\n","Test loss: 2.2603, Test acccuracy: 0.1794\n","--- Epoch 189 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2477\n","Train batch: 200, Train loss: 2.2728\n","Train batch: 300, Train loss: 2.2728\n","Train batch: 400, Train loss: 2.2428\n","Train batch: 500, Train loss: 2.2952\n","Train batch: 600, Train loss: 2.2745\n","Train batch: 700, Train loss: 2.2533\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2601, Test acccuracy: 0.1788\n","--- Epoch 190 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2748\n","Train batch: 200, Train loss: 2.2368\n","Train batch: 300, Train loss: 2.2799\n","Train batch: 400, Train loss: 2.2597\n","Train batch: 500, Train loss: 2.2711\n","Train batch: 600, Train loss: 2.2924\n","Train batch: 700, Train loss: 2.2505\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2597, Test acccuracy: 0.1792\n","--- Epoch 191 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2716\n","Train batch: 200, Train loss: 2.2657\n","Train batch: 300, Train loss: 2.2600\n","Train batch: 400, Train loss: 2.2748\n","Train batch: 500, Train loss: 2.2206\n","Train batch: 600, Train loss: 2.2593\n","Train batch: 700, Train loss: 2.2441\n","Train loss: 2.2598, Train acccuracy: 0.1794\n","Test loss: 2.2597, Test acccuracy: 0.1787\n","--- Epoch 192 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2675\n","Train batch: 200, Train loss: 2.2753\n","Train batch: 300, Train loss: 2.2492\n","Train batch: 400, Train loss: 2.2529\n","Train batch: 500, Train loss: 2.2751\n","Train batch: 600, Train loss: 2.2414\n","Train batch: 700, Train loss: 2.2543\n","Train loss: 2.2597, Train acccuracy: 0.1790\n","Test loss: 2.2605, Test acccuracy: 0.1789\n","--- Epoch 193 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2884\n","Train batch: 200, Train loss: 2.2211\n","Train batch: 300, Train loss: 2.2640\n","Train batch: 400, Train loss: 2.2667\n","Train batch: 500, Train loss: 2.2693\n","Train batch: 600, Train loss: 2.2644\n","Train batch: 700, Train loss: 2.2634\n","Train loss: 2.2597, Train acccuracy: 0.1786\n","Test loss: 2.2602, Test acccuracy: 0.1787\n","--- Epoch 194 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2730\n","Train batch: 200, Train loss: 2.2726\n","Train batch: 300, Train loss: 2.2624\n","Train batch: 400, Train loss: 2.2800\n","Train batch: 500, Train loss: 2.2747\n","Train batch: 600, Train loss: 2.2651\n","Train batch: 700, Train loss: 2.2393\n","Train loss: 2.2598, Train acccuracy: 0.1800\n","Test loss: 2.2608, Test acccuracy: 0.1786\n","--- Epoch 195 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2871\n","Train batch: 200, Train loss: 2.2564\n","Train batch: 300, Train loss: 2.2907\n","Train batch: 400, Train loss: 2.2680\n","Train batch: 500, Train loss: 2.2319\n","Train batch: 600, Train loss: 2.2665\n","Train batch: 700, Train loss: 2.2362\n","Train loss: 2.2598, Train acccuracy: 0.1790\n","Test loss: 2.2608, Test acccuracy: 0.1793\n","--- Epoch 196 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2466\n","Train batch: 200, Train loss: 2.2714\n","Train batch: 300, Train loss: 2.2528\n","Train batch: 400, Train loss: 2.2773\n","Train batch: 500, Train loss: 2.2624\n","Train batch: 600, Train loss: 2.3021\n","Train batch: 700, Train loss: 2.2861\n","Train loss: 2.2596, Train acccuracy: 0.1800\n","Test loss: 2.2608, Test acccuracy: 0.1781\n","--- Epoch 197 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2726\n","Train batch: 200, Train loss: 2.2398\n","Train batch: 300, Train loss: 2.2621\n","Train batch: 400, Train loss: 2.2526\n","Train batch: 500, Train loss: 2.2641\n","Train batch: 600, Train loss: 2.2483\n","Train batch: 700, Train loss: 2.2363\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2604, Test acccuracy: 0.1791\n","--- Epoch 198 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2408\n","Train batch: 200, Train loss: 2.2489\n","Train batch: 300, Train loss: 2.2781\n","Train batch: 400, Train loss: 2.2780\n","Train batch: 500, Train loss: 2.2527\n","Train batch: 600, Train loss: 2.2446\n","Train batch: 700, Train loss: 2.2340\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2603, Test acccuracy: 0.1786\n","--- Epoch 199 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2264\n","Train batch: 200, Train loss: 2.2342\n","Train batch: 300, Train loss: 2.2360\n","Train batch: 400, Train loss: 2.2798\n","Train batch: 500, Train loss: 2.2844\n","Train batch: 600, Train loss: 2.2904\n","Train batch: 700, Train loss: 2.2283\n","Train loss: 2.2599, Train acccuracy: 0.1794\n","Test loss: 2.2607, Test acccuracy: 0.1789\n","--- Epoch 200 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2846\n","Train batch: 200, Train loss: 2.2866\n","Train batch: 300, Train loss: 2.2947\n","Train batch: 400, Train loss: 2.2208\n","Train batch: 500, Train loss: 2.2610\n","Train batch: 600, Train loss: 2.2747\n","Train batch: 700, Train loss: 2.2513\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2612, Test acccuracy: 0.1793\n","--- Epoch 201 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2651\n","Train batch: 200, Train loss: 2.2516\n","Train batch: 300, Train loss: 2.2637\n","Train batch: 400, Train loss: 2.2669\n","Train batch: 500, Train loss: 2.2768\n","Train batch: 600, Train loss: 2.3043\n","Train batch: 700, Train loss: 2.2464\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2611, Test acccuracy: 0.1762\n","--- Epoch 202 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2550\n","Train batch: 200, Train loss: 2.2173\n","Train batch: 300, Train loss: 2.2491\n","Train batch: 400, Train loss: 2.2679\n","Train batch: 500, Train loss: 2.2695\n","Train batch: 600, Train loss: 2.2431\n","Train batch: 700, Train loss: 2.2225\n","Train loss: 2.2598, Train acccuracy: 0.1795\n","Test loss: 2.2612, Test acccuracy: 0.1782\n","--- Epoch 203 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2700\n","Train batch: 200, Train loss: 2.2903\n","Train batch: 300, Train loss: 2.2525\n","Train batch: 400, Train loss: 2.2733\n","Train batch: 500, Train loss: 2.2622\n","Train batch: 600, Train loss: 2.2679\n","Train batch: 700, Train loss: 2.2539\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2603, Test acccuracy: 0.1765\n","--- Epoch 204 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2529\n","Train batch: 200, Train loss: 2.2400\n","Train batch: 300, Train loss: 2.1919\n","Train batch: 400, Train loss: 2.2888\n","Train batch: 500, Train loss: 2.2439\n","Train batch: 600, Train loss: 2.2460\n","Train batch: 700, Train loss: 2.2640\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2602, Test acccuracy: 0.1780\n","--- Epoch 205 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2768\n","Train batch: 200, Train loss: 2.2766\n","Train batch: 300, Train loss: 2.2800\n","Train batch: 400, Train loss: 2.2487\n","Train batch: 500, Train loss: 2.2417\n","Train batch: 600, Train loss: 2.2288\n","Train batch: 700, Train loss: 2.2632\n","Train loss: 2.2595, Train acccuracy: 0.1798\n","Test loss: 2.2599, Test acccuracy: 0.1784\n","--- Epoch 206 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2864\n","Train batch: 200, Train loss: 2.2696\n","Train batch: 300, Train loss: 2.2605\n","Train batch: 400, Train loss: 2.2279\n","Train batch: 500, Train loss: 2.2934\n","Train batch: 600, Train loss: 2.2613\n","Train batch: 700, Train loss: 2.2745\n","Train loss: 2.2595, Train acccuracy: 0.1799\n","Test loss: 2.2606, Test acccuracy: 0.1790\n","--- Epoch 207 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2376\n","Train batch: 200, Train loss: 2.2331\n","Train batch: 300, Train loss: 2.2671\n","Train batch: 400, Train loss: 2.2232\n","Train batch: 500, Train loss: 2.2309\n","Train batch: 600, Train loss: 2.2427\n","Train batch: 700, Train loss: 2.2313\n","Train loss: 2.2597, Train acccuracy: 0.1789\n","Test loss: 2.2607, Test acccuracy: 0.1800\n","--- Epoch 208 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2795\n","Train batch: 200, Train loss: 2.2799\n","Train batch: 300, Train loss: 2.2627\n","Train batch: 400, Train loss: 2.2795\n","Train batch: 500, Train loss: 2.2855\n","Train batch: 600, Train loss: 2.2638\n","Train batch: 700, Train loss: 2.2609\n","Train loss: 2.2597, Train acccuracy: 0.1801\n","Test loss: 2.2605, Test acccuracy: 0.1783\n","--- Epoch 209 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2207\n","Train batch: 200, Train loss: 2.2355\n","Train batch: 300, Train loss: 2.3023\n","Train batch: 400, Train loss: 2.2686\n","Train batch: 500, Train loss: 2.2618\n","Train batch: 600, Train loss: 2.2381\n","Train batch: 700, Train loss: 2.2789\n","Train loss: 2.2597, Train acccuracy: 0.1799\n","Test loss: 2.2603, Test acccuracy: 0.1780\n","--- Epoch 210 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.3029\n","Train batch: 200, Train loss: 2.2304\n","Train batch: 300, Train loss: 2.2701\n","Train batch: 400, Train loss: 2.2444\n","Train batch: 500, Train loss: 2.2623\n","Train batch: 600, Train loss: 2.2448\n","Train batch: 700, Train loss: 2.2550\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2606, Test acccuracy: 0.1776\n","--- Epoch 211 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2701\n","Train batch: 200, Train loss: 2.2555\n","Train batch: 300, Train loss: 2.2489\n","Train batch: 400, Train loss: 2.2597\n","Train batch: 500, Train loss: 2.2596\n","Train batch: 600, Train loss: 2.2595\n","Train batch: 700, Train loss: 2.2753\n","Train loss: 2.2596, Train acccuracy: 0.1792\n","Test loss: 2.2605, Test acccuracy: 0.1774\n","--- Epoch 212 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2449\n","Train batch: 200, Train loss: 2.2747\n","Train batch: 300, Train loss: 2.2393\n","Train batch: 400, Train loss: 2.2623\n","Train batch: 500, Train loss: 2.2775\n","Train batch: 600, Train loss: 2.2325\n","Train batch: 700, Train loss: 2.2667\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2605, Test acccuracy: 0.1798\n","--- Epoch 213 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2873\n","Train batch: 200, Train loss: 2.3005\n","Train batch: 300, Train loss: 2.2603\n","Train batch: 400, Train loss: 2.2412\n","Train batch: 500, Train loss: 2.2409\n","Train batch: 600, Train loss: 2.2640\n","Train batch: 700, Train loss: 2.2853\n","Train loss: 2.2598, Train acccuracy: 0.1797\n","Test loss: 2.2605, Test acccuracy: 0.1778\n","--- Epoch 214 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2430\n","Train batch: 200, Train loss: 2.2580\n","Train batch: 300, Train loss: 2.2692\n","Train batch: 400, Train loss: 2.2686\n","Train batch: 500, Train loss: 2.2576\n","Train batch: 600, Train loss: 2.2432\n","Train batch: 700, Train loss: 2.2448\n","Train loss: 2.2595, Train acccuracy: 0.1797\n","Test loss: 2.2608, Test acccuracy: 0.1777\n","--- Epoch 215 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2171\n","Train batch: 200, Train loss: 2.2552\n","Train batch: 300, Train loss: 2.2706\n","Train batch: 400, Train loss: 2.2728\n","Train batch: 500, Train loss: 2.2732\n","Train batch: 600, Train loss: 2.2116\n","Train batch: 700, Train loss: 2.2529\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2608, Test acccuracy: 0.1770\n","--- Epoch 216 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2634\n","Train batch: 200, Train loss: 2.2660\n","Train batch: 300, Train loss: 2.2226\n","Train batch: 400, Train loss: 2.2844\n","Train batch: 500, Train loss: 2.2427\n","Train batch: 600, Train loss: 2.2530\n","Train batch: 700, Train loss: 2.2780\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2603, Test acccuracy: 0.1786\n","--- Epoch 217 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2740\n","Train batch: 200, Train loss: 2.2125\n","Train batch: 300, Train loss: 2.2424\n","Train batch: 400, Train loss: 2.2443\n","Train batch: 500, Train loss: 2.2610\n","Train batch: 600, Train loss: 2.2746\n","Train batch: 700, Train loss: 2.2623\n","Train loss: 2.2596, Train acccuracy: 0.1794\n","Test loss: 2.2604, Test acccuracy: 0.1785\n","--- Epoch 218 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2382\n","Train batch: 200, Train loss: 2.2619\n","Train batch: 300, Train loss: 2.2658\n","Train batch: 400, Train loss: 2.2893\n","Train batch: 500, Train loss: 2.2327\n","Train batch: 600, Train loss: 2.2611\n","Train batch: 700, Train loss: 2.2370\n","Train loss: 2.2596, Train acccuracy: 0.1798\n","Test loss: 2.2602, Test acccuracy: 0.1779\n","--- Epoch 219 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2261\n","Train batch: 200, Train loss: 2.2712\n","Train batch: 300, Train loss: 2.2490\n","Train batch: 400, Train loss: 2.1997\n","Train batch: 500, Train loss: 2.2467\n","Train batch: 600, Train loss: 2.2407\n","Train batch: 700, Train loss: 2.2644\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2605, Test acccuracy: 0.1776\n","--- Epoch 220 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2796\n","Train batch: 200, Train loss: 2.2767\n","Train batch: 300, Train loss: 2.2474\n","Train batch: 400, Train loss: 2.2497\n","Train batch: 500, Train loss: 2.2559\n","Train batch: 600, Train loss: 2.2378\n","Train batch: 700, Train loss: 2.2974\n","Train loss: 2.2598, Train acccuracy: 0.1798\n","Test loss: 2.2608, Test acccuracy: 0.1791\n","--- Epoch 221 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2507\n","Train batch: 200, Train loss: 2.2186\n","Train batch: 300, Train loss: 2.2670\n","Train batch: 400, Train loss: 2.2582\n","Train batch: 500, Train loss: 2.2587\n","Train batch: 600, Train loss: 2.2582\n","Train batch: 700, Train loss: 2.2829\n","Train loss: 2.2595, Train acccuracy: 0.1797\n","Test loss: 2.2605, Test acccuracy: 0.1786\n","--- Epoch 222 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2809\n","Train batch: 200, Train loss: 2.2592\n","Train batch: 300, Train loss: 2.2239\n","Train batch: 400, Train loss: 2.2559\n","Train batch: 500, Train loss: 2.2543\n","Train batch: 600, Train loss: 2.2576\n","Train batch: 700, Train loss: 2.2434\n","Train loss: 2.2597, Train acccuracy: 0.1793\n","Test loss: 2.2608, Test acccuracy: 0.1786\n","--- Epoch 223 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2456\n","Train batch: 200, Train loss: 2.2663\n","Train batch: 300, Train loss: 2.2567\n","Train batch: 400, Train loss: 2.2576\n","Train batch: 500, Train loss: 2.2200\n","Train batch: 600, Train loss: 2.2848\n","Train batch: 700, Train loss: 2.2845\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2599, Test acccuracy: 0.1781\n","--- Epoch 224 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2323\n","Train batch: 200, Train loss: 2.2939\n","Train batch: 300, Train loss: 2.2769\n","Train batch: 400, Train loss: 2.2467\n","Train batch: 500, Train loss: 2.2565\n","Train batch: 600, Train loss: 2.2731\n","Train batch: 700, Train loss: 2.2391\n","Train loss: 2.2595, Train acccuracy: 0.1804\n","Test loss: 2.2605, Test acccuracy: 0.1790\n","--- Epoch 225 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2533\n","Train batch: 200, Train loss: 2.2579\n","Train batch: 300, Train loss: 2.3011\n","Train batch: 400, Train loss: 2.2708\n","Train batch: 500, Train loss: 2.2542\n","Train batch: 600, Train loss: 2.2253\n","Train batch: 700, Train loss: 2.2655\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2604, Test acccuracy: 0.1781\n","--- Epoch 226 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2710\n","Train batch: 200, Train loss: 2.2913\n","Train batch: 300, Train loss: 2.2407\n","Train batch: 400, Train loss: 2.2507\n","Train batch: 500, Train loss: 2.2610\n","Train batch: 600, Train loss: 2.2772\n","Train batch: 700, Train loss: 2.2390\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2603, Test acccuracy: 0.1787\n","--- Epoch 227 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2742\n","Train batch: 200, Train loss: 2.2333\n","Train batch: 300, Train loss: 2.2462\n","Train batch: 400, Train loss: 2.2538\n","Train batch: 500, Train loss: 2.2439\n","Train batch: 600, Train loss: 2.2695\n","Train batch: 700, Train loss: 2.2151\n","Train loss: 2.2597, Train acccuracy: 0.1794\n","Test loss: 2.2606, Test acccuracy: 0.1783\n","--- Epoch 228 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2426\n","Train batch: 200, Train loss: 2.2361\n","Train batch: 300, Train loss: 2.2854\n","Train batch: 400, Train loss: 2.2947\n","Train batch: 500, Train loss: 2.2522\n","Train batch: 600, Train loss: 2.2757\n","Train batch: 700, Train loss: 2.2905\n","Train loss: 2.2598, Train acccuracy: 0.1799\n","Test loss: 2.2602, Test acccuracy: 0.1791\n","--- Epoch 229 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2765\n","Train batch: 200, Train loss: 2.2936\n","Train batch: 300, Train loss: 2.2838\n","Train batch: 400, Train loss: 2.2809\n","Train batch: 500, Train loss: 2.3008\n","Train batch: 600, Train loss: 2.2408\n","Train batch: 700, Train loss: 2.2652\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2618, Test acccuracy: 0.1795\n","--- Epoch 230 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2231\n","Train batch: 200, Train loss: 2.2359\n","Train batch: 300, Train loss: 2.2358\n","Train batch: 400, Train loss: 2.2491\n","Train batch: 500, Train loss: 2.2699\n","Train batch: 600, Train loss: 2.2803\n","Train batch: 700, Train loss: 2.2694\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2607, Test acccuracy: 0.1797\n","--- Epoch 231 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2490\n","Train batch: 200, Train loss: 2.2785\n","Train batch: 300, Train loss: 2.2661\n","Train batch: 400, Train loss: 2.2575\n","Train batch: 500, Train loss: 2.2683\n","Train batch: 600, Train loss: 2.2476\n","Train batch: 700, Train loss: 2.2651\n","Train loss: 2.2595, Train acccuracy: 0.1797\n","Test loss: 2.2609, Test acccuracy: 0.1788\n","--- Epoch 232 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.1972\n","Train batch: 200, Train loss: 2.2346\n","Train batch: 300, Train loss: 2.2540\n","Train batch: 400, Train loss: 2.2250\n","Train batch: 500, Train loss: 2.2725\n","Train batch: 600, Train loss: 2.2506\n","Train batch: 700, Train loss: 2.2724\n","Train loss: 2.2595, Train acccuracy: 0.1804\n","Test loss: 2.2609, Test acccuracy: 0.1770\n","--- Epoch 233 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2587\n","Train batch: 200, Train loss: 2.2515\n","Train batch: 300, Train loss: 2.2582\n","Train batch: 400, Train loss: 2.1921\n","Train batch: 500, Train loss: 2.2811\n","Train batch: 600, Train loss: 2.2830\n","Train batch: 700, Train loss: 2.2415\n","Train loss: 2.2597, Train acccuracy: 0.1800\n","Test loss: 2.2598, Test acccuracy: 0.1790\n","--- Epoch 234 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2963\n","Train batch: 200, Train loss: 2.2692\n","Train batch: 300, Train loss: 2.2884\n","Train batch: 400, Train loss: 2.2370\n","Train batch: 500, Train loss: 2.2125\n","Train batch: 600, Train loss: 2.2299\n","Train batch: 700, Train loss: 2.2820\n","Train loss: 2.2595, Train acccuracy: 0.1797\n","Test loss: 2.2609, Test acccuracy: 0.1782\n","--- Epoch 235 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2874\n","Train batch: 200, Train loss: 2.2707\n","Train batch: 300, Train loss: 2.2826\n","Train batch: 400, Train loss: 2.2788\n","Train batch: 500, Train loss: 2.2046\n","Train batch: 600, Train loss: 2.1949\n","Train batch: 700, Train loss: 2.2550\n","Train loss: 2.2598, Train acccuracy: 0.1791\n","Test loss: 2.2602, Test acccuracy: 0.1789\n","--- Epoch 236 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2439\n","Train batch: 200, Train loss: 2.2754\n","Train batch: 300, Train loss: 2.2542\n","Train batch: 400, Train loss: 2.2461\n","Train batch: 500, Train loss: 2.2595\n","Train batch: 600, Train loss: 2.3047\n","Train batch: 700, Train loss: 2.2605\n","Train loss: 2.2597, Train acccuracy: 0.1789\n","Test loss: 2.2599, Test acccuracy: 0.1791\n","--- Epoch 237 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2793\n","Train batch: 200, Train loss: 2.2342\n","Train batch: 300, Train loss: 2.2932\n","Train batch: 400, Train loss: 2.2723\n","Train batch: 500, Train loss: 2.2427\n","Train batch: 600, Train loss: 2.2436\n","Train batch: 700, Train loss: 2.2661\n","Train loss: 2.2597, Train acccuracy: 0.1795\n","Test loss: 2.2606, Test acccuracy: 0.1776\n","--- Epoch 238 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2490\n","Train batch: 200, Train loss: 2.2771\n","Train batch: 300, Train loss: 2.2630\n","Train batch: 400, Train loss: 2.2973\n","Train batch: 500, Train loss: 2.2505\n","Train batch: 600, Train loss: 2.2642\n","Train batch: 700, Train loss: 2.2313\n","Train loss: 2.2597, Train acccuracy: 0.1792\n","Test loss: 2.2601, Test acccuracy: 0.1787\n","--- Epoch 239 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2556\n","Train batch: 200, Train loss: 2.2525\n","Train batch: 300, Train loss: 2.2448\n","Train batch: 400, Train loss: 2.2689\n","Train batch: 500, Train loss: 2.2328\n","Train batch: 600, Train loss: 2.2657\n","Train batch: 700, Train loss: 2.2887\n","Train loss: 2.2596, Train acccuracy: 0.1795\n","Test loss: 2.2597, Test acccuracy: 0.1782\n","--- Epoch 240 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2644\n","Train batch: 200, Train loss: 2.2851\n","Train batch: 300, Train loss: 2.2671\n","Train batch: 400, Train loss: 2.2775\n","Train batch: 500, Train loss: 2.2761\n","Train batch: 600, Train loss: 2.2900\n","Train batch: 700, Train loss: 2.2533\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2603, Test acccuracy: 0.1789\n","--- Epoch 241 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2550\n","Train batch: 200, Train loss: 2.2843\n","Train batch: 300, Train loss: 2.2288\n","Train batch: 400, Train loss: 2.2517\n","Train batch: 500, Train loss: 2.2975\n","Train batch: 600, Train loss: 2.2630\n","Train batch: 700, Train loss: 2.2687\n","Train loss: 2.2597, Train acccuracy: 0.1798\n","Test loss: 2.2592, Test acccuracy: 0.1800\n","--- Epoch 242 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2539\n","Train batch: 200, Train loss: 2.2668\n","Train batch: 300, Train loss: 2.2530\n","Train batch: 400, Train loss: 2.3085\n","Train batch: 500, Train loss: 2.2535\n","Train batch: 600, Train loss: 2.2244\n","Train batch: 700, Train loss: 2.2628\n","Train loss: 2.2596, Train acccuracy: 0.1796\n","Test loss: 2.2602, Test acccuracy: 0.1790\n","--- Epoch 243 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2507\n","Train batch: 200, Train loss: 2.2752\n","Train batch: 300, Train loss: 2.2759\n","Train batch: 400, Train loss: 2.2880\n","Train batch: 500, Train loss: 2.2547\n","Train batch: 600, Train loss: 2.2792\n","Train batch: 700, Train loss: 2.2311\n","Train loss: 2.2597, Train acccuracy: 0.1797\n","Test loss: 2.2615, Test acccuracy: 0.1793\n","--- Epoch 244 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2704\n","Train batch: 200, Train loss: 2.2402\n","Train batch: 300, Train loss: 2.2609\n","Train batch: 400, Train loss: 2.2586\n","Train batch: 500, Train loss: 2.2446\n","Train batch: 600, Train loss: 2.2393\n","Train batch: 700, Train loss: 2.2563\n","Train loss: 2.2596, Train acccuracy: 0.1793\n","Test loss: 2.2621, Test acccuracy: 0.1793\n","--- Epoch 245 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2146\n","Train batch: 200, Train loss: 2.2542\n","Train batch: 300, Train loss: 2.2600\n","Train batch: 400, Train loss: 2.2132\n","Train batch: 500, Train loss: 2.2597\n","Train batch: 600, Train loss: 2.2486\n","Train batch: 700, Train loss: 2.2443\n","Train loss: 2.2598, Train acccuracy: 0.1793\n","Test loss: 2.2606, Test acccuracy: 0.1799\n","--- Epoch 246 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2501\n","Train batch: 200, Train loss: 2.2646\n","Train batch: 300, Train loss: 2.2527\n","Train batch: 400, Train loss: 2.2998\n","Train batch: 500, Train loss: 2.3078\n","Train batch: 600, Train loss: 2.2879\n","Train batch: 700, Train loss: 2.2753\n","Train loss: 2.2595, Train acccuracy: 0.1800\n","Test loss: 2.2605, Test acccuracy: 0.1783\n","--- Epoch 247 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2680\n","Train batch: 200, Train loss: 2.2857\n","Train batch: 300, Train loss: 2.2732\n","Train batch: 400, Train loss: 2.2230\n","Train batch: 500, Train loss: 2.2532\n","Train batch: 600, Train loss: 2.2804\n","Train batch: 700, Train loss: 2.2832\n","Train loss: 2.2594, Train acccuracy: 0.1796\n","Test loss: 2.2621, Test acccuracy: 0.1807\n","--- Epoch 248 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2369\n","Train batch: 200, Train loss: 2.2609\n","Train batch: 300, Train loss: 2.2649\n","Train batch: 400, Train loss: 2.2749\n","Train batch: 500, Train loss: 2.2574\n","Train batch: 600, Train loss: 2.2450\n","Train batch: 700, Train loss: 2.2821\n","Train loss: 2.2596, Train acccuracy: 0.1797\n","Test loss: 2.2603, Test acccuracy: 0.1791\n","--- Epoch 249 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2554\n","Train batch: 200, Train loss: 2.2852\n","Train batch: 300, Train loss: 2.2817\n","Train batch: 400, Train loss: 2.2515\n","Train batch: 500, Train loss: 2.2580\n","Train batch: 600, Train loss: 2.2417\n","Train batch: 700, Train loss: 2.2828\n","Train loss: 2.2597, Train acccuracy: 0.1796\n","Test loss: 2.2606, Test acccuracy: 0.1788\n","--- Epoch 250 --- (With L2 regularization)\n","Train batch: 100, Train loss: 2.2665\n","Train batch: 200, Train loss: 2.2722\n","Train batch: 300, Train loss: 2.2661\n","Train batch: 400, Train loss: 2.2356\n","Train batch: 500, Train loss: 2.2872\n","Train batch: 600, Train loss: 2.2814\n","Train batch: 700, Train loss: 2.2684\n","Train loss: 2.2595, Train acccuracy: 0.1796\n","Test loss: 2.2602, Test acccuracy: 0.1785\n"]}],"source":["train_loss, test_loss = [], []\n","train_accu, test_accu = [], []\n","\n","for epoch in range(1, num_epoch + 1):\n","    print('--- Epoch {} --- (With L2 regularization)'.format(epoch))\n","    trloss, traccu = train(mlp250, trainloader, optimizer, loss_func, device)\n","    teloss, teaccu = test(mlp250, testloader, loss_func, device)\n","\n","    train_loss.append(trloss)\n","    train_accu.append(traccu)\n","    test_loss.append(teloss)\n","    test_accu.append(teaccu)\n","\n","np.savetxt('train-250-l2.txt', np.vstack([train_loss, train_accu]))\n","np.savetxt('test-250-l2.txt', np.vstack([test_loss, test_accu]))"]},{"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"elapsed":8,"status":"error","timestamp":1648882304367,"user":{"displayName":"杨朝辉","userId":"06729079918662690657"},"user_tz":420},"id":"n4ZyydsFv724","outputId":"b16f4229-46e6-4c06-867e-e15af81077d6"},"source":["### Results comparison"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["train_50 = np.loadtxt('output/train-50.txt')\n","test_50 = np.loadtxt('output/test-50.txt')\n","train_50_l2 = np.loadtxt('output/train-50-l2.txt')\n","test_50_l2 = np.loadtxt('output/test-50-l2.txt')"]},{"cell_type":"markdown","metadata":{"id":"RYix2qSvv724"},"source":["## 2. Adaboost "]},{"cell_type":"markdown","metadata":{"id":"DZF1eZmiv724"},"source":["### load data\n","`adult_train.csv`, `adult_test.csv`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLJ06xkwv724","outputId":"8e38b4e5-d844-4ad3-b133-322b04ff0090"},"outputs":[{"name":"stdout","output_type":"stream","text":["(20000, 14) (10000, 14)\n"]}],"source":["train_data = np.loadtxt('data/adult_train.csv', delimiter=',')\n","test_data = np.loadtxt('data/adult_test.csv', delimiter=',')\n","idx_train, idx_test = np.random.choice(range(len(train_data)), 20000), np.random.choice(range(len(test_data)), 10000)\n","train_data, test_data = train_data[idx_train], test_data[idx_test]\n","X_train, y_train = train_data[:,:-1], train_data[:,-1]\n","X_test, y_test = test_data[:,:-1], test_data[:,-1]\n","# convert {0,1} into {-1,1}\n","y_train = np.sign(y_train - 0.5)\n","y_test = np.sign(y_test - 0.5)\n","print(X_train.shape, X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"ol-WzKlWv725"},"source":["### Compare effetc of self-implemented adaboost and built-in adaboost in sklearn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e1KZkiYbv725"},"outputs":[],"source":["booster = MyAdaBoostClassifier(n_estimators=10, max_depth=3, rand_seed=1234)\n","booster.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jW5AmOjv725","outputId":"4ec602f4-e0a3-4f88-c3e1-aba3bf2f7369"},"outputs":[{"data":{"text/plain":["AdaBoostClassifier(algorithm='SAMME.R',\n","                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n","                                                         class_weight=None,\n","                                                         criterion='gini',\n","                                                         max_depth=3,\n","                                                         max_features=None,\n","                                                         max_leaf_nodes=None,\n","                                                         min_impurity_decrease=0.0,\n","                                                         min_impurity_split=None,\n","                                                         min_samples_leaf=1,\n","                                                         min_samples_split=2,\n","                                                         min_weight_fraction_leaf=0.0,\n","                                                         presort='deprecated',\n","                                                         random_state=None,\n","                                                         splitter='best'),\n","                   learning_rate=1.0, n_estimators=10, random_state=None)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["t = tree.DecisionTreeClassifier(max_depth=3)\n","t.fit(X_train, y_train)\n","\n","ada = ensemble.AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=3), n_estimators=10)\n","ada.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rOXrz-Rsv725","outputId":"b2d1fa92-da15-4c61-8642-8d10a1a59101"},"outputs":[{"name":"stdout","output_type":"stream","text":["my self-implemented adaboost:  0.8429\n","single decision tree: 0.8417\n","built-in adaboost in sklearn: 0.8579\n"]}],"source":["# ensemble classifier accuracy v.s. single decision tree\n","print('my self-implemented adaboost: ', metrics.accuracy_score(booster.predict(X_test), y_test))\n","print('single decision tree:', metrics.accuracy_score(t.predict(X_test), y_test))\n","print('built-in adaboost in sklearn:', metrics.accuracy_score(ada.predict(X_test), y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"91_Gw9uZv725"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"hw-4.ipynb","provenance":[]},"interpreter":{"hash":"26d6d95e799f68a0680bea77b17a4e3218da601be7d02863e2950dbe63a5be85"},"kernelspec":{"display_name":"Python 3.8.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"orig_nbformat":4,"widgets":{"application/vnd.jupyter.widget-state+json":{"0eb2a87f47d146d4ab4f62d16fde2e1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32b6de3cf20e40119f2ded41de92369d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81044ed6104047d3896ce7b535744e51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4ae6471349f4ce58b51d18f0fdbf262","IPY_MODEL_a197876f366f4549b07ae4b499969c7a","IPY_MODEL_86a27bc6efc34fb3bc59705b1221c625"],"layout":"IPY_MODEL_ed06b218451b446e9935861e0671f393"}},"86a27bc6efc34fb3bc59705b1221c625":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9ae4d43857a4581908b06e10d7a1dc7","placeholder":"​","style":"IPY_MODEL_32b6de3cf20e40119f2ded41de92369d","value":" 170499072/? [00:02&lt;00:00, 58071748.55it/s]"}},"8ab5b541d41a4043961d37f64e56a51f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a197876f366f4549b07ae4b499969c7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eb2a87f47d146d4ab4f62d16fde2e1c","max":170498071,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5913d39f1dc4db6b40b327379b9a9a5","value":170498071}},"a4ae6471349f4ce58b51d18f0fdbf262":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ab5b541d41a4043961d37f64e56a51f","placeholder":"​","style":"IPY_MODEL_e6cfa800fb9d48b7a20a21e6b6323772","value":""}},"a5913d39f1dc4db6b40b327379b9a9a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9ae4d43857a4581908b06e10d7a1dc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6cfa800fb9d48b7a20a21e6b6323772":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed06b218451b446e9935861e0671f393":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
